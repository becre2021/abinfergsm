{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "np.set_printoptions(precision = 4)\n",
    "import pickle\n",
    "\n",
    "from datasets.dataset import _load_collection_real,_load_collection_syn\n",
    "from models_utility.construct_models import _initialize_SMkernelhyp,_make_gpmodel\n",
    "from utility.eval_metric import _evaluate_metric\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "from matplotlib import rc\n",
    "rc('font', size=20)\n",
    "rc('legend', fontsize=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAABECAYAAAD+xS3TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAACo0lEQVR4nO3aMWobaRzG4TeSCnXGmIEUIieYUtfQBaLzyaTXNVx+J1hUWHwEYdKo0EhbmN2FOAO74PGwk+cpNTa8/0b6gfTpdrvdAgD81mZjDwAAxicIAABBAAAIAgAgyaLvwfl8TiklTdNkPp9/5CYA4J11XZdaa9q2zXK5fPO8NwhKKdlut4OOAwA+1m63y3q9fvN6bxA0TfP6j9//yOfrZbhlIyqP+7SnzdgzBlPu9yntdO9ryz6b9uvYMwaxL4/ZtKexZwxmX+6zKe3YMwazb0u+bqZ73+O+5DTh++73Je2mjD3j3T0vfmT75dvfn+8/6w2Cv74m+Hy9ZDXRIDg2TVazad6WJMeHJner6d7XHJtcVtexZwzi9bbp/sSnOT7kcrcae8ZgmuaY62Xa980mfN9Dc8zqcjf2jMH0/Qxguu84AMC/JggAAEEAAAgCACCCAACIIAAAIggAgAgCACCCAACIIAAAIggAgAgCACCCAACIIAAAIggAgAgCACCCAACIIAAAIggAgAgCACCCAACIIAAAIggAgAgCACCCAACIIAAAIggAgAgCACCCAACIIAAAIggAgAgCACCCAACIIAAAIggAgAgCACCCAACIIAAAIggAgAgCACCCAACIIAAAIggAgAgCACCCAACIIAAAIggAgAgCACCCAACIIAAAIggAgCSLvgdd1yVJnme9f/K/V2vN4TTh+641L4cJ31drFodpNu3rbaexZwym1msWL4exZwym1prZYtr3nSZ837XWHBYvY894d8+LH0n++Xz/2afb7Xb71YOnp6dst9vhlgEAH26322W9Xr95vTcIzudzSilpmibz+XzwgQDAcLquS601bdtmuVy+ed4bBADA72OaX8ACAP+JIAAABAEAIAgAgCR/Aiw6mLAkRVIHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 648x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_style('white')\n",
    "import matplotlib\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "plt.rc('font', family='serif')\n",
    "\n",
    "current_palette = sns.color_palette(sns.hls_palette(8+1, l=.5, s=1.0))\n",
    "\n",
    "sns.palplot(current_palette)\n",
    "current_palette = np.asarray(current_palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = True\n",
    "datafilename_list = ['CO2','airline']\n",
    "\n",
    "#filename = 'CO2'\n",
    "filename = 'airline'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#loaded collection#\n",
      "airline setting\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "x_train, x_test, y_train, y_test = _load_collection_real(filename,cuda_option=device)\n",
    "x_full = torch.cat([x_train,x_test],dim = 0)\n",
    "y_full = torch.cat([y_train,y_test],dim = 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "random_seed = 1000\n",
    "setting_dict = {}\n",
    "setting_dict['random_seed'] = random_seed\n",
    "setting_dict['input_dim'] = x_train.shape[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if filename in [ 'CO2']:\n",
    "    print('C02 setting') \n",
    "    setting_dict['init_sample_num'] = 500    \n",
    "    setting_dict['lr_hyp'] = 0.005 \n",
    "    setting_dict['noise_err'] = .05*y_train.cpu().data.numpy().std()    \n",
    "    setting_dict['num_Q'] = 10\n",
    "    setting_dict['num_sample_pt'] = 4\n",
    "    setting_dict['iter'] = 6000\n",
    "    setting_dict['weight_rate'] = .1  #allocation rate\n",
    "    \n",
    "    \n",
    "elif filename in ['airline']:\n",
    "    print('airline setting') \n",
    "    setting_dict['init_sample_num'] = 500    \n",
    "    #previous\n",
    "    setting_dict['lr_hyp'] = 0.005  \n",
    "    \n",
    "    setting_dict['noise_err'] = .05*y_train.cpu().data.numpy().std()\n",
    "    setting_dict['num_sample_pt'] = 10\n",
    "    setting_dict['num_Q'] = 7\n",
    "    setting_dict['iter'] = 5000\n",
    "\n",
    "    setting_dict['weight_rate'] = .5 #allocation rate\n",
    "\n",
    "else:\n",
    "    pass\n",
    "\n",
    "\n",
    "setting_dict['kl_option'] = True    #['True','False']\n",
    "setting_dict['num_batch'] = 1\n",
    "setting_dict['num_rep'] = 1\n",
    "setting_dict['optimizer'] = 'Adam'\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.cuda.DoubleTensor'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {}\n",
    "result_dict['Exp_setting'] = setting_dict\n",
    "result_dict['Data_setting'] = {'x_train' : x_train.cpu().data.numpy(),\n",
    "                               'y_train' : y_train.cpu().data.numpy(),\n",
    "                               'x_test' : x_test.cpu().data.numpy(),\n",
    "                               'y_test' : y_test.cpu().data.numpy()}\n",
    "\n",
    "result_dict['loss'] = {}\n",
    "result_dict['rmse'] = {}\n",
    "result_dict['mnll'] = {}\n",
    "result_dict['best_loss'] = {}\n",
    "result_dict['best_rmse'] = {}\n",
    "result_dict['best_mnll'] = {}\n",
    "\n",
    "result_dict['pred_train_mu'] = {}\n",
    "result_dict['pred_train_var'] = {}\n",
    "result_dict['pred_test_mu'] = {}\n",
    "result_dict['pred_test_var'] = {}\n",
    "result_dict['param_history'] = {}\n",
    "result_dict['error_history'] = {}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### modelsetup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_param(temp_model):\n",
    "    param_dict = {}\n",
    "    for ith_name,ith_param in temp_model.named_parameters():\n",
    "        param_dict[ith_name] = ith_param.data.clone()    \n",
    "    if hasattr(temp_model,'likelihood'):\n",
    "        param_dict['var_noise'] = temp_model.likelihood.variance.data.clone()     \n",
    "    return param_dict\n",
    "\n",
    "\n",
    "def load_model_param(temp_model,saved_param):\n",
    "    for ith_name,ith_param in temp_model.named_parameters():\n",
    "        ith_param.data = saved_param[ith_name]        \n",
    "    if hasattr(temp_model,'likelihood'):\n",
    "        temp_model.likelihood.variance.data = saved_param['var_noise']\n",
    "    return temp_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### proposed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_period = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.utils as torch_utils\n",
    "from scipy.linalg import norm as fnorm\n",
    "from models_utility.personalized_adam import Adam_variation\n",
    "\n",
    "\n",
    "def _train_model(ith_model_name,ith,setting_dict,num_spt1 ):\n",
    "    setting_dict['num_sample_pt'] = num_spt1     \n",
    "    #if num_spt1 >= 2:\n",
    "    \n",
    "    \n",
    "    \n",
    "    if num_spt1 >= 1:\n",
    "        \n",
    "        # intializatoin part\n",
    "        best_loss = np.inf\n",
    "        for ith in range(10):    \n",
    "            temp_model = _make_gpmodel(model_name=ith_model_name, setting_dict=setting_dict, device=device)\n",
    "            if ith_model_name in ['gpvfe', 'gpvferbf']:\n",
    "                temp_model._set_data(batch_x=x_train, batch_y=y_train)        \n",
    "                temp_model._set_inducing_pt(2 * setting_dict['num_Q'] * setting_dict['num_sample_pt'])\n",
    "                \n",
    "                optimizable_param =  [*temp_model.parameters(),temp_model.likelihood.variance]\n",
    "            elif ith_model_name in ['vssgp']:\n",
    "                temp_model._set_data(batch_x=x_train, batch_y=y_train)                \n",
    "                temp_model._set_inducing_pt( setting_dict['num_Q'] * setting_dict['num_sample_pt'])\n",
    "                optimizable_param =  [*temp_model.parameters()]\n",
    "            else:\n",
    "                temp_model._set_data(x_train, y_train)                            \n",
    "                optimizable_param =  [*temp_model.parameters(),temp_model.likelihood.variance]\n",
    "                try:\n",
    "                    temp_model.spt_manager.adaptive_alpha = 0.0\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                \n",
    "                \n",
    "            temp_optimizer = torch.optim.Adam(optimizable_param ,\n",
    "                                              lr=setting_dict['lr_hyp'],\n",
    "                                              betas=(0.9, 0.99),\n",
    "                                              eps=1e-08,\n",
    "                                              weight_decay=0.0)    \n",
    "\n",
    "\n",
    "            for i in range(50 + 1):    \n",
    "                temp_optimizer.zero_grad()    \n",
    "                losstotal = temp_model.compute_loss(batch_x=x_train, batch_y=y_train, kl_option=setting_dict['kl_option'])\n",
    "                losstotal.backward()\n",
    "                temp_optimizer.step()\n",
    "\n",
    "            # best model chosen\n",
    "            if best_loss >= losstotal.cpu().data.numpy():\n",
    "                best_loss = losstotal.cpu().data.numpy()        \n",
    "                saved_param = save_model_param(temp_model)\n",
    "                ith_model = load_model_param(temp_model,saved_param)\n",
    "                optimizer = temp_optimizer\n",
    "                \n",
    "\n",
    "                \n",
    "                print('%d init loss: %.4f '%(ith,losstotal.cpu().data.numpy()))\n",
    "                print('%d model chosen '%(ith))\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "\n",
    "\n",
    "        param_history_list = []\n",
    "        error_history_list1,error_history_list2 = [],[]\n",
    "        loss_history_list,loss_history_list1,loss_history_list2 = [],[],[]\n",
    "        rmse_history_list,rmse_history_list1,rmse_history_list2 = [],[],[]\n",
    "        mnll_history_list = []\n",
    "        ###################\n",
    "        #scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.5)\n",
    "        ###################\n",
    "        \n",
    "        print('#'*200)\n",
    "        print(ith_model_name)\n",
    "        print('#'*200)        \n",
    "        \n",
    "        ith_model.train()\n",
    "        try:\n",
    "            ith_model.spt_manager.total_trainiter = setting_dict['iter']\n",
    "            ith_model.spt_manager.call_num = 0\n",
    "            ith_model.spt_manager.adaptive_alpha = 0.5            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        for i in range(setting_dict['iter'] + 1):\n",
    "            #scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            ith_tic = time.time()\n",
    "            losstotal = ith_model.compute_loss(batch_x=x_train, batch_y=y_train, kl_option=setting_dict['kl_option'])\n",
    "            losstotal.backward()\n",
    "            optimizer.step()\n",
    "            ith_toc = time.time()\n",
    "\n",
    "\n",
    "            #print('\\n')\n",
    "\n",
    "            if i % observed_period == 0 :\n",
    "                with torch.no_grad():\n",
    "                    pred_train_mu, pred_train_var = ith_model._predict(inputs_new=x_train)\n",
    "                    pred_test_mu, pred_test_var = ith_model._predict(inputs_new=x_test)      \n",
    "                    ith_rmse,ith_mnll = _evaluate_metric(pred_test_mu, pred_test_var, y_test)\n",
    "                \n",
    "                print('%d th loss0 : %.4f, test rmse : %.4f, test mnll: : %.4f' % (i,losstotal.cpu().data.numpy(),ith_rmse,ith_mnll))        \n",
    "                try:\n",
    "                    ith_weights = ith_model.weight.exp().squeeze().cpu().data.numpy().round(0)\n",
    "                    index = np.argsort(-ith_weights)\n",
    "        \n",
    "                    print('{0} \\t\\t\\t\\t\\t self.weight.exp() '.format(ith_weights[index] ))            \n",
    "                    print('{0} \\t\\t\\t\\t\\t self.mu.exp() '.format(ith_model.mu.exp().squeeze().cpu().data.numpy().round(4)[index]  ))            \n",
    "                    print('{0} \\t\\t\\t\\t\\t self.std.exp() '.format(ith_model.std.exp().squeeze().cpu().data.numpy().round(4)[index]   )) \n",
    "                    print('{0} \\t\\t\\t\\t\\t self.num_samplept_list_at '.format(np.array(ith_model.num_samplept_list_at)[index]))\n",
    "                    print('{0} \\t\\t\\t\\t\\t likelihood variance '.format(ith_model.likelihood.variance.transform().cpu().data.numpy()**2   ))                                \n",
    "\n",
    "                    print('\\n')\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                loss_history_list.append(losstotal.cpu().data.numpy().squeeze())\n",
    "                rmse_history_list.append(ith_rmse.squeeze())\n",
    "                mnll_history_list.append(ith_mnll.squeeze())\n",
    "\n",
    "\n",
    "        return ith_model,loss_history_list,rmse_history_list,mnll_history_list\n",
    "    else:\n",
    "        return ith_model,loss_history_list,rmse_history_list,mnll_history_list\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compare_reg_model(num_spt1,num_rep,setting_dict):\n",
    "    rep_loss_history_list_e,rep_loss_history_list_w,rep_loss_history_list_nw = [],[],[]\n",
    "    rep_rmse_history_list_e,rep_rmse_history_list_w,rep_rmse_history_list_nw = [],[],[]\n",
    "    rep_mnll_history_list_e,rep_mnll_history_list_w,rep_mnll_history_list_nw = [],[],[]    \n",
    "    rep_model_history_list_e,rep_model_history_list_w,rep_model_history_list_nw = [],[],[]\n",
    "\n",
    "    for i in range(num_rep):\n",
    "        print('#'*50)\n",
    "        print('#{0} th experimnet'.format(i))\n",
    "        setting_dict = _initialize_SMkernelhyp(x_train, y_train, setting_dict, random_seed + i ,yesSM= True, filename = filename)        \n",
    "        \n",
    "        model_w,loss_history_list_w,rmse_history_list_w,mnll_history_list_w =  _train_model('weight_reg',i,setting_dict,num_spt1=num_spt1)            \n",
    "        model_e,loss_history_list_e,rmse_history_list_e,mnll_history_list_e  =  _train_model('equal_reg',i,setting_dict,num_spt1=num_spt1)        \n",
    "        \n",
    "        print('\\n'*5)\n",
    "\n",
    "        rep_loss_history_list_e.append(loss_history_list_e)\n",
    "        rep_loss_history_list_w.append(loss_history_list_w)\n",
    "        \n",
    "        rep_rmse_history_list_e.append(rmse_history_list_e)\n",
    "        rep_rmse_history_list_w.append(rmse_history_list_w)\n",
    "  \n",
    "        rep_mnll_history_list_e.append(mnll_history_list_e)\n",
    "        rep_mnll_history_list_w.append(mnll_history_list_w)\n",
    "        \n",
    "        rep_model_history_list_e.append(model_e)\n",
    "        rep_model_history_list_w.append(model_w)\n",
    "        \n",
    "    return rep_loss_history_list_e,rep_loss_history_list_w,\\\n",
    "           rep_rmse_history_list_e,rep_rmse_history_list_w,\\\n",
    "           rep_mnll_history_list_e,rep_mnll_history_list_w,\\\n",
    "           rep_model_history_list_e,rep_model_history_list_w\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _compare_reg_model2(num_spt1,num_rep,setting_dict):\n",
    "    rep_loss_history_list_e,rep_loss_history_list_w,rep_loss_history_list_nw = [],[],[]\n",
    "    rep_rmse_history_list_e,rep_rmse_history_list_w,rep_rmse_history_list_nw = [],[],[]\n",
    "    rep_mnll_history_list_e,rep_mnll_history_list_w,rep_mnll_history_list_nw = [],[],[]    \n",
    "    rep_model_history_list_e,rep_model_history_list_w,rep_model_history_list_nw = [],[],[]\n",
    "\n",
    "    for i in range(num_rep):\n",
    "        print('#'*50)\n",
    "        print('#{0} th experimnet'.format(i))\n",
    "        setting_dict = _initialize_SMkernelhyp(x_train, y_train, setting_dict, random_seed + i ,yesSM= True, filename = filename)        \n",
    " \n",
    "        model_nw,loss_history_list_nw,rmse_history_list_nw,mnll_history_list_nw =  _train_model('gpsm',i,setting_dict,num_spt1=num_spt1)        \n",
    "        model_w,loss_history_list_w,rmse_history_list_w,mnll_history_list_w =  _train_model('weight_reg',i,setting_dict,num_spt1=num_spt1)            \n",
    "        model_e,loss_history_list_e,rmse_history_list_e,mnll_history_list_e  =  _train_model('equal_reg',i,setting_dict,num_spt1=num_spt1)        \n",
    "        \n",
    "        print('\\n'*5)\n",
    "\n",
    "        rep_loss_history_list_e.append(loss_history_list_e)\n",
    "        rep_loss_history_list_w.append(loss_history_list_w)\n",
    "        rep_loss_history_list_nw.append(loss_history_list_nw)\n",
    "        \n",
    "        rep_rmse_history_list_e.append(rmse_history_list_e)\n",
    "        rep_rmse_history_list_w.append(rmse_history_list_w)\n",
    "        rep_rmse_history_list_nw.append(rmse_history_list_nw)\n",
    "\n",
    "        rep_mnll_history_list_e.append(mnll_history_list_e)\n",
    "        rep_mnll_history_list_w.append(mnll_history_list_w)\n",
    "        rep_mnll_history_list_nw.append(mnll_history_list_nw)\n",
    "        \n",
    "        rep_model_history_list_e.append(model_e)\n",
    "        rep_model_history_list_w.append(model_w)\n",
    "        rep_model_history_list_nw.append(model_nw)\n",
    "        \n",
    "    return rep_loss_history_list_e,rep_loss_history_list_w,rep_loss_history_list_nw,\\\n",
    "           rep_rmse_history_list_e,rep_rmse_history_list_w,rep_rmse_history_list_nw,\\\n",
    "           rep_mnll_history_list_e,rep_mnll_history_list_w,rep_mnll_history_list_nw,\\\n",
    "           rep_model_history_list_e,rep_model_history_list_w,rep_model_history_list_nw \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rep,num_spt1 = 5,4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "#0 th experimnet\n",
      "0 init loss: 58448.5398 \n",
      "0 model chosen \n",
      "1 init loss: 58448.5398 \n",
      "1 model chosen \n",
      "2 init loss: 58448.5398 \n",
      "2 model chosen \n",
      "3 init loss: 58448.5398 \n",
      "3 model chosen \n",
      "4 init loss: 58448.5398 \n",
      "4 model chosen \n",
      "5 init loss: 58448.5398 \n",
      "5 model chosen \n",
      "6 init loss: 58448.5398 \n",
      "6 model chosen \n",
      "7 init loss: 58448.5398 \n",
      "7 model chosen \n",
      "8 init loss: 58448.5398 \n",
      "8 model chosen \n",
      "9 init loss: 58448.5398 \n",
      "9 model chosen \n",
      "########################################################################################################################################################################################################\n",
      "gpsm\n",
      "########################################################################################################################################################################################################\n",
      "0 th loss0 : 57665.1489, test rmse : 514.3344, test mnll: : 4715.8369\n",
      "100 th loss0 : 20538.1865, test rmse : 436.6066, test mnll: : 2239.0451\n",
      "200 th loss0 : 11968.6366, test rmse : 370.2520, test mnll: : 1274.2906\n",
      "300 th loss0 : 8053.6975, test rmse : 334.1077, test mnll: : 845.9174\n",
      "400 th loss0 : 5681.3371, test rmse : 307.8396, test mnll: : 586.7229\n",
      "500 th loss0 : 4105.7849, test rmse : 285.2532, test mnll: : 408.4538\n",
      "600 th loss0 : 3029.6606, test rmse : 265.3219, test mnll: : 280.2439\n",
      "700 th loss0 : 2284.1914, test rmse : 248.8223, test mnll: : 190.9595\n",
      "800 th loss0 : 1760.0573, test rmse : 236.6547, test mnll: : 130.5440\n",
      "900 th loss0 : 1386.9774, test rmse : 229.0452, test mnll: : 90.1002\n",
      "1000 th loss0 : 1120.8364, test rmse : 225.4865, test mnll: : 62.9876\n",
      "1100 th loss0 : 932.8896, test rmse : 224.9096, test mnll: : 44.7692\n",
      "1200 th loss0 : 802.6659, test rmse : 225.7951, test mnll: : 32.6081\n",
      "1300 th loss0 : 714.2622, test rmse : 226.0859, test mnll: : 24.6866\n",
      "1400 th loss0 : 654.3640, test rmse : 222.7815, test mnll: : 19.8560\n",
      "1500 th loss0 : 610.2169, test rmse : 211.3749, test mnll: : 17.5948\n",
      "1600 th loss0 : 568.3544, test rmse : 187.2403, test mnll: : 17.9164\n",
      "1700 th loss0 : 522.9051, test rmse : 154.3612, test mnll: : 19.1733\n",
      "1800 th loss0 : 472.4610, test rmse : 142.0765, test mnll: : 21.9161\n",
      "1900 th loss0 : 424.9144, test rmse : 137.0703, test mnll: : 22.6151\n",
      "2000 th loss0 : 399.5032, test rmse : 133.5686, test mnll: : 20.5961\n",
      "2100 th loss0 : 386.7388, test rmse : 123.2013, test mnll: : 15.6743\n",
      "2200 th loss0 : 375.1880, test rmse : 117.2099, test mnll: : 12.9243\n",
      "2300 th loss0 : 369.4811, test rmse : 111.6968, test mnll: : 10.9568\n",
      "2400 th loss0 : 365.7905, test rmse : 105.0278, test mnll: : 9.3905\n",
      "2500 th loss0 : 363.2355, test rmse : 97.4290, test mnll: : 8.1847\n",
      "2600 th loss0 : 361.4942, test rmse : 88.7854, test mnll: : 7.2954\n",
      "2700 th loss0 : 360.2751, test rmse : 77.9351, test mnll: : 6.5716\n",
      "2800 th loss0 : 359.3899, test rmse : 66.2565, test mnll: : 5.9876\n",
      "2900 th loss0 : 358.7585, test rmse : 55.9875, test mnll: : 5.5538\n",
      "3000 th loss0 : 358.3230, test rmse : 47.6823, test mnll: : 5.2466\n",
      "3100 th loss0 : 358.0349, test rmse : 41.0985, test mnll: : 5.0287\n",
      "3200 th loss0 : 357.8771, test rmse : 36.3184, test mnll: : 4.8869\n",
      "3300 th loss0 : 357.7558, test rmse : 32.4867, test mnll: : 4.7762\n",
      "3400 th loss0 : 357.7035, test rmse : 30.0263, test mnll: : 4.7100\n",
      "3500 th loss0 : 357.6851, test rmse : 28.5888, test mnll: : 4.6730\n",
      "3600 th loss0 : 357.6812, test rmse : 27.7888, test mnll: : 4.6521\n",
      "3700 th loss0 : 357.6829, test rmse : 27.6360, test mnll: : 4.6489\n",
      "3800 th loss0 : 357.6809, test rmse : 27.5664, test mnll: : 4.6467\n",
      "3900 th loss0 : 357.6808, test rmse : 27.5554, test mnll: : 4.6462\n",
      "4000 th loss0 : 357.6891, test rmse : 27.5572, test mnll: : 4.6463\n",
      "4100 th loss0 : 357.6833, test rmse : 27.5034, test mnll: : 4.6446\n",
      "4200 th loss0 : 357.6832, test rmse : 27.6125, test mnll: : 4.6482\n",
      "4300 th loss0 : 357.6810, test rmse : 27.5597, test mnll: : 4.6467\n",
      "4400 th loss0 : 357.6845, test rmse : 27.4459, test mnll: : 4.6426\n",
      "4500 th loss0 : 357.6807, test rmse : 27.5375, test mnll: : 4.6457\n",
      "4600 th loss0 : 357.6806, test rmse : 27.5370, test mnll: : 4.6457\n",
      "4700 th loss0 : 357.6814, test rmse : 27.5491, test mnll: : 4.6459\n",
      "4800 th loss0 : 357.6810, test rmse : 27.5652, test mnll: : 4.6467\n",
      "4900 th loss0 : 357.6902, test rmse : 27.6396, test mnll: : 4.6496\n",
      "5000 th loss0 : 357.6931, test rmse : 27.3999, test mnll: : 4.6407\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "0 init loss: 102658.9159 \n",
      "0 model chosen \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "1 init loss: 101938.7202 \n",
      "1 model chosen \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "2 init loss: 43234.7203 \n",
      "2 model chosen \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "########################################################################################################################################################################################################\n",
      "weight_reg\n",
      "########################################################################################################################################################################################################\n",
      "0 th loss0 : 70370.0670, test rmse : 464.3913, test mnll: : 4282.8381\n",
      "[1. 1. 1. 1. 1. 1. 1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0789 0.0084 0.1683 0.341  0.406  0.2396 0.0264] \t\t\t\t\t self.mu.exp() \n",
      "[0.0056 0.0012 0.0064 0.0045 0.0256 0.0161 0.0174] \t\t\t\t\t self.std.exp() \n",
      "[4 3 4 4 4 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[19.8355] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "100 th loss0 : 26422.5152, test rmse : 455.8349, test mnll: : 2617.2907\n",
      "[2. 2. 2. 2. 2. 2. 2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0764 0.0056 0.1689 0.3326 0.3978 0.2441 0.0245] \t\t\t\t\t self.mu.exp() \n",
      "[0.005  0.0016 0.0053 0.0047 0.0253 0.0158 0.0181] \t\t\t\t\t self.std.exp() \n",
      "[4 3 4 4 4 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[31.6591] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "200 th loss0 : 12838.2709, test rmse : 454.7160, test mnll: : 2025.7508\n",
      "[3. 3. 2. 2. 2. 2. 2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0044 0.168  0.0787 0.3375 0.4062 0.2462 0.0237] \t\t\t\t\t self.mu.exp() \n",
      "[0.0017 0.0044 0.0043 0.0044 0.0251 0.0152 0.0182] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 4 4 5 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[40.3924] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "300 th loss0 : 11377.6291, test rmse : 422.6034, test mnll: : 1435.2872\n",
      "[5. 4. 3. 3. 3. 2. 2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0037 0.1665 0.0813 0.3325 0.2448 0.4035 0.0236] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.0035 0.0038 0.0042 0.0142 0.0253 0.0181] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 4 4 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[48.8352] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "400 th loss0 : 7020.5666, test rmse : 394.8273, test mnll: : 1065.6319\n",
      "[7. 5. 4. 4. 3. 2. 2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0033 0.1695 0.0812 0.3331 0.2401 0.4127 0.0235] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.0029 0.0033 0.0038 0.0133 0.0258 0.018 ] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 4 4 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[57.9103] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "500 th loss0 : 4313.5597, test rmse : 276.0125, test mnll: : 432.1256\n",
      "[10.  7.  6.  5.  4.  3.  2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0029 0.1687 0.0811 0.3342 0.2456 0.4051 0.023 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0014 0.0024 0.0028 0.0035 0.0125 0.0263 0.0182] \t\t\t\t\t self.std.exp() \n",
      "[3 3 4 4 5 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[69.8296] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 th loss0 : 3589.2609, test rmse : 277.7666, test mnll: : 352.3558\n",
      "[13. 10.  8.  6.  6.  3.  3.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0027 0.1676 0.0817 0.3315 0.2496 0.4009 0.0228] \t\t\t\t\t self.mu.exp() \n",
      "[0.0013 0.002  0.0026 0.0035 0.0112 0.0269 0.0182] \t\t\t\t\t self.std.exp() \n",
      "[3 3 4 4 5 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[84.0674] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "700 th loss0 : 2784.4539, test rmse : 246.8924, test mnll: : 226.1895\n",
      "[18. 13. 11.  8.  8.  3.  3.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0024 0.169  0.0817 0.3331 0.2488 0.4059 0.0224] \t\t\t\t\t self.mu.exp() \n",
      "[0.0011 0.0017 0.0024 0.0037 0.01   0.0282 0.0183] \t\t\t\t\t self.std.exp() \n",
      "[3 3 4 4 5 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[104.0412] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "800 th loss0 : 2167.8071, test rmse : 203.9695, test mnll: : 126.7684\n",
      "[26. 18. 16. 10. 10.  3.  2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0023 0.1675 0.0819 0.3307 0.2472 0.0222 0.4162] \t\t\t\t\t self.mu.exp() \n",
      "[0.001  0.0016 0.0023 0.0042 0.0086 0.0182 0.0304] \t\t\t\t\t self.std.exp() \n",
      "[3 3 4 4 5 5 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[131.064] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "900 th loss0 : 1677.3566, test rmse : 213.5778, test mnll: : 105.0311\n",
      "[35. 25. 22. 13.  9.  4.  2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0022 0.1675 0.081  0.2507 0.254  0.0219 0.4266] \t\t\t\t\t self.mu.exp() \n",
      "[0.0009 0.0014 0.0023 0.0076 0.0055 0.0182 0.0338] \t\t\t\t\t self.std.exp() \n",
      "[3 3 4 5 4 5 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[171.4048] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1000 th loss0 : 1336.7260, test rmse : 233.8114, test mnll: : 101.1952\n",
      "[49. 33. 30. 14.  7.  4.  1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0021 0.1681 0.0812 0.249  0.1907 0.0216 0.447 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0008 0.0014 0.0023 0.0069 0.0073 0.0182 0.0383] \t\t\t\t\t self.std.exp() \n",
      "[3 3 4 5 4 5 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[228.5036] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1100 th loss0 : 1130.4780, test rmse : 194.9786, test mnll: : 53.8115\n",
      "[67. 43. 41. 15.  6.  5.  1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0021 0.1684 0.0821 0.2495 0.1552 0.0214 0.4708] \t\t\t\t\t self.mu.exp() \n",
      "[0.0007 0.0015 0.0023 0.0064 0.0096 0.0182 0.0461] \t\t\t\t\t self.std.exp() \n",
      "[3 3 4 4 4 5 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[312.8431] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1200 th loss0 : 967.4261, test rmse : 234.1450, test mnll: : 56.2562\n",
      "[93. 56. 55. 14.  5.  4.  1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0021 0.0822 0.1681 0.2493 0.0212 0.1312 0.4869] \t\t\t\t\t self.mu.exp() \n",
      "[0.0006 0.0024 0.0016 0.0065 0.0183 0.0138 0.0584] \t\t\t\t\t self.std.exp() \n",
      "[3 4 3 4 4 5 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[433.5741] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1300 th loss0 : 837.9981, test rmse : 192.8179, test mnll: : 30.2445\n",
      "[127.  75.  69.  12.   6.   3.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.002  0.0818 0.168  0.244  0.021  0.112  0.4974] \t\t\t\t\t self.mu.exp() \n",
      "[0.0006 0.0022 0.0018 0.008  0.0184 0.0192 0.0733] \t\t\t\t\t self.std.exp() \n",
      "[3 4 3 5 4 5 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[594.0839] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1400 th loss0 : 765.9452, test rmse : 209.5163, test mnll: : 28.6241\n",
      "[175. 101.  84.   8.   6.   3.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0021 0.082  0.1687 0.229  0.0211 0.0996 0.4979] \t\t\t\t\t self.mu.exp() \n",
      "[0.0005 0.0023 0.0021 0.0129 0.0183 0.0201 0.0814] \t\t\t\t\t self.std.exp() \n",
      "[3 4 3 5 5 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[770.7723] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1500 th loss0 : 706.8895, test rmse : 196.4626, test mnll: : 22.5058\n",
      "[241. 134.  95.   7.   5.   3.   0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0021 0.0817 0.1672 0.0213 0.2034 0.0915 0.4976] \t\t\t\t\t self.mu.exp() \n",
      "[0.0005 0.0025 0.0023 0.0184 0.0218 0.0204 0.0831] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 4 5 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[916.7564] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1600 th loss0 : 665.7436, test rmse : 179.3008, test mnll: : 18.9893\n",
      "[335. 182. 103.   8.   4.   2.   0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.002  0.0816 0.1674 0.0217 0.1813 0.0875 0.4972] \t\t\t\t\t self.mu.exp() \n",
      "[0.0005 0.0026 0.0027 0.0185 0.0338 0.0203 0.0827] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 4 5 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[908.6282] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1700 th loss0 : 635.8752, test rmse : 170.7303, test mnll: : 19.9765\n",
      "[471. 253. 113.  10.   3.   2.   0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.002  0.0826 0.1687 0.0221 0.1672 0.0868 0.4988] \t\t\t\t\t self.mu.exp() \n",
      "[0.0004 0.0027 0.0029 0.0187 0.0451 0.02   0.083 ] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 5 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[707.6801] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1800 th loss0 : 606.5012, test rmse : 127.8630, test mnll: : 16.9312\n",
      "[670. 356. 124.  14.   2.   2.   0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0018 0.0831 0.1683 0.0236 0.0868 0.1642 0.4973] \t\t\t\t\t self.mu.exp() \n",
      "[0.0004 0.0028 0.0026 0.0176 0.0208 0.0519 0.0834] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 5 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[471.1457] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1900 th loss0 : 571.8269, test rmse : 121.4258, test mnll: : 19.1543\n",
      "[957. 503. 148.  25.   2.   1.   0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0017 0.0815 0.168  0.0212 0.0867 0.1628 0.4987] \t\t\t\t\t self.mu.exp() \n",
      "[0.0004 0.0026 0.0021 0.018  0.0199 0.0546 0.0841] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 5 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[290.7109] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2000 th loss0 : 545.5550, test rmse : 95.6705, test mnll: : 16.6320\n",
      "[1.364e+03 7.110e+02 1.840e+02 4.500e+01 1.000e+00 1.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0015 0.0827 0.1674 0.0208 0.0849 0.1588 0.501 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0003 0.0029 0.002  0.0167 0.0203 0.0574 0.0833] \t\t\t\t\t self.std.exp() \n",
      "[4 4 3 5 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[212.5666] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2100 th loss0 : 523.6114, test rmse : 101.2707, test mnll: : 19.0846\n",
      "[1.935e+03 8.090e+02 2.130e+02 7.200e+01 1.000e+00 1.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0015 0.0837 0.1684 0.0196 0.0855 0.1624 0.4971] \t\t\t\t\t self.mu.exp() \n",
      "[0.0004 0.0025 0.0021 0.0154 0.0209 0.0567 0.0828] \t\t\t\t\t self.std.exp() \n",
      "[4 4 3 5 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[164.6449] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2200 th loss0 : 514.0833, test rmse : 80.1880, test mnll: : 11.9432\n",
      "[2.719e+03 9.670e+02 2.330e+02 1.100e+02 1.000e+00 1.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0015 0.0824 0.1688 0.0171 0.0855 0.1639 0.5028] \t\t\t\t\t self.mu.exp() \n",
      "[0.0004 0.0023 0.002  0.0147 0.02   0.0527 0.0836] \t\t\t\t\t self.std.exp() \n",
      "[3 4 3 4 4 5 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[138.6973] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2300 th loss0 : 539.3123, test rmse : 96.6538, test mnll: : 11.3211\n",
      "[3.776e+03 1.064e+03 2.660e+02 1.550e+02 1.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0014 0.0826 0.1677 0.0155 0.0869 0.5    0.1672] \t\t\t\t\t self.mu.exp() \n",
      "[0.0004 0.0022 0.002  0.0128 0.0204 0.0837 0.0564] \t\t\t\t\t self.std.exp() \n",
      "[3 4 3 4 4 5 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[137.2719] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2400 th loss0 : 509.6764, test rmse : 79.9938, test mnll: : 10.6676\n",
      "[5.258e+03 1.176e+03 2.710e+02 2.190e+02 1.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0014 0.0826 0.1697 0.0157 0.087  0.4977 0.1643] \t\t\t\t\t self.mu.exp() \n",
      "[0.0004 0.0022 0.0018 0.0119 0.0206 0.0829 0.0563] \t\t\t\t\t self.std.exp() \n",
      "[3 4 3 4 4 5 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[127.2043] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2500 th loss0 : 505.7673, test rmse : 98.7565, test mnll: : 11.3165\n",
      "[7.299e+03 1.311e+03 2.880e+02 2.600e+02 1.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.0835 0.0151 0.1686 0.0849 0.4987 0.1616] \t\t\t\t\t self.mu.exp() \n",
      "[0.0005 0.0022 0.0108 0.0018 0.0207 0.0824 0.0561] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 3 4 5 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[131.8208] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2600 th loss0 : 504.6198, test rmse : 80.6837, test mnll: : 8.1474\n",
      "[9.988e+03 1.296e+03 3.580e+02 2.940e+02 1.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.0832 0.0151 0.1673 0.0857 0.4959 0.1619] \t\t\t\t\t self.mu.exp() \n",
      "[0.0005 0.0021 0.0099 0.0018 0.0197 0.0829 0.0555] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 3 4 5 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[121.6324] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2700 th loss0 : 499.6921, test rmse : 97.3059, test mnll: : 9.9888\n",
      "[1.3796e+04 1.4330e+03 4.1800e+02 3.2500e+02 1.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0014 0.0838 0.0155 0.1678 0.0857 0.4992 0.1597] \t\t\t\t\t self.mu.exp() \n",
      "[0.0006 0.0021 0.0089 0.002  0.0205 0.0831 0.052 ] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 3 4 5 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[117.9053] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800 th loss0 : 499.8825, test rmse : 102.0677, test mnll: : 8.0772\n",
      "[1.8758e+04 1.4170e+03 4.6000e+02 3.1600e+02 1.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0014 0.083  0.0154 0.1673 0.0885 0.4999 0.1618] \t\t\t\t\t self.mu.exp() \n",
      "[0.0007 0.0021 0.0078 0.002  0.0206 0.0829 0.0547] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 3 4 5 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[122.6724] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2900 th loss0 : 496.3945, test rmse : 83.8181, test mnll: : 8.3998\n",
      "[24646.  1403.   489.   321.     0.     0.     0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.0837 0.0154 0.1685 0.0862 0.4976 0.1626] \t\t\t\t\t self.mu.exp() \n",
      "[0.0008 0.0021 0.0073 0.002  0.0201 0.0831 0.054 ] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 3 4 5 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[116.4028] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3000 th loss0 : 493.5250, test rmse : 73.4788, test mnll: : 6.3581\n",
      "[32857.  1451.   496.   347.     0.     0.     0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.0833 0.0151 0.1661 0.0875 0.4975 0.1583] \t\t\t\t\t self.mu.exp() \n",
      "[0.0009 0.002  0.0071 0.002  0.0207 0.0825 0.0541] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 3 4 5 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[116.0048] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3100 th loss0 : 492.8251, test rmse : 73.4375, test mnll: : 6.5595\n",
      "[43515.  1482.   480.   366.     0.     0.     0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0012 0.0835 0.0159 0.1679 0.0878 0.4981 0.1598] \t\t\t\t\t self.mu.exp() \n",
      "[0.001  0.002  0.0064 0.0021 0.0202 0.0828 0.0578] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 3 4 5 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[114.7451] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3200 th loss0 : 491.8133, test rmse : 64.2762, test mnll: : 5.6134\n",
      "[56232.  1445.   406.   361.     0.     0.     0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.0834 0.0156 0.1676 0.0875 0.4985 0.1606] \t\t\t\t\t self.mu.exp() \n",
      "[0.0011 0.002  0.0062 0.0021 0.0206 0.0837 0.0572] \t\t\t\t\t self.std.exp() \n",
      "[3 4 5 3 4 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[111.688] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3300 th loss0 : 491.9757, test rmse : 68.0293, test mnll: : 5.8566\n",
      "[66986.  1459.   341.   309.     0.     0.     0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0012 0.0831 0.1678 0.0166 0.0868 0.4983 0.162 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0012 0.002  0.002  0.0062 0.0199 0.0829 0.0553] \t\t\t\t\t self.std.exp() \n",
      "[3 4 3 5 4 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[112.7677] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3400 th loss0 : 490.1304, test rmse : 48.8035, test mnll: : 5.4766\n",
      "[81813.  1565.   354.   244.     0.     0.     0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0011 0.0828 0.1681 0.0173 0.0879 0.4979 0.1638] \t\t\t\t\t self.mu.exp() \n",
      "[0.0013 0.0021 0.002  0.0063 0.0203 0.083  0.0564] \t\t\t\t\t self.std.exp() \n",
      "[3 4 3 4 4 5 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[116.395] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3500 th loss0 : 492.7386, test rmse : 53.2158, test mnll: : 6.1591\n",
      "[95963.  1484.   337.   187.     0.     0.     0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.001  0.0832 0.1685 0.0189 0.0873 0.4985 0.1608] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.002  0.0019 0.006  0.0208 0.0827 0.0557] \t\t\t\t\t self.std.exp() \n",
      "[3 4 3 4 4 5 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[115.7875] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3600 th loss0 : 492.0245, test rmse : 41.0996, test mnll: : 5.1773\n",
      "[110862.   1484.    325.    137.      0.      0.      0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.001  0.0837 0.1674 0.0201 0.0874 0.4981 0.163 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.0021 0.0018 0.0063 0.0207 0.0831 0.0554] \t\t\t\t\t self.std.exp() \n",
      "[3 4 3 4 4 5 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[115.8521] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3700 th loss0 : 490.6517, test rmse : 47.4204, test mnll: : 5.3769\n",
      "[1.2542e+05 1.4060e+03 3.5100e+02 1.0800e+02 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.001  0.083  0.1683 0.0201 0.0865 0.4984 0.1617] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.0021 0.002  0.0066 0.0207 0.0829 0.0559] \t\t\t\t\t self.std.exp() \n",
      "[3 4 3 4 4 5 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[116.6592] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3800 th loss0 : 501.1175, test rmse : 43.9513, test mnll: : 5.0475\n",
      "[1.3651e+05 1.4720e+03 3.4100e+02 1.0200e+02 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0009 0.0833 0.1685 0.0191 0.088  0.4979 0.1584] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.0022 0.002  0.0065 0.0206 0.0829 0.0548] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 4 4 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[118.9757] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3900 th loss0 : 490.2432, test rmse : 85.7250, test mnll: : 6.5360\n",
      "[1.4336e+05 1.5440e+03 3.1800e+02 9.7000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0009 0.0843 0.1672 0.0196 0.0876 0.4977 0.1648] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.0022 0.002  0.0064 0.0203 0.0829 0.0553] \t\t\t\t\t self.std.exp() \n",
      "[3 4 3 4 4 5 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[115.2813] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4000 th loss0 : 491.7494, test rmse : 42.4981, test mnll: : 5.1181\n",
      "[1.5676e+05 1.5540e+03 3.1000e+02 9.7000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0009 0.0835 0.1666 0.0198 0.0876 0.498  0.1592] \t\t\t\t\t self.mu.exp() \n",
      "[0.0017 0.0022 0.002  0.0068 0.0205 0.0829 0.0541] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 4 4 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[114.3189] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4100 th loss0 : 489.0134, test rmse : 49.4770, test mnll: : 5.3067\n",
      "[1.5644e+05 1.5630e+03 2.8500e+02 9.0000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0009 0.0834 0.1693 0.0205 0.0872 0.4981 0.1649] \t\t\t\t\t self.mu.exp() \n",
      "[0.0017 0.0021 0.002  0.0066 0.0206 0.0829 0.0575] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 4 4 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[112.4941] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4200 th loss0 : 489.6089, test rmse : 31.0586, test mnll: : 4.8262\n",
      "[1.5762e+05 1.5030e+03 2.8800e+02 7.9000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0009 0.0836 0.1674 0.0222 0.0878 0.498  0.1591] \t\t\t\t\t self.mu.exp() \n",
      "[0.0017 0.0021 0.002  0.007  0.0205 0.0828 0.0557] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 5 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[112.3411] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4300 th loss0 : 494.9988, test rmse : 34.6177, test mnll: : 4.9465\n",
      "[1.6992e+05 1.4660e+03 2.7700e+02 7.3000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0009 0.0841 0.169  0.0229 0.0871 0.4979 0.1614] \t\t\t\t\t self.mu.exp() \n",
      "[0.0017 0.002  0.0019 0.0078 0.0205 0.0829 0.0558] \t\t\t\t\t self.std.exp() \n",
      "[3 4 3 4 4 5 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[113.1886] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4400 th loss0 : 488.4199, test rmse : 36.5670, test mnll: : 4.9809\n",
      "[1.7942e+05 1.5290e+03 3.0700e+02 6.8000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0009 0.0834 0.1693 0.0228 0.0879 0.4982 0.1607] \t\t\t\t\t self.mu.exp() \n",
      "[0.0017 0.0019 0.002  0.008  0.0204 0.0829 0.0547] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 4 4 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[114.5899] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4500 th loss0 : 491.2616, test rmse : 29.3252, test mnll: : 4.8453\n",
      "[1.8043e+05 1.5470e+03 2.8700e+02 6.6000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0009 0.0835 0.1683 0.0232 0.088  0.4983 0.161 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0017 0.002  0.0019 0.0083 0.0207 0.0828 0.0555] \t\t\t\t\t self.std.exp() \n",
      "[3 4 3 4 4 5 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[115.1599] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4600 th loss0 : 500.5309, test rmse : 39.2778, test mnll: : 4.9126\n",
      "[1.7713e+05 1.5400e+03 3.0400e+02 6.3000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0008 0.0834 0.1666 0.024  0.0873 0.4982 0.1601] \t\t\t\t\t self.mu.exp() \n",
      "[0.0017 0.0022 0.002  0.0077 0.0206 0.0829 0.0556] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 4 4 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[110.6624] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4700 th loss0 : 488.6217, test rmse : 33.8310, test mnll: : 4.8429\n",
      "[1.8148e+05 1.5830e+03 2.8700e+02 6.3000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0008 0.0833 0.1674 0.0238 0.087  0.4982 0.1636] \t\t\t\t\t self.mu.exp() \n",
      "[0.0018 0.0021 0.002  0.0077 0.0206 0.0829 0.0568] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 4 4 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[117.1294] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4800 th loss0 : 492.2456, test rmse : 31.5333, test mnll: : 4.8844\n",
      "[1.9305e+05 1.4970e+03 2.8400e+02 6.1000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0008 0.0829 0.1679 0.0227 0.0879 0.4979 0.1605] \t\t\t\t\t self.mu.exp() \n",
      "[0.0017 0.002  0.002  0.0082 0.0205 0.0828 0.0555] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 4 4 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[111.1347] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4900 th loss0 : 491.5581, test rmse : 40.6077, test mnll: : 5.1267\n",
      "[1.8925e+05 1.4990e+03 2.8300e+02 6.1000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0008 0.0824 0.1675 0.0229 0.0872 0.4981 0.1612] \t\t\t\t\t self.mu.exp() \n",
      "[0.0017 0.0021 0.002  0.008  0.0205 0.0829 0.0542] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 4 4 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[117.1521] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "5000 th loss0 : 491.4176, test rmse : 30.1872, test mnll: : 4.8616\n",
      "[2.0082e+05 1.5470e+03 2.9000e+02 6.2000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0009 0.0829 0.1688 0.0232 0.0875 0.4981 0.1624] \t\t\t\t\t self.mu.exp() \n",
      "[0.0017 0.0021 0.002  0.0081 0.0204 0.0829 0.0556] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 4 4 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[112.4151] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "0 init loss: 47767.0168 \n",
      "0 model chosen \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "4 init loss: 35659.0786 \n",
      "4 model chosen \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "########################################################################################################################################################################################################\n",
      "equal_reg\n",
      "########################################################################################################################################################################################################\n",
      "0 th loss0 : 109749.2897, test rmse : 488.9480, test mnll: : 4733.4232\n",
      "[1. 1. 1. 1. 1. 1. 1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0777 0.0089 0.169  0.3429 0.4373 0.2408 0.0269] \t\t\t\t\t self.mu.exp() \n",
      "[0.0056 0.0012 0.006  0.0048 0.0243 0.016  0.0169] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[19.9218] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "100 th loss0 : 30441.1683, test rmse : 475.4545, test mnll: : 2744.3235\n",
      "[2. 2. 2. 2. 2. 2. 2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0786 0.0059 0.1721 0.3374 0.4684 0.2428 0.0257] \t\t\t\t\t self.mu.exp() \n",
      "[0.0051 0.0016 0.0047 0.005  0.0239 0.0166 0.0172] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[32.9623] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "200 th loss0 : 10718.7742, test rmse : 422.3023, test mnll: : 1705.0663\n",
      "[3. 3. 3. 2. 2. 2. 2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.079  0.0046 0.1681 0.3352 0.4766 0.247  0.0253] \t\t\t\t\t self.mu.exp() \n",
      "[0.0046 0.0019 0.0038 0.005  0.0239 0.0159 0.0171] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[41.3165] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "300 th loss0 : 10464.4524, test rmse : 377.7709, test mnll: : 1120.5907\n",
      "[5. 4. 3. 3. 3. 2. 2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0039 0.1677 0.0802 0.3362 0.243  0.4587 0.0242] \t\t\t\t\t self.mu.exp() \n",
      "[0.0019 0.0031 0.004  0.0045 0.0149 0.025  0.0176] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[50.1788] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "400 th loss0 : 6840.2073, test rmse : 345.4701, test mnll: : 768.9781\n",
      "[7. 5. 5. 4. 3. 2. 2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0034 0.0808 0.1685 0.3335 0.2471 0.4438 0.0238] \t\t\t\t\t self.mu.exp() \n",
      "[0.0018 0.0034 0.0025 0.0041 0.0146 0.0261 0.0176] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[60.5048] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "500 th loss0 : 4741.3306, test rmse : 322.3105, test mnll: : 558.9830\n",
      "[9. 7. 6. 5. 4. 3. 2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.003  0.1681 0.0803 0.3336 0.2543 0.4401 0.0238] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.0022 0.003  0.0038 0.0132 0.0264 0.0175] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[72.0473] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "600 th loss0 : 3732.1666, test rmse : 290.7227, test mnll: : 383.1792\n",
      "[13. 10.  9.  6.  5.  3.  2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0027 0.1676 0.0812 0.3321 0.2475 0.449  0.0234] \t\t\t\t\t self.mu.exp() \n",
      "[0.0015 0.0018 0.0027 0.0036 0.012  0.0273 0.0175] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[87.1169] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "700 th loss0 : 2656.8149, test rmse : 246.3298, test mnll: : 224.0819\n",
      "[18. 14. 12.  8.  7.  3.  2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0025 0.1684 0.0814 0.3316 0.2479 0.0231 0.4403] \t\t\t\t\t self.mu.exp() \n",
      "[0.0013 0.0017 0.0026 0.0038 0.0108 0.0176 0.0286] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[106.5343] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "800 th loss0 : 2164.6522, test rmse : 256.3043, test mnll: : 193.4916\n",
      "[25. 18. 16. 10.  9.  3.  2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0023 0.1683 0.0822 0.3289 0.2517 0.0227 0.4353] \t\t\t\t\t self.mu.exp() \n",
      "[0.0012 0.0015 0.0024 0.0042 0.0096 0.0176 0.0303] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[134.5437] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "900 th loss0 : 1696.7117, test rmse : 268.0479, test mnll: : 164.6806\n",
      "[34. 25. 22. 11.  9.  3.  2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0022 0.168  0.0812 0.2497 0.2475 0.0224 0.4426] \t\t\t\t\t self.mu.exp() \n",
      "[0.0011 0.0015 0.0023 0.0082 0.0057 0.0177 0.0323] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[175.2283] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1000 th loss0 : 1470.5083, test rmse : 246.7369, test mnll: : 108.6749\n",
      "[48. 34. 31. 12.  7.  4.  1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0021 0.168  0.0817 0.2499 0.1883 0.0222 0.4503] \t\t\t\t\t self.mu.exp() \n",
      "[0.001  0.0014 0.0022 0.0072 0.0075 0.0176 0.0375] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[234.4855] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1100 th loss0 : 1159.7404, test rmse : 230.6294, test mnll: : 71.5369\n",
      "[66. 43. 42. 14.  6.  4.  1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.002  0.1675 0.0816 0.2462 0.1524 0.022  0.4721] \t\t\t\t\t self.mu.exp() \n",
      "[0.0009 0.0016 0.0021 0.0066 0.0097 0.0177 0.046 ] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[320.8119] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1200 th loss0 : 977.0536, test rmse : 222.2490, test mnll: : 50.8717\n",
      "[90. 57. 56. 13.  4.  4.  1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.002  0.0818 0.1678 0.2486 0.1291 0.0217 0.4882] \t\t\t\t\t self.mu.exp() \n",
      "[0.0008 0.0023 0.0017 0.007  0.0139 0.0177 0.0594] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[446.5066] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1300 th loss0 : 850.8638, test rmse : 195.0732, test mnll: : 30.4845\n",
      "[124.  77.  71.  10.   5.   3.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.002  0.0818 0.1683 0.2431 0.0215 0.1109 0.497 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0007 0.0023 0.0019 0.0087 0.0178 0.0189 0.073 ] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[610.9332] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1400 th loss0 : 804.9796, test rmse : 234.7914, test mnll: : 33.4095\n",
      "[170. 103.  84.   7.   5.   3.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0021 0.0823 0.1678 0.2329 0.0216 0.0978 0.4985] \t\t\t\t\t self.mu.exp() \n",
      "[0.0007 0.0024 0.0022 0.0139 0.0178 0.0212 0.0814] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[796.4952] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1500 th loss0 : 714.5417, test rmse : 198.9082, test mnll: : 22.2099\n",
      "[234. 137.  95.   6.   5.   3.   0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0021 0.0817 0.1684 0.0218 0.2054 0.0904 0.4976] \t\t\t\t\t self.mu.exp() \n",
      "[0.0006 0.0025 0.0026 0.0179 0.0227 0.0206 0.0829] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[951.8772] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600 th loss0 : 670.9090, test rmse : 193.0267, test mnll: : 20.6072\n",
      "[325. 185. 101.   6.   3.   3.   0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.002  0.0815 0.1686 0.0222 0.0871 0.1834 0.498 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0006 0.0024 0.0027 0.018  0.0204 0.0352 0.0829] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[955.3034] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1700 th loss0 : 646.7108, test rmse : 168.6045, test mnll: : 18.7585\n",
      "[457. 256. 110.   7.   2.   2.   0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.002  0.0822 0.1678 0.0234 0.0863 0.1704 0.4985] \t\t\t\t\t self.mu.exp() \n",
      "[0.0005 0.0028 0.0029 0.0179 0.0208 0.0476 0.083 ] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[764.6802] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1800 th loss0 : 607.9060, test rmse : 133.2236, test mnll: : 16.7774\n",
      "[650. 358. 121.  10.   2.   2.   0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0018 0.0829 0.1698 0.0252 0.0856 0.1648 0.4979] \t\t\t\t\t self.mu.exp() \n",
      "[0.0005 0.0027 0.0026 0.0175 0.0205 0.0525 0.0835] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[525.9667] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1900 th loss0 : 577.2746, test rmse : 126.2372, test mnll: : 19.2369\n",
      "[931. 502. 136.  17.   2.   1.   0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0017 0.082  0.1691 0.0256 0.0832 0.1582 0.4976] \t\t\t\t\t self.mu.exp() \n",
      "[0.0004 0.0027 0.0022 0.0174 0.0213 0.0558 0.084 ] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[351.4651] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2000 th loss0 : 566.2522, test rmse : 101.7074, test mnll: : 16.0849\n",
      "[1.331e+03 6.560e+02 1.500e+02 2.900e+01 2.000e+00 1.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0015 0.0833 0.1683 0.0232 0.0838 0.1619 0.4999] \t\t\t\t\t self.mu.exp() \n",
      "[0.0004 0.0025 0.0021 0.0176 0.0209 0.0545 0.0816] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[255.7774] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2100 th loss0 : 550.6896, test rmse : 104.7604, test mnll: : 16.6022\n",
      "[1.899e+03 8.170e+02 1.890e+02 4.800e+01 1.000e+00 1.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0015 0.0825 0.1681 0.0217 0.0839 0.1591 0.4971] \t\t\t\t\t self.mu.exp() \n",
      "[0.0004 0.0026 0.0022 0.018  0.0213 0.052  0.0825] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[198.5617] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2200 th loss0 : 538.5501, test rmse : 105.7611, test mnll: : 16.6831\n",
      "[2.703e+03 9.340e+02 1.890e+02 7.400e+01 1.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0014 0.0828 0.1664 0.0199 0.0865 0.5017 0.1656] \t\t\t\t\t self.mu.exp() \n",
      "[0.0005 0.0023 0.002  0.0168 0.021  0.0842 0.0549] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[168.4253] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2300 th loss0 : 546.0150, test rmse : 87.8634, test mnll: : 15.0493\n",
      "[3.833e+03 1.067e+03 2.030e+02 1.110e+02 1.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.0835 0.1683 0.0195 0.0879 0.4989 0.1573] \t\t\t\t\t self.mu.exp() \n",
      "[0.0005 0.0022 0.002  0.0152 0.0201 0.0821 0.0526] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[163.709] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2400 th loss0 : 530.2956, test rmse : 69.6885, test mnll: : 12.1016\n",
      "[5.391e+03 1.162e+03 2.240e+02 1.520e+02 1.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.0826 0.168  0.0174 0.0865 0.5    0.1624] \t\t\t\t\t self.mu.exp() \n",
      "[0.0006 0.0021 0.002  0.0167 0.0207 0.084  0.0567] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[133.9731] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2500 th loss0 : 502.3699, test rmse : 67.6784, test mnll: : 9.4713\n",
      "[7.517e+03 1.249e+03 2.230e+02 2.020e+02 1.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.0825 0.1691 0.0175 0.0847 0.4957 0.1615] \t\t\t\t\t self.mu.exp() \n",
      "[0.0007 0.0021 0.0019 0.0156 0.0212 0.085  0.0564] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[125.9302] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2600 th loss0 : 497.6124, test rmse : 107.7336, test mnll: : 11.5180\n",
      "[1.0415e+04 1.2670e+03 2.5700e+02 2.4500e+02 1.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0014 0.0838 0.1676 0.0171 0.0843 0.5    0.1597] \t\t\t\t\t self.mu.exp() \n",
      "[0.001  0.0021 0.0021 0.0147 0.0211 0.0826 0.0565] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[119.1515] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2700 th loss0 : 498.6492, test rmse : 69.9506, test mnll: : 6.5828\n",
      "[1.443e+04 1.374e+03 2.600e+02 2.520e+02 1.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0014 0.0834 0.017  0.1666 0.0853 0.4971 0.1639] \t\t\t\t\t self.mu.exp() \n",
      "[0.0012 0.0021 0.0135 0.002  0.0202 0.0839 0.0574] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[117.9194] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2800 th loss0 : 493.1278, test rmse : 81.9806, test mnll: : 6.7572\n",
      "[1.9585e+04 1.3900e+03 2.5600e+02 2.5200e+02 1.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0014 0.0835 0.016  0.1692 0.0868 0.5004 0.1665] \t\t\t\t\t self.mu.exp() \n",
      "[0.0014 0.0021 0.0119 0.0019 0.0211 0.0832 0.0587] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[116.9015] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2900 th loss0 : 490.1435, test rmse : 69.9749, test mnll: : 6.7558\n",
      "[2.5646e+04 1.3910e+03 2.6800e+02 2.4100e+02 1.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0014 0.0827 0.1679 0.0164 0.0861 0.4985 0.1636] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.002  0.0019 0.0113 0.0205 0.0826 0.059 ] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[119.3502] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3000 th loss0 : 493.3657, test rmse : 60.5206, test mnll: : 5.7650\n",
      "[33335.  1479.   260.   210.     0.     0.     0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0014 0.0824 0.1675 0.0176 0.0887 0.4988 0.1665] \t\t\t\t\t self.mu.exp() \n",
      "[0.0018 0.002  0.0019 0.0099 0.0199 0.0835 0.0582] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[114.9065] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3100 th loss0 : 491.8079, test rmse : 37.2086, test mnll: : 5.1695\n",
      "[44113.  1489.   277.   165.     0.     0.     0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0014 0.0835 0.1672 0.0188 0.087  0.4984 0.1588] \t\t\t\t\t self.mu.exp() \n",
      "[0.0019 0.002  0.0019 0.0092 0.0202 0.0832 0.0556] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[114.5137] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3200 th loss0 : 490.5997, test rmse : 46.2318, test mnll: : 5.4043\n",
      "[56045.  1460.   287.   131.     0.     0.     0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0014 0.0824 0.168  0.022  0.0869 0.4985 0.1612] \t\t\t\t\t self.mu.exp() \n",
      "[0.002  0.002  0.0019 0.0086 0.0204 0.0831 0.0554] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[112.7401] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3300 th loss0 : 489.0384, test rmse : 57.2103, test mnll: : 5.4003\n",
      "[68616.  1541.   285.    97.     0.     0.     0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0014 0.0839 0.1679 0.0214 0.0873 0.4982 0.1605] \t\t\t\t\t self.mu.exp() \n",
      "[0.0021 0.0021 0.0019 0.0084 0.0204 0.0831 0.0553] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[114.6035] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3400 th loss0 : 490.8612, test rmse : 50.3154, test mnll: : 5.5580\n",
      "[77441.  1480.   280.    81.     0.     0.     0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.0831 0.1686 0.0226 0.0869 0.4983 0.1646] \t\t\t\t\t self.mu.exp() \n",
      "[0.0021 0.0021 0.0018 0.0079 0.0202 0.083  0.0564] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[110.4193] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3500 th loss0 : 489.1387, test rmse : 34.9555, test mnll: : 4.8851\n",
      "[8.6494e+04 1.4010e+03 3.0100e+02 6.6000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0012 0.0831 0.1674 0.023  0.0879 0.498  0.1614] \t\t\t\t\t self.mu.exp() \n",
      "[0.0021 0.002  0.002  0.0075 0.0206 0.083  0.0557] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[112.6773] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3600 th loss0 : 490.3481, test rmse : 35.3725, test mnll: : 4.9891\n",
      "[9.4215e+04 1.3630e+03 2.9200e+02 5.9000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0012 0.0832 0.1661 0.0247 0.0861 0.4978 0.1631] \t\t\t\t\t self.mu.exp() \n",
      "[0.002  0.0019 0.0019 0.0079 0.0205 0.083  0.0557] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[111.4126] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3700 th loss0 : 488.4896, test rmse : 36.6737, test mnll: : 5.0878\n",
      "[1.0768e+05 1.4000e+03 2.8500e+02 6.0000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0012 0.0827 0.1686 0.0223 0.0877 0.4985 0.1633] \t\t\t\t\t self.mu.exp() \n",
      "[0.0019 0.002  0.002  0.0079 0.0204 0.0831 0.0559] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[111.5714] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3800 th loss0 : 491.2284, test rmse : 57.3664, test mnll: : 5.2456\n",
      "[1.1738e+05 1.4300e+03 3.1900e+02 6.2000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0011 0.0834 0.1667 0.0234 0.0863 0.4977 0.1631] \t\t\t\t\t self.mu.exp() \n",
      "[0.002  0.002  0.0021 0.0075 0.0204 0.0832 0.0571] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[111.4672] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3900 th loss0 : 491.6969, test rmse : 38.4763, test mnll: : 4.9343\n",
      "[1.1861e+05 1.5680e+03 2.8700e+02 5.9000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0011 0.0836 0.1679 0.0245 0.0871 0.4971 0.1642] \t\t\t\t\t self.mu.exp() \n",
      "[0.0019 0.0021 0.002  0.0079 0.0204 0.0828 0.0569] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[114.436] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4000 th loss0 : 488.8193, test rmse : 36.3210, test mnll: : 5.4438\n",
      "[1.2617e+05 1.4930e+03 2.6800e+02 6.1000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0011 0.0834 0.1686 0.0226 0.0875 0.4982 0.162 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0018 0.002  0.0018 0.0075 0.0205 0.0831 0.055 ] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[112.6779] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4100 th loss0 : 488.7936, test rmse : 32.6189, test mnll: : 4.8251\n",
      "[1.2909e+05 1.5790e+03 2.9600e+02 6.1000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0011 0.0828 0.1671 0.0228 0.0871 0.4985 0.1614] \t\t\t\t\t self.mu.exp() \n",
      "[0.0017 0.002  0.002  0.008  0.0204 0.0829 0.0569] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[118.1804] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4200 th loss0 : 488.8584, test rmse : 34.3641, test mnll: : 4.9386\n",
      "[1.3247e+05 1.6210e+03 3.0800e+02 5.8000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0011 0.0838 0.1691 0.0234 0.0868 0.498  0.1594] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.0021 0.002  0.0075 0.0203 0.083  0.0542] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[116.236] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4300 th loss0 : 489.9880, test rmse : 36.6984, test mnll: : 5.0735\n",
      "[1.3894e+05 1.5790e+03 3.2000e+02 5.3000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0011 0.0827 0.1691 0.0237 0.0873 0.498  0.1617] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.002  0.0021 0.0079 0.0206 0.0827 0.0557] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[113.3098] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4400 th loss0 : 489.5272, test rmse : 26.1216, test mnll: : 4.7040\n",
      "[1.4173e+05 1.5550e+03 2.9900e+02 5.9000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0011 0.0831 0.1677 0.0232 0.0877 0.4983 0.1601] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.002  0.0021 0.0077 0.0205 0.0832 0.0544] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[110.7969] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4500 th loss0 : 489.8402, test rmse : 30.7930, test mnll: : 4.8553\n",
      "[1.4512e+05 1.4800e+03 2.9700e+02 5.8000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0012 0.0828 0.1687 0.0232 0.0878 0.4984 0.1614] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.002  0.002  0.0077 0.0206 0.0829 0.0553] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[111.7594] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4600 th loss0 : 489.4977, test rmse : 35.5841, test mnll: : 4.9756\n",
      "[1.4993e+05 1.5700e+03 2.8100e+02 6.0000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0011 0.0827 0.1683 0.0234 0.0882 0.4981 0.1614] \t\t\t\t\t self.mu.exp() \n",
      "[0.0017 0.002  0.0018 0.0075 0.0204 0.0829 0.0562] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[118.9434] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4700 th loss0 : 494.2548, test rmse : 41.4732, test mnll: : 4.9941\n",
      "[1.4879e+05 1.5600e+03 2.8300e+02 5.5000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.001  0.0831 0.1678 0.0241 0.0873 0.4981 0.1619] \t\t\t\t\t self.mu.exp() \n",
      "[0.0017 0.002  0.0019 0.0077 0.0206 0.083  0.0559] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[111.0484] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4800 th loss0 : 491.8418, test rmse : 32.5943, test mnll: : 4.9871\n",
      "[1.5056e+05 1.5420e+03 2.8800e+02 5.7000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.001  0.084  0.1675 0.0247 0.0873 0.498  0.1617] \t\t\t\t\t self.mu.exp() \n",
      "[0.0017 0.0021 0.0019 0.0078 0.0205 0.083  0.0554] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[112.8827] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4900 th loss0 : 490.2410, test rmse : 33.7429, test mnll: : 4.9434\n",
      "[1.5205e+05 1.5050e+03 2.7600e+02 5.6000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0008 0.0833 0.1671 0.0235 0.0872 0.4982 0.1617] \t\t\t\t\t self.mu.exp() \n",
      "[0.0018 0.0021 0.0019 0.0075 0.0207 0.0828 0.0557] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[109.9137] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "5000 th loss0 : 490.5413, test rmse : 30.3591, test mnll: : 4.8857\n",
      "[1.565e+05 1.436e+03 2.970e+02 5.500e+01 0.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0008 0.0834 0.1689 0.0228 0.0881 0.4979 0.1642] \t\t\t\t\t self.mu.exp() \n",
      "[0.0018 0.0021 0.0019 0.0077 0.0205 0.0829 0.0562] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[113.0525] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "##################################################\n",
      "#1 th experimnet\n",
      "0 init loss: 69845.3055 \n",
      "0 model chosen \n",
      "1 init loss: 69845.3055 \n",
      "1 model chosen \n",
      "2 init loss: 69845.3055 \n",
      "2 model chosen \n",
      "3 init loss: 69845.3055 \n",
      "3 model chosen \n",
      "4 init loss: 69845.3055 \n",
      "4 model chosen \n",
      "5 init loss: 69845.3055 \n",
      "5 model chosen \n",
      "6 init loss: 69845.3055 \n",
      "6 model chosen \n",
      "7 init loss: 69845.3055 \n",
      "7 model chosen \n",
      "8 init loss: 69845.3055 \n",
      "8 model chosen \n",
      "9 init loss: 69845.3055 \n",
      "9 model chosen \n",
      "########################################################################################################################################################################################################\n",
      "gpsm\n",
      "########################################################################################################################################################################################################\n",
      "0 th loss0 : 68610.2436, test rmse : 548.6889, test mnll: : 5396.9090\n",
      "100 th loss0 : 23147.9179, test rmse : 466.0691, test mnll: : 2811.4016\n",
      "200 th loss0 : 13501.1598, test rmse : 403.4500, test mnll: : 1762.8230\n",
      "300 th loss0 : 8993.4106, test rmse : 363.8111, test mnll: : 1230.2795\n",
      "400 th loss0 : 6316.6051, test rmse : 336.3120, test mnll: : 901.5790\n",
      "500 th loss0 : 4547.9233, test rmse : 314.2756, test mnll: : 669.9586\n",
      "600 th loss0 : 3329.5610, test rmse : 294.6666, test mnll: : 497.3382\n",
      "700 th loss0 : 2479.8917, test rmse : 276.6495, test mnll: : 368.1584\n",
      "800 th loss0 : 1884.4116, test rmse : 260.6387, test mnll: : 273.1831\n",
      "900 th loss0 : 1463.9326, test rmse : 247.2320, test mnll: : 206.6995\n",
      "1000 th loss0 : 1163.8413, test rmse : 236.6124, test mnll: : 163.2603\n",
      "1100 th loss0 : 948.4735, test rmse : 228.3563, test mnll: : 128.9476\n",
      "1200 th loss0 : 792.4454, test rmse : 221.7597, test mnll: : 104.0475\n",
      "1300 th loss0 : 678.0095, test rmse : 216.2779, test mnll: : 86.2992\n",
      "1400 th loss0 : 592.3073, test rmse : 211.6453, test mnll: : 73.7361\n",
      "1500 th loss0 : 526.9448, test rmse : 207.6750, test mnll: : 64.0259\n",
      "1600 th loss0 : 478.3945, test rmse : 204.3182, test mnll: : 54.5982\n",
      "1700 th loss0 : 444.4242, test rmse : 201.5559, test mnll: : 43.9977\n",
      "1800 th loss0 : 418.7983, test rmse : 202.9331, test mnll: : 35.3625\n",
      "1900 th loss0 : 400.9883, test rmse : 203.4127, test mnll: : 28.8724\n",
      "2000 th loss0 : 389.1621, test rmse : 201.5918, test mnll: : 23.3922\n",
      "2100 th loss0 : 380.9486, test rmse : 198.5394, test mnll: : 19.1370\n",
      "2200 th loss0 : 375.2527, test rmse : 194.4879, test mnll: : 15.9237\n",
      "2300 th loss0 : 371.3003, test rmse : 188.7532, test mnll: : 13.5273\n",
      "2400 th loss0 : 368.4995, test rmse : 180.0406, test mnll: : 11.7876\n",
      "2500 th loss0 : 366.3400, test rmse : 165.7714, test mnll: : 10.5243\n",
      "2600 th loss0 : 364.3763, test rmse : 144.3577, test mnll: : 9.3843\n",
      "2700 th loss0 : 362.4662, test rmse : 121.0343, test mnll: : 8.0692\n",
      "2800 th loss0 : 360.8373, test rmse : 97.5744, test mnll: : 7.0400\n",
      "2900 th loss0 : 359.5810, test rmse : 76.9403, test mnll: : 6.2264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 th loss0 : 358.7067, test rmse : 59.6266, test mnll: : 5.6209\n",
      "3100 th loss0 : 358.1969, test rmse : 46.5666, test mnll: : 5.1947\n",
      "3200 th loss0 : 357.9172, test rmse : 38.4401, test mnll: : 4.9468\n",
      "3300 th loss0 : 357.7806, test rmse : 33.6540, test mnll: : 4.8084\n",
      "3400 th loss0 : 357.7148, test rmse : 30.6440, test mnll: : 4.7261\n",
      "3500 th loss0 : 357.6888, test rmse : 28.8820, test mnll: : 4.6803\n",
      "3600 th loss0 : 357.6842, test rmse : 28.0920, test mnll: : 4.6611\n",
      "3700 th loss0 : 357.6825, test rmse : 27.5980, test mnll: : 4.6471\n",
      "3800 th loss0 : 357.6829, test rmse : 27.5216, test mnll: : 4.6464\n",
      "3900 th loss0 : 357.6809, test rmse : 27.5174, test mnll: : 4.6448\n",
      "4000 th loss0 : 357.6809, test rmse : 27.5897, test mnll: : 4.6472\n",
      "4100 th loss0 : 357.6809, test rmse : 27.5163, test mnll: : 4.6448\n",
      "4200 th loss0 : 357.6809, test rmse : 27.5310, test mnll: : 4.6454\n",
      "4300 th loss0 : 357.6819, test rmse : 27.5627, test mnll: : 4.6463\n",
      "4400 th loss0 : 357.6838, test rmse : 27.6023, test mnll: : 4.6477\n",
      "4500 th loss0 : 357.6807, test rmse : 27.5796, test mnll: : 4.6470\n",
      "4600 th loss0 : 357.6848, test rmse : 27.4643, test mnll: : 4.6429\n",
      "4700 th loss0 : 357.6809, test rmse : 27.5150, test mnll: : 4.6448\n",
      "4800 th loss0 : 357.6807, test rmse : 27.5505, test mnll: : 4.6461\n",
      "4900 th loss0 : 357.6809, test rmse : 27.5607, test mnll: : 4.6462\n",
      "5000 th loss0 : 357.6811, test rmse : 27.5803, test mnll: : 4.6470\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "0 init loss: 79028.5913 \n",
      "0 model chosen \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "3 init loss: 75169.3063 \n",
      "3 model chosen \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "5 init loss: 73211.8048 \n",
      "5 model chosen \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "########################################################################################################################################################################################################\n",
      "weight_reg\n",
      "########################################################################################################################################################################################################\n",
      "0 th loss0 : 84098.8837, test rmse : 567.9489, test mnll: : 6174.7453\n",
      "[1. 1. 1. 1. 1. 1. 1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.1705 0.008  0.0772 0.3498 0.2513 0.4308 0.0292] \t\t\t\t\t self.mu.exp() \n",
      "[0.0069 0.0013 0.0058 0.0102 0.008  0.0083 0.0095] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[20.3014] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "100 th loss0 : 28124.2667, test rmse : 390.5671, test mnll: : 1901.7938\n",
      "[2. 2. 2. 2. 2. 2. 2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.1723 0.0054 0.0772 0.3463 0.2495 0.4244 0.0269] \t\t\t\t\t self.mu.exp() \n",
      "[0.0058 0.0016 0.0049 0.0101 0.0073 0.0084 0.0099] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[31.7683] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "200 th loss0 : 21629.1608, test rmse : 401.5265, test mnll: : 1605.1127\n",
      "[3. 3. 2. 2. 2. 2. 2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.1702 0.0044 0.0795 0.3475 0.2487 0.4221 0.0252] \t\t\t\t\t self.mu.exp() \n",
      "[0.0049 0.0017 0.0043 0.0098 0.0066 0.0079 0.0102] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[39.6677] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "300 th loss0 : 11024.1587, test rmse : 313.8722, test mnll: : 803.2650\n",
      "[5. 3. 3. 3. 3. 3. 2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0038 0.1716 0.0796 0.3358 0.2505 0.4217 0.024 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0017 0.004  0.0039 0.0093 0.0059 0.0074 0.0102] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 4 4 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[46.6478] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "400 th loss0 : 6371.0630, test rmse : 326.6988, test mnll: : 721.1697\n",
      "[7. 5. 4. 4. 4. 3. 3.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0033 0.1664 0.081  0.3301 0.2513 0.4151 0.0228] \t\t\t\t\t self.mu.exp() \n",
      "[0.0015 0.0033 0.0034 0.0086 0.0052 0.007  0.0102] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 5 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[55.9052] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "500 th loss0 : 6643.7145, test rmse : 294.7320, test mnll: : 495.6092\n",
      "[9. 7. 6. 5. 5. 4. 4.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0029 0.1686 0.0814 0.3341 0.2494 0.417  0.0217] \t\t\t\t\t self.mu.exp() \n",
      "[0.0014 0.0028 0.0029 0.0079 0.0045 0.0068 0.0106] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 5 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[65.3714] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "600 th loss0 : 4010.6724, test rmse : 244.8144, test mnll: : 288.4939\n",
      "[13. 10.  8.  6.  6.  5.  4.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0027 0.169  0.0816 0.3333 0.2491 0.0204 0.4221] \t\t\t\t\t self.mu.exp() \n",
      "[0.0012 0.0023 0.0026 0.0072 0.0041 0.0106 0.0065] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 5 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[77.4683] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "700 th loss0 : 2590.1340, test rmse : 266.2196, test mnll: : 291.3311\n",
      "[17. 13. 11.  8.  8.  6.  5.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0025 0.1677 0.0811 0.3337 0.2508 0.0192 0.4225] \t\t\t\t\t self.mu.exp() \n",
      "[0.0011 0.002  0.0025 0.0066 0.0038 0.0106 0.0063] \t\t\t\t\t self.std.exp() \n",
      "[3 3 4 5 4 5 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[92.1129] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "800 th loss0 : 1979.7212, test rmse : 234.2998, test mnll: : 184.0229\n",
      "[24. 18. 16. 11. 11.  7.  5.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0023 0.168  0.0817 0.3379 0.2505 0.0178 0.4208] \t\t\t\t\t self.mu.exp() \n",
      "[0.001  0.0017 0.0023 0.0061 0.0036 0.0106 0.0063] \t\t\t\t\t self.std.exp() \n",
      "[3 3 4 5 4 5 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[110.7115] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "900 th loss0 : 1575.3454, test rmse : 228.7876, test mnll: : 141.5879\n",
      "[33. 24. 22. 14. 14. 10.  5.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0022 0.1687 0.082  0.3334 0.2514 0.0165 0.418 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0009 0.0015 0.0023 0.0059 0.0034 0.0108 0.0066] \t\t\t\t\t self.std.exp() \n",
      "[3 3 4 5 4 5 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[133.8061] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1000 th loss0 : 1329.5878, test rmse : 243.5614, test mnll: : 133.8428\n",
      "[45. 33. 31. 18. 17. 14.  5.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0021 0.1684 0.0811 0.2483 0.338  0.0153 0.4141] \t\t\t\t\t self.mu.exp() \n",
      "[0.0009 0.0014 0.0024 0.0033 0.0054 0.0105 0.0082] \t\t\t\t\t self.std.exp() \n",
      "[3 3 4 4 5 5 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[165.1105] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1100 th loss0 : 1032.1497, test rmse : 240.3596, test mnll: : 102.2409\n",
      "[62. 44. 43. 20. 20. 18.  3.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0021 0.1684 0.0818 0.2497 0.0142 0.3333 0.4163] \t\t\t\t\t self.mu.exp() \n",
      "[0.0008 0.0014 0.0025 0.0035 0.0101 0.0052 0.012 ] \t\t\t\t\t self.std.exp() \n",
      "[3 3 4 4 5 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[205.8967] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1200 th loss0 : 912.3842, test rmse : 235.7019, test mnll: : 83.0462\n",
      "[84. 59. 58. 28. 21. 18.  2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.002  0.082  0.1691 0.0128 0.2506 0.3317 0.4043] \t\t\t\t\t self.mu.exp() \n",
      "[0.0007 0.0027 0.0015 0.01   0.0037 0.0049 0.0201] \t\t\t\t\t self.std.exp() \n",
      "[3 4 3 5 4 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[250.7993] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1300 th loss0 : 753.9096, test rmse : 215.9240, test mnll: : 56.0867\n",
      "[115.  82.  76.  39.  20.  15.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.002  0.0818 0.1677 0.0116 0.2497 0.3303 0.3733] \t\t\t\t\t self.mu.exp() \n",
      "[0.0007 0.0027 0.0016 0.0095 0.0041 0.0051 0.0344] \t\t\t\t\t self.std.exp() \n",
      "[3 4 3 5 4 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[298.8374] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1400 th loss0 : 715.3137, test rmse : 201.2138, test mnll: : 44.5374\n",
      "[157. 114.  95.  57.  17.  13.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.002  0.082  0.1679 0.0107 0.2485 0.3335 0.3347] \t\t\t\t\t self.mu.exp() \n",
      "[0.0006 0.0028 0.0016 0.0092 0.0047 0.006  0.0537] \t\t\t\t\t self.std.exp() \n",
      "[3 4 3 5 4 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[331.1446] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 th loss0 : 643.6860, test rmse : 183.9375, test mnll: : 36.7009\n",
      "[215. 159. 117.  83.  14.  10.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0019 0.0828 0.1683 0.0101 0.251  0.3327 0.3072] \t\t\t\t\t self.mu.exp() \n",
      "[0.0006 0.0028 0.0018 0.0091 0.0055 0.0073 0.0765] \t\t\t\t\t self.std.exp() \n",
      "[3 4 3 5 4 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[327.3572] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1600 th loss0 : 582.1300, test rmse : 194.9521, test mnll: : 40.8798\n",
      "[296. 223. 140. 120.  13.   9.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0019 0.0819 0.1687 0.0092 0.2478 0.3356 0.2892] \t\t\t\t\t self.mu.exp() \n",
      "[0.0005 0.0027 0.0018 0.0085 0.0059 0.0093 0.0899] \t\t\t\t\t self.std.exp() \n",
      "[3 4 3 5 4 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[263.0243] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1700 th loss0 : 526.5152, test rmse : 160.6444, test mnll: : 32.3558\n",
      "[408. 317. 188. 179.  15.  10.   0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0018 0.0824 0.1675 0.0092 0.2501 0.3321 0.2841] \t\t\t\t\t self.mu.exp() \n",
      "[0.0005 0.0027 0.0018 0.0085 0.0052 0.0096 0.0945] \t\t\t\t\t self.std.exp() \n",
      "[3 4 3 5 4 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[180.0241] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1800 th loss0 : 489.8678, test rmse : 179.2238, test mnll: : 45.1521\n",
      "[569. 448. 260. 220.  19.  15.   0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0018 0.0821 0.0104 0.1677 0.249  0.3328 0.2704] \t\t\t\t\t self.mu.exp() \n",
      "[0.0004 0.0026 0.0078 0.0019 0.0042 0.0074 0.1006] \t\t\t\t\t self.std.exp() \n",
      "[3 4 5 3 4 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[108.0895] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1900 th loss0 : 465.6362, test rmse : 145.6888, test mnll: : 28.0038\n",
      "[789. 639. 370. 272.  22.  20.   0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0018 0.0831 0.0109 0.167  0.334  0.2482 0.2845] \t\t\t\t\t self.mu.exp() \n",
      "[0.0004 0.0026 0.0072 0.0019 0.0053 0.0032 0.0998] \t\t\t\t\t self.std.exp() \n",
      "[3 4 5 3 4 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[76.009] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2000 th loss0 : 455.3523, test rmse : 176.0904, test mnll: : 28.8894\n",
      "[1091.  828.  513.  310.   26.   24.    0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0017 0.083  0.012  0.168  0.3308 0.2496 0.2859] \t\t\t\t\t self.mu.exp() \n",
      "[0.0004 0.0026 0.0069 0.002  0.0043 0.003  0.1014] \t\t\t\t\t self.std.exp() \n",
      "[3 4 6 3 4 3 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[62.8293] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2100 th loss0 : 440.9428, test rmse : 170.6956, test mnll: : 23.8126\n",
      "[1502. 1068.  691.  374.   26.   25.    0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0018 0.083  0.0125 0.1666 0.3321 0.2491 0.2766] \t\t\t\t\t self.mu.exp() \n",
      "[0.0004 0.0025 0.0068 0.002  0.0036 0.0028 0.0991] \t\t\t\t\t self.std.exp() \n",
      "[3 4 6 3 4 3 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[60.3945] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2200 th loss0 : 437.8298, test rmse : 181.1034, test mnll: : 19.8193\n",
      "[2079. 1273.  893.  395.   26.   25.    0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0017 0.0823 0.0135 0.1681 0.3321 0.2497 0.2828] \t\t\t\t\t self.mu.exp() \n",
      "[0.0005 0.0023 0.0061 0.0019 0.003  0.0027 0.1003] \t\t\t\t\t self.std.exp() \n",
      "[3 4 6 3 4 3 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[56.8844] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2300 th loss0 : 432.3835, test rmse : 175.0303, test mnll: : 17.7632\n",
      "[2862. 1393. 1079.  421.   29.   25.    0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0018 0.0827 0.0128 0.1672 0.3323 0.2507 0.2762] \t\t\t\t\t self.mu.exp() \n",
      "[0.0005 0.0022 0.006  0.0019 0.0027 0.0025 0.098 ] \t\t\t\t\t self.std.exp() \n",
      "[4 4 6 3 3 3 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[55.9382] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2400 th loss0 : 433.7018, test rmse : 183.4057, test mnll: : 17.1995\n",
      "[3924. 1676. 1288.  438.   31.   25.    0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0017 0.0821 0.0129 0.1687 0.3331 0.2484 0.2907] \t\t\t\t\t self.mu.exp() \n",
      "[0.0006 0.0022 0.0056 0.0019 0.0026 0.0025 0.0973] \t\t\t\t\t self.std.exp() \n",
      "[4 4 6 3 3 3 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[58.2551] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2500 th loss0 : 429.8772, test rmse : 188.7645, test mnll: : 14.5526\n",
      "[5376. 1675. 1438.  425.   32.   25.    0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0018 0.0824 0.0124 0.1676 0.3317 0.2491 0.2811] \t\t\t\t\t self.mu.exp() \n",
      "[0.0007 0.002  0.0057 0.0017 0.0028 0.0024 0.0963] \t\t\t\t\t self.std.exp() \n",
      "[4 4 6 3 3 3 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[56.9129] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2600 th loss0 : 427.6027, test rmse : 153.0646, test mnll: : 14.1474\n",
      "[7338. 1850. 1526.  417.   32.   25.    0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0018 0.0835 0.0128 0.1683 0.3344 0.2488 0.2825] \t\t\t\t\t self.mu.exp() \n",
      "[0.0009 0.002  0.0057 0.0017 0.0027 0.0025 0.099 ] \t\t\t\t\t self.std.exp() \n",
      "[4 4 6 3 3 3 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[59.1171] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2700 th loss0 : 423.3361, test rmse : 147.2054, test mnll: : 12.1927\n",
      "[10039.  2019.  1527.   416.    30.    24.     0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0017 0.0831 0.0129 0.1685 0.3327 0.2493 0.2807] \t\t\t\t\t self.mu.exp() \n",
      "[0.001  0.002  0.0056 0.0017 0.0025 0.0024 0.0951] \t\t\t\t\t self.std.exp() \n",
      "[4 4 6 3 3 3 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[57.4423] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2800 th loss0 : 423.7689, test rmse : 153.1861, test mnll: : 10.3405\n",
      "[13782.  2036.  1393.   452.    32.    24.     0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0017 0.0827 0.0133 0.168  0.3348 0.25   0.2802] \t\t\t\t\t self.mu.exp() \n",
      "[0.0012 0.0019 0.0056 0.0017 0.0026 0.0025 0.1022] \t\t\t\t\t self.std.exp() \n",
      "[4 4 6 3 3 3 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[58.547] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2900 th loss0 : 421.5152, test rmse : 131.6812, test mnll: : 8.6421\n",
      "[18533.  2004.  1152.   471.    30.    25.     0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0016 0.0834 0.0133 0.169  0.3337 0.2492 0.2817] \t\t\t\t\t self.mu.exp() \n",
      "[0.0014 0.0018 0.0053 0.0018 0.0027 0.0024 0.0981] \t\t\t\t\t self.std.exp() \n",
      "[4 4 6 3 3 3 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[57.8967] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3000 th loss0 : 423.8252, test rmse : 115.7799, test mnll: : 8.6145\n",
      "[2.4756e+04 2.1540e+03 9.5700e+02 5.0900e+02 3.1000e+01 2.3000e+01\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0015 0.0821 0.0141 0.1666 0.3324 0.2499 0.2813] \t\t\t\t\t self.mu.exp() \n",
      "[0.0017 0.002  0.0056 0.0018 0.0026 0.0026 0.0971] \t\t\t\t\t self.std.exp() \n",
      "[4 4 5 3 3 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[57.6052] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3100 th loss0 : 417.2963, test rmse : 133.9710, test mnll: : 8.1211\n",
      "[3.307e+04 2.175e+03 7.290e+02 4.450e+02 3.000e+01 2.300e+01 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0014 0.0829 0.0145 0.1694 0.3302 0.2492 0.2822] \t\t\t\t\t self.mu.exp() \n",
      "[0.0019 0.002  0.0056 0.0017 0.0026 0.0026 0.0973] \t\t\t\t\t self.std.exp() \n",
      "[4 4 5 4 3 3 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[54.3083] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3200 th loss0 : 422.9306, test rmse : 121.6421, test mnll: : 7.1504\n",
      "[4.0506e+04 2.1650e+03 5.2400e+02 4.0900e+02 3.1000e+01 2.3000e+01\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.0824 0.015  0.167  0.3314 0.2496 0.2785] \t\t\t\t\t self.mu.exp() \n",
      "[0.0021 0.002  0.0064 0.0017 0.0026 0.0025 0.0975] \t\t\t\t\t self.std.exp() \n",
      "[4 4 5 4 3 3 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[55.6721] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3300 th loss0 : 416.5172, test rmse : 99.6758, test mnll: : 6.9356\n",
      "[4.9551e+04 2.1550e+03 4.3900e+02 4.1000e+02 3.0000e+01 2.4000e+01\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0011 0.0823 0.1672 0.017  0.3333 0.2497 0.2836] \t\t\t\t\t self.mu.exp() \n",
      "[0.0022 0.0019 0.0018 0.0066 0.0025 0.0025 0.0993] \t\t\t\t\t self.std.exp() \n",
      "[4 4 3 5 3 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[55.2428] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3400 th loss0 : 415.5332, test rmse : 57.4192, test mnll: : 6.2449\n",
      "[5.5662e+04 2.3460e+03 4.5300e+02 2.8700e+02 3.1000e+01 2.5000e+01\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.001  0.0818 0.1684 0.0179 0.3316 0.2514 0.2833] \t\t\t\t\t self.mu.exp() \n",
      "[0.0024 0.0022 0.0019 0.0077 0.0026 0.0025 0.0979] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 5 3 3 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[54.0553] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3500 th loss0 : 416.4429, test rmse : 81.3347, test mnll: : 5.7987\n",
      "[6.6074e+04 2.3320e+03 4.3100e+02 2.1000e+02 3.1000e+01 2.6000e+01\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0011 0.082  0.1688 0.02   0.3307 0.2498 0.2839] \t\t\t\t\t self.mu.exp() \n",
      "[0.0023 0.0021 0.0019 0.0088 0.0024 0.0025 0.0971] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 5 3 3 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[52.6063] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3600 th loss0 : 415.7911, test rmse : 75.2593, test mnll: : 5.3518\n",
      "[7.4894e+04 2.3830e+03 4.1500e+02 1.5200e+02 3.2000e+01 2.7000e+01\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0011 0.0832 0.1674 0.0219 0.334  0.2497 0.2841] \t\t\t\t\t self.mu.exp() \n",
      "[0.0022 0.0021 0.0019 0.009  0.0025 0.0026 0.0949] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 5 3 3 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[53.7099] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3700 th loss0 : 417.1371, test rmse : 43.8888, test mnll: : 5.1795\n",
      "[8.4581e+04 2.3940e+03 4.0300e+02 1.1900e+02 3.3000e+01 2.6000e+01\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.001  0.0832 0.168  0.0234 0.3285 0.2488 0.2844] \t\t\t\t\t self.mu.exp() \n",
      "[0.0023 0.0021 0.0018 0.0098 0.0026 0.0026 0.0983] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 5 3 3 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[48.9102] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3800 th loss0 : 416.3054, test rmse : 45.2579, test mnll: : 4.9228\n",
      "[9.5648e+04 2.2710e+03 3.9500e+02 1.0200e+02 3.4000e+01 2.6000e+01\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.001  0.0833 0.1685 0.0236 0.3322 0.2498 0.2819] \t\t\t\t\t self.mu.exp() \n",
      "[0.0023 0.002  0.0019 0.0092 0.0026 0.0027 0.0979] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 5 3 3 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[50.9148] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3900 th loss0 : 417.2511, test rmse : 22.4271, test mnll: : 4.4872\n",
      "[9.771e+04 2.185e+03 4.010e+02 8.400e+01 3.300e+01 2.700e+01 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0009 0.0834 0.1673 0.0229 0.3315 0.2498 0.2834] \t\t\t\t\t self.mu.exp() \n",
      "[0.0021 0.002  0.0018 0.0095 0.0026 0.0025 0.0969] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 5 3 3 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[50.037] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4000 th loss0 : 419.1068, test rmse : 27.9858, test mnll: : 4.6292\n",
      "[1.0482e+05 2.3340e+03 4.3500e+02 8.0000e+01 3.1000e+01 2.6000e+01\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0008 0.0825 0.1657 0.0227 0.3312 0.2488 0.2838] \t\t\t\t\t self.mu.exp() \n",
      "[0.0022 0.002  0.002  0.0089 0.0024 0.0025 0.0975] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 5 3 3 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[50.2767] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4100 th loss0 : 419.2279, test rmse : 41.3177, test mnll: : 4.8782\n",
      "[1.1311e+05 2.4070e+03 4.5000e+02 7.6000e+01 3.1000e+01 2.5000e+01\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0009 0.0835 0.1687 0.0237 0.3312 0.25   0.2822] \t\t\t\t\t self.mu.exp() \n",
      "[0.0021 0.0019 0.0021 0.0088 0.0024 0.0024 0.0967] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 5 3 3 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[52.1951] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4200 th loss0 : 418.0205, test rmse : 22.7943, test mnll: : 4.5613\n",
      "[1.2103e+05 2.4490e+03 4.0500e+02 7.9000e+01 3.1000e+01 2.7000e+01\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0008 0.0831 0.1684 0.0243 0.3323 0.2498 0.2837] \t\t\t\t\t self.mu.exp() \n",
      "[0.0021 0.0019 0.0018 0.009  0.0024 0.0024 0.0978] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 5 3 3 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[50.099] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4300 th loss0 : 423.2596, test rmse : 23.9439, test mnll: : 4.5942\n",
      "[1.296e+05 2.385e+03 3.960e+02 7.800e+01 3.100e+01 2.500e+01 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0008 0.0831 0.1679 0.0241 0.333  0.2504 0.2827] \t\t\t\t\t self.mu.exp() \n",
      "[0.0021 0.0019 0.0019 0.0094 0.0024 0.0024 0.0968] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 5 3 3 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[49.3286] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4400 th loss0 : 413.4266, test rmse : 20.5720, test mnll: : 4.4701\n",
      "[1.3914e+05 2.6380e+03 4.0100e+02 7.8000e+01 3.1000e+01 2.5000e+01\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0008 0.0828 0.1675 0.0248 0.3322 0.249  0.2833] \t\t\t\t\t self.mu.exp() \n",
      "[0.0022 0.0021 0.0018 0.0092 0.0024 0.0026 0.0975] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 5 3 3 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[53.2117] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4500 th loss0 : 413.6461, test rmse : 51.2144, test mnll: : 5.0690\n",
      "[1.3594e+05 2.5340e+03 4.0800e+02 7.7000e+01 3.2000e+01 2.5000e+01\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0008 0.0824 0.1686 0.0237 0.3337 0.2494 0.2832] \t\t\t\t\t self.mu.exp() \n",
      "[0.0021 0.002  0.0018 0.009  0.0025 0.0026 0.0973] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 5 3 3 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[50.4472] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4600 th loss0 : 417.5852, test rmse : 25.7201, test mnll: : 4.6180\n",
      "[1.4025e+05 2.4180e+03 4.1300e+02 7.7000e+01 3.2000e+01 2.6000e+01\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0008 0.083  0.1678 0.0241 0.3312 0.2501 0.2818] \t\t\t\t\t self.mu.exp() \n",
      "[0.0021 0.002  0.0019 0.0089 0.0025 0.0025 0.0965] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 5 3 3 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[49.301] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4700 th loss0 : 414.0816, test rmse : 35.0769, test mnll: : 4.8723\n",
      "[1.3678e+05 2.4200e+03 3.8800e+02 7.5000e+01 3.4000e+01 2.5000e+01\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0008 0.0825 0.1684 0.0241 0.3307 0.2485 0.2831] \t\t\t\t\t self.mu.exp() \n",
      "[0.0021 0.002  0.0018 0.0092 0.0025 0.0026 0.0974] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 5 3 3 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[50.0957] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4800 th loss0 : 421.4877, test rmse : 24.8453, test mnll: : 4.6939\n",
      "[1.3385e+05 2.6040e+03 4.0400e+02 7.6000e+01 3.2000e+01 2.8000e+01\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0008 0.0837 0.1681 0.0233 0.3328 0.2496 0.2819] \t\t\t\t\t self.mu.exp() \n",
      "[0.002  0.0021 0.0018 0.0094 0.0025 0.0028 0.0968] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 5 3 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[50.8915] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4900 th loss0 : 413.8903, test rmse : 52.6033, test mnll: : 5.2455\n",
      "[1.42e+05 2.59e+03 4.41e+02 8.40e+01 3.30e+01 2.40e+01 0.00e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0008 0.0837 0.1679 0.023  0.3333 0.249  0.2827] \t\t\t\t\t self.mu.exp() \n",
      "[0.0019 0.0021 0.0019 0.0093 0.0027 0.0027 0.0975] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 5 3 3 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[49.8578] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "5000 th loss0 : 413.8957, test rmse : 28.6766, test mnll: : 4.6752\n",
      "[1.6283e+05 2.5900e+03 4.0600e+02 8.4000e+01 3.2000e+01 2.6000e+01\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0008 0.0839 0.1679 0.0235 0.3325 0.2511 0.2821] \t\t\t\t\t self.mu.exp() \n",
      "[0.0019 0.0021 0.0019 0.0088 0.0027 0.0026 0.0973] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 5 4 3 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[52.0032] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "0 init loss: 86221.5961 \n",
      "0 model chosen \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "2 init loss: 83590.2155 \n",
      "2 model chosen \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "5 init loss: 79984.9835 \n",
      "5 model chosen \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "7 init loss: 48345.5828 \n",
      "7 model chosen \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "########################################################################################################################################################################################################\n",
      "equal_reg\n",
      "########################################################################################################################################################################################################\n",
      "0 th loss0 : 68844.9514, test rmse : 553.5480, test mnll: : 5949.5294\n",
      "[1. 1. 1. 1. 1. 1. 1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.1773 0.0081 0.0763 0.3353 0.2482 0.414  0.0303] \t\t\t\t\t self.mu.exp() \n",
      "[0.0069 0.0012 0.0062 0.0092 0.008  0.0079 0.0093] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[20.4085] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "100 th loss0 : 24384.4739, test rmse : 480.9610, test mnll: : 2879.2733\n",
      "[2. 2. 2. 2. 2. 2. 2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.169  0.0054 0.0774 0.3425 0.2469 0.4187 0.0282] \t\t\t\t\t self.mu.exp() \n",
      "[0.0059 0.0016 0.0062 0.0089 0.0073 0.008  0.0097] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[31.8326] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "200 th loss0 : 14635.7583, test rmse : 443.6028, test mnll: : 1988.8133\n",
      "[3. 3. 2. 2. 2. 2. 2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.169  0.0044 0.0799 0.3395 0.2519 0.4307 0.0263] \t\t\t\t\t self.mu.exp() \n",
      "[0.0051 0.0017 0.0056 0.0084 0.0068 0.008  0.0099] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[39.2485] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 th loss0 : 10125.2452, test rmse : 430.5047, test mnll: : 1556.0229\n",
      "[5. 4. 3. 3. 3. 3. 2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0037 0.169  0.079  0.3374 0.2482 0.4251 0.0247] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.0041 0.0049 0.008  0.0061 0.0077 0.0102] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[47.0505] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "400 th loss0 : 7074.1737, test rmse : 305.7732, test mnll: : 636.4808\n",
      "[7. 5. 4. 4. 4. 3. 3.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0033 0.1685 0.0807 0.3407 0.251  0.4195 0.0235] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.0033 0.0042 0.0076 0.0054 0.0072 0.0104] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[54.807] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "500 th loss0 : 4965.0190, test rmse : 264.3585, test mnll: : 421.7936\n",
      "[9. 7. 6. 5. 5. 4. 3.] \t\t\t\t\t self.weight.exp() \n",
      "[0.003  0.1668 0.0803 0.3366 0.249  0.419  0.022 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0015 0.0029 0.0036 0.0071 0.0047 0.0067 0.0107] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[63.5455] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "600 th loss0 : 3350.2075, test rmse : 263.9915, test mnll: : 344.9270\n",
      "[13. 10.  8.  7.  6.  4.  4.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0027 0.1682 0.0806 0.3372 0.2495 0.4188 0.021 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0013 0.0024 0.0031 0.0065 0.0042 0.0062 0.0108] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[74.9925] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "700 th loss0 : 2765.3100, test rmse : 283.4521, test mnll: : 333.7815\n",
      "[18. 13. 12.  9.  9.  5.  5.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0025 0.1691 0.0812 0.3337 0.2494 0.4141 0.0199] \t\t\t\t\t self.mu.exp() \n",
      "[0.0012 0.0021 0.0028 0.006  0.0038 0.006  0.0109] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[88.3821] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "800 th loss0 : 2315.3660, test rmse : 243.3802, test mnll: : 202.4059\n",
      "[24. 18. 16. 11. 11.  7.  5.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0024 0.168  0.0813 0.3348 0.2495 0.0188 0.4163] \t\t\t\t\t self.mu.exp() \n",
      "[0.0011 0.0019 0.0026 0.005  0.0033 0.0111 0.0063] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[106.0823] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "900 th loss0 : 1624.2257, test rmse : 205.8812, test mnll: : 120.3802\n",
      "[33. 25. 23. 15. 14.  9.  5.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0023 0.1678 0.0819 0.2502 0.3336 0.0173 0.4181] \t\t\t\t\t self.mu.exp() \n",
      "[0.001  0.0017 0.0026 0.0032 0.0047 0.0112 0.0068] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[130.3688] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1000 th loss0 : 1328.2631, test rmse : 253.9890, test mnll: : 141.7115\n",
      "[46. 34. 31. 18. 17. 13.  5.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0022 0.1677 0.0821 0.2508 0.3341 0.0162 0.4168] \t\t\t\t\t self.mu.exp() \n",
      "[0.0009 0.0016 0.0026 0.003  0.0044 0.011  0.0081] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[162.0567] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1100 th loss0 : 1097.1530, test rmse : 207.0720, test mnll: : 78.8534\n",
      "[63. 45. 43. 21. 18. 18.  3.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0021 0.1679 0.082  0.2506 0.3337 0.0153 0.4153] \t\t\t\t\t self.mu.exp() \n",
      "[0.0008 0.0016 0.0025 0.0033 0.0042 0.0109 0.0111] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[202.8992] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1200 th loss0 : 935.6945, test rmse : 213.1952, test mnll: : 67.3317\n",
      "[86. 60. 60. 24. 22. 18.  2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.002  0.1676 0.0811 0.0143 0.2491 0.3335 0.409 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0008 0.0016 0.0026 0.0107 0.0036 0.0041 0.0189] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[250.1554] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1300 th loss0 : 789.1789, test rmse : 207.9433, test mnll: : 54.3571\n",
      "[118.  83.  77.  34.  20.  16.   2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.002  0.0814 0.1681 0.0132 0.2495 0.3351 0.3761] \t\t\t\t\t self.mu.exp() \n",
      "[0.0007 0.0027 0.0018 0.0102 0.0041 0.0045 0.0325] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[304.4194] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1400 th loss0 : 699.1494, test rmse : 208.7106, test mnll: : 45.6470\n",
      "[162. 113.  95.  49.  17.  13.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.002  0.0825 0.1681 0.0123 0.2488 0.3293 0.3344] \t\t\t\t\t self.mu.exp() \n",
      "[0.0007 0.0028 0.0018 0.0097 0.0046 0.0054 0.0507] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[343.6113] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1500 th loss0 : 675.5866, test rmse : 192.4743, test mnll: : 39.1234\n",
      "[222. 157. 115.  70.  14.  10.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0019 0.0812 0.1667 0.0117 0.25   0.324  0.3088] \t\t\t\t\t self.mu.exp() \n",
      "[0.0006 0.0029 0.0019 0.0089 0.0052 0.0073 0.0741] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[351.8904] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1600 th loss0 : 573.3939, test rmse : 200.7394, test mnll: : 39.7769\n",
      "[307. 219. 135. 100.  12.   7.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0019 0.0827 0.1676 0.0111 0.2516 0.3282 0.2865] \t\t\t\t\t self.mu.exp() \n",
      "[0.0006 0.0028 0.002  0.0087 0.0058 0.011  0.0946] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[300.2539] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1700 th loss0 : 560.0883, test rmse : 141.7989, test mnll: : 27.2478\n",
      "[425. 306. 151. 146.  13.   6.   0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0019 0.0825 0.1675 0.0103 0.25   0.3262 0.2841] \t\t\t\t\t self.mu.exp() \n",
      "[0.0005 0.0028 0.002  0.0082 0.0058 0.0139 0.1004] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[212.0172] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1800 th loss0 : 518.3623, test rmse : 164.8086, test mnll: : 34.8758\n",
      "[590. 436. 217. 184.  18.   7.   0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0018 0.0818 0.0111 0.1668 0.2477 0.3254 0.2745] \t\t\t\t\t self.mu.exp() \n",
      "[0.0005 0.0028 0.0074 0.0021 0.0044 0.0137 0.0978] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[128.9489] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1900 th loss0 : 483.5002, test rmse : 162.2333, test mnll: : 31.8553\n",
      "[823. 616. 311. 249.  20.  10.   0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0018 0.0828 0.0123 0.1677 0.2495 0.3295 0.2839] \t\t\t\t\t self.mu.exp() \n",
      "[0.0005 0.0027 0.0068 0.0023 0.0035 0.0109 0.1059] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[89.8075] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2000 th loss0 : 465.4114, test rmse : 145.2702, test mnll: : 30.8171\n",
      "[1151.  803.  432.  265.   22.   16.    0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0018 0.0817 0.0128 0.1679 0.2497 0.3317 0.2971] \t\t\t\t\t self.mu.exp() \n",
      "[0.0005 0.0027 0.006  0.0021 0.0031 0.0077 0.115 ] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[77.0296] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2100 th loss0 : 442.5260, test rmse : 194.5373, test mnll: : 24.2918\n",
      "[1588.  982.  593.  278.   22.   22.    0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0018 0.0819 0.0139 0.1677 0.3328 0.2493 0.2834] \t\t\t\t\t self.mu.exp() \n",
      "[0.0005 0.0025 0.0059 0.0019 0.0058 0.0029 0.1082] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[63.2465] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2200 th loss0 : 441.2582, test rmse : 183.5774, test mnll: : 20.1921\n",
      "[2201. 1222.  756.  316.   26.   24.    0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0018 0.0836 0.0137 0.1675 0.3323 0.2485 0.2678] \t\t\t\t\t self.mu.exp() \n",
      "[0.0005 0.0024 0.0057 0.0019 0.0047 0.0027 0.1026] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[61.2705] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2300 th loss0 : 433.3635, test rmse : 166.1428, test mnll: : 17.2857\n",
      "[3031. 1377.  971.  313.   29.   25.    0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0017 0.0833 0.0139 0.1681 0.327  0.248  0.2678] \t\t\t\t\t self.mu.exp() \n",
      "[0.0006 0.0023 0.0052 0.0019 0.0043 0.0027 0.1048] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[56.0943] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2400 th loss0 : 428.0655, test rmse : 140.3005, test mnll: : 27.9368\n",
      "[4127. 1566. 1156.  326.   29.   25.    0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0017 0.0828 0.014  0.167  0.3338 0.2491 0.2722] \t\t\t\t\t self.mu.exp() \n",
      "[0.0006 0.0023 0.005  0.0019 0.0038 0.0026 0.1   ] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[56.6724] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2500 th loss0 : 435.4520, test rmse : 139.5247, test mnll: : 13.0900\n",
      "[5700. 1638. 1331.  332.   29.   24.    0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0017 0.083  0.0146 0.1686 0.3353 0.249  0.2758] \t\t\t\t\t self.mu.exp() \n",
      "[0.0007 0.0021 0.0046 0.0018 0.0033 0.0027 0.0972] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[56.7892] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2600 th loss0 : 424.0277, test rmse : 160.9604, test mnll: : 15.1816\n",
      "[7735. 1821. 1399.  363.   28.   24.    0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0017 0.0832 0.0143 0.1692 0.3317 0.2492 0.2734] \t\t\t\t\t self.mu.exp() \n",
      "[0.0008 0.0021 0.0046 0.002  0.003  0.0026 0.0982] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[55.6633] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2700 th loss0 : 421.7250, test rmse : 144.4873, test mnll: : 9.7480\n",
      "[10484.  1903.  1457.   418.    28.    25.     0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0017 0.0829 0.0141 0.1685 0.3315 0.2493 0.2832] \t\t\t\t\t self.mu.exp() \n",
      "[0.0009 0.0021 0.0046 0.0023 0.0028 0.0029 0.1006] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[54.9614] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2800 th loss0 : 427.3051, test rmse : 148.0470, test mnll: : 10.7637\n",
      "[13893.  2056.  1368.   397.    27.    24.     0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0017 0.0824 0.0143 0.1675 0.3319 0.2489 0.2833] \t\t\t\t\t self.mu.exp() \n",
      "[0.001  0.0021 0.0046 0.0021 0.0027 0.0028 0.0957] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[55.8025] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2900 th loss0 : 422.3252, test rmse : 149.2670, test mnll: : 10.3959\n",
      "[18510.  2006.  1338.   409.    28.    24.     0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0016 0.0824 0.0146 0.1682 0.3344 0.2511 0.2877] \t\t\t\t\t self.mu.exp() \n",
      "[0.0012 0.002  0.0046 0.002  0.0026 0.003  0.1011] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[56.9125] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3000 th loss0 : 421.0353, test rmse : 133.8023, test mnll: : 9.0590\n",
      "[2.4326e+04 2.0490e+03 1.1480e+03 3.9200e+02 2.9000e+01 2.2000e+01\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0015 0.0828 0.0146 0.1672 0.3334 0.249  0.2822] \t\t\t\t\t self.mu.exp() \n",
      "[0.0015 0.002  0.0046 0.002  0.0026 0.0029 0.0986] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[56.496] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3100 th loss0 : 420.2346, test rmse : 109.9966, test mnll: : 6.3591\n",
      "[3.1852e+04 2.0640e+03 9.0400e+02 3.6900e+02 3.0000e+01 2.3000e+01\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0015 0.0838 0.0142 0.1672 0.333  0.2504 0.2852] \t\t\t\t\t self.mu.exp() \n",
      "[0.0017 0.002  0.0045 0.0018 0.0024 0.0027 0.0977] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[57.2246] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3200 th loss0 : 419.1383, test rmse : 128.4698, test mnll: : 8.2949\n",
      "[3.9701e+04 2.1270e+03 7.3700e+02 3.5600e+02 2.9000e+01 2.3000e+01\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0014 0.0831 0.0157 0.1684 0.332  0.2515 0.2923] \t\t\t\t\t self.mu.exp() \n",
      "[0.002  0.002  0.0047 0.0018 0.0024 0.0027 0.0995] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[54.8457] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3300 th loss0 : 419.9583, test rmse : 81.0696, test mnll: : 7.0096\n",
      "[4.7888e+04 2.0800e+03 5.4300e+02 3.6100e+02 2.9000e+01 2.4000e+01\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.0825 0.0169 0.1679 0.3334 0.2482 0.2858] \t\t\t\t\t self.mu.exp() \n",
      "[0.0021 0.002  0.0054 0.0018 0.0025 0.0027 0.0982] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[53.5565] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3400 th loss0 : 416.1944, test rmse : 83.5739, test mnll: : 5.8872\n",
      "[5.5204e+04 2.0810e+03 3.7300e+02 3.7000e+02 2.8000e+01 2.3000e+01\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0012 0.0828 0.018  0.1659 0.3318 0.2511 0.2845] \t\t\t\t\t self.mu.exp() \n",
      "[0.0021 0.002  0.0056 0.0019 0.0024 0.0026 0.0982] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[53.3252] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3500 th loss0 : 424.2763, test rmse : 112.4163, test mnll: : 7.6039\n",
      "[6.619e+04 2.174e+03 3.950e+02 2.590e+02 2.900e+01 2.400e+01 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0012 0.0829 0.1682 0.0204 0.3311 0.2482 0.2839] \t\t\t\t\t self.mu.exp() \n",
      "[0.0022 0.0021 0.002  0.006  0.0025 0.0026 0.0967] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[52.6379] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3600 th loss0 : 414.6569, test rmse : 114.0484, test mnll: : 7.3230\n",
      "[7.2277e+04 2.3220e+03 3.8100e+02 1.8200e+02 3.0000e+01 2.5000e+01\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0011 0.0828 0.1669 0.0207 0.3335 0.2503 0.2833] \t\t\t\t\t self.mu.exp() \n",
      "[0.0023 0.0022 0.0019 0.0064 0.0026 0.0027 0.0981] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[51.1646] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3700 th loss0 : 418.9183, test rmse : 44.8334, test mnll: : 5.4005\n",
      "[8.2215e+04 2.3220e+03 3.7100e+02 1.3400e+02 3.0000e+01 2.3000e+01\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.001  0.0823 0.1665 0.0222 0.331  0.2514 0.2824] \t\t\t\t\t self.mu.exp() \n",
      "[0.0023 0.0021 0.0019 0.007  0.0025 0.0027 0.0971] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[53.856] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3800 th loss0 : 415.7175, test rmse : 74.5284, test mnll: : 6.0734\n",
      "[9.4038e+04 2.1690e+03 3.6900e+02 1.1000e+02 3.0000e+01 2.5000e+01\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0011 0.0826 0.1685 0.0222 0.3315 0.2492 0.2841] \t\t\t\t\t self.mu.exp() \n",
      "[0.002  0.0019 0.002  0.0068 0.0026 0.0027 0.0986] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[53.6008] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3900 th loss0 : 432.1952, test rmse : 55.5702, test mnll: : 5.7773\n",
      "[1.0142e+05 2.2060e+03 3.8800e+02 9.5000e+01 3.0000e+01 2.5000e+01\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0011 0.0819 0.1683 0.0216 0.3342 0.2489 0.2819] \t\t\t\t\t self.mu.exp() \n",
      "[0.0021 0.002  0.002  0.0069 0.0027 0.0027 0.0969] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[52.6682] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4000 th loss0 : 416.1380, test rmse : 51.6864, test mnll: : 5.6823\n",
      "[1.1135e+05 2.1570e+03 3.7800e+02 8.7000e+01 2.9000e+01 2.3000e+01\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0011 0.0829 0.1687 0.0217 0.3329 0.2484 0.2843] \t\t\t\t\t self.mu.exp() \n",
      "[0.0021 0.002  0.002  0.0071 0.0026 0.0026 0.0968] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[52.3598] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4100 th loss0 : 416.6779, test rmse : 27.1061, test mnll: : 4.6830\n",
      "[1.1422e+05 2.2870e+03 3.6100e+02 8.6000e+01 2.9000e+01 2.3000e+01\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.001  0.0835 0.1675 0.022  0.3307 0.2488 0.2833] \t\t\t\t\t self.mu.exp() \n",
      "[0.0021 0.0019 0.0018 0.0073 0.0025 0.0026 0.0969] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[51.5884] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4200 th loss0 : 417.9761, test rmse : 34.4815, test mnll: : 4.8516\n",
      "[1.158e+05 2.306e+03 3.750e+02 8.600e+01 2.900e+01 2.500e+01 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.001  0.0838 0.1664 0.0225 0.3318 0.249  0.2816] \t\t\t\t\t self.mu.exp() \n",
      "[0.0021 0.002  0.0018 0.0067 0.0025 0.0027 0.098 ] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[52.0187] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4300 th loss0 : 417.4977, test rmse : 61.9198, test mnll: : 5.8881\n",
      "[1.1405e+05 2.3090e+03 3.8700e+02 8.3000e+01 3.0000e+01 2.4000e+01\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.001  0.083  0.1683 0.0229 0.3324 0.2505 0.284 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0019 0.0021 0.0018 0.007  0.0026 0.0027 0.0969] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[51.775] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4400 th loss0 : 430.5876, test rmse : 25.1675, test mnll: : 4.8874\n",
      "[1.2326e+05 2.2650e+03 3.7600e+02 8.4000e+01 2.9000e+01 2.5000e+01\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.001  0.0831 0.1684 0.0232 0.3315 0.25   0.2838] \t\t\t\t\t self.mu.exp() \n",
      "[0.002  0.0021 0.0018 0.0074 0.0025 0.0029 0.0972] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[50.4551] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4500 th loss0 : 414.0535, test rmse : 40.1975, test mnll: : 4.8872\n",
      "[1.2368e+05 2.2880e+03 3.8400e+02 8.3000e+01 2.8000e+01 2.4000e+01\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.001  0.0822 0.1683 0.0229 0.332  0.2498 0.2816] \t\t\t\t\t self.mu.exp() \n",
      "[0.0019 0.0021 0.0019 0.0074 0.0025 0.0026 0.0968] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[52.2891] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4600 th loss0 : 414.0093, test rmse : 39.7217, test mnll: : 5.1164\n",
      "[1.2899e+05 2.3260e+03 3.7300e+02 8.1000e+01 3.0000e+01 2.4000e+01\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0009 0.0826 0.1677 0.0225 0.3313 0.2501 0.2828] \t\t\t\t\t self.mu.exp() \n",
      "[0.002  0.0021 0.0019 0.0076 0.0026 0.0025 0.0971] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[52.196] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4700 th loss0 : 421.4222, test rmse : 39.3956, test mnll: : 5.1278\n",
      "[1.2917e+05 2.3750e+03 3.7700e+02 7.6000e+01 3.2000e+01 2.4000e+01\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0009 0.0829 0.1666 0.0236 0.3331 0.2497 0.2819] \t\t\t\t\t self.mu.exp() \n",
      "[0.002  0.0022 0.002  0.0081 0.0027 0.0024 0.097 ] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[51.6535] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4800 th loss0 : 412.7452, test rmse : 37.2376, test mnll: : 5.7759\n",
      "[1.2401e+05 2.4530e+03 3.8800e+02 7.6000e+01 3.0000e+01 2.4000e+01\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0009 0.0834 0.1689 0.0237 0.3332 0.2488 0.2823] \t\t\t\t\t self.mu.exp() \n",
      "[0.0019 0.0022 0.002  0.0078 0.0026 0.0025 0.0972] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[51.5644] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4900 th loss0 : 421.3560, test rmse : 24.4040, test mnll: : 4.6871\n",
      "[1.3418e+05 2.4880e+03 3.6900e+02 7.8000e+01 2.8000e+01 2.4000e+01\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.001  0.0832 0.1676 0.0239 0.3331 0.2502 0.2841] \t\t\t\t\t self.mu.exp() \n",
      "[0.0018 0.0021 0.0019 0.0081 0.0026 0.0027 0.0967] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[51.2191] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "5000 th loss0 : 411.3282, test rmse : 43.3702, test mnll: : 5.2347\n",
      "[1.2885e+05 2.2340e+03 3.6500e+02 7.5000e+01 3.2000e+01 2.5000e+01\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.001  0.0833 0.1677 0.0241 0.3328 0.2501 0.282 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0018 0.002  0.0019 0.0084 0.0027 0.0028 0.0967] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[50.6711] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "##################################################\n",
      "#2 th experimnet\n",
      "0 init loss: 67819.5384 \n",
      "0 model chosen \n",
      "1 init loss: 67819.5384 \n",
      "1 model chosen \n",
      "2 init loss: 67819.5384 \n",
      "2 model chosen \n",
      "3 init loss: 67819.5384 \n",
      "3 model chosen \n",
      "4 init loss: 67819.5384 \n",
      "4 model chosen \n",
      "5 init loss: 67819.5384 \n",
      "5 model chosen \n",
      "6 init loss: 67819.5384 \n",
      "6 model chosen \n",
      "7 init loss: 67819.5384 \n",
      "7 model chosen \n",
      "8 init loss: 67819.5384 \n",
      "8 model chosen \n",
      "9 init loss: 67819.5384 \n",
      "9 model chosen \n",
      "########################################################################################################################################################################################################\n",
      "gpsm\n",
      "########################################################################################################################################################################################################\n",
      "0 th loss0 : 66840.4635, test rmse : 525.9893, test mnll: : 4890.1328\n",
      "100 th loss0 : 22464.1907, test rmse : 437.0639, test mnll: : 2221.8135\n",
      "200 th loss0 : 13062.1339, test rmse : 369.8071, test mnll: : 1275.3078\n",
      "300 th loss0 : 8791.2073, test rmse : 333.4227, test mnll: : 857.3303\n",
      "400 th loss0 : 6211.2174, test rmse : 307.7278, test mnll: : 604.6697\n",
      "500 th loss0 : 4491.2710, test rmse : 286.1154, test mnll: : 429.0542\n",
      "600 th loss0 : 3306.2475, test rmse : 266.9140, test mnll: : 301.8371\n",
      "700 th loss0 : 2480.1149, test rmse : 250.3812, test mnll: : 210.1983\n",
      "800 th loss0 : 1899.0478, test rmse : 237.3085, test mnll: : 145.8435\n",
      "900 th loss0 : 1486.4389, test rmse : 228.1838, test mnll: : 101.6270\n",
      "1000 th loss0 : 1192.0444, test rmse : 222.8526, test mnll: : 71.5776\n",
      "1100 th loss0 : 983.0185, test rmse : 220.5220, test mnll: : 51.2059\n",
      "1200 th loss0 : 836.6451, test rmse : 219.9333, test mnll: : 37.4431\n",
      "1300 th loss0 : 735.8774, test rmse : 219.3212, test mnll: : 28.2836\n",
      "1400 th loss0 : 666.8923, test rmse : 216.2692, test mnll: : 22.4804\n",
      "1500 th loss0 : 617.2892, test rmse : 207.2050, test mnll: : 19.3471\n",
      "1600 th loss0 : 574.8960, test rmse : 187.8991, test mnll: : 18.6362\n",
      "1700 th loss0 : 531.7930, test rmse : 159.4304, test mnll: : 19.3209\n",
      "1800 th loss0 : 484.1901, test rmse : 147.0161, test mnll: : 22.2158\n",
      "1900 th loss0 : 442.6641, test rmse : 144.1238, test mnll: : 23.5069\n",
      "2000 th loss0 : 420.6807, test rmse : 142.3143, test mnll: : 20.9748\n",
      "2100 th loss0 : 408.6875, test rmse : 138.9056, test mnll: : 17.5177\n",
      "2200 th loss0 : 400.7454, test rmse : 134.2140, test mnll: : 14.6390\n",
      "2300 th loss0 : 395.3147, test rmse : 128.0229, test mnll: : 12.2439\n",
      "2400 th loss0 : 391.4812, test rmse : 116.5997, test mnll: : 9.9697\n",
      "2500 th loss0 : 388.1891, test rmse : 98.4108, test mnll: : 8.1041\n",
      "2600 th loss0 : 386.1412, test rmse : 90.5252, test mnll: : 7.1807\n",
      "2700 th loss0 : 384.7811, test rmse : 80.9164, test mnll: : 6.4958\n",
      "2800 th loss0 : 383.8178, test rmse : 68.8990, test mnll: : 5.9245\n",
      "2900 th loss0 : 383.1229, test rmse : 57.6227, test mnll: : 5.4930\n",
      "3000 th loss0 : 382.6376, test rmse : 48.3750, test mnll: : 5.1895\n",
      "3100 th loss0 : 382.3119, test rmse : 41.0081, test mnll: : 4.9777\n",
      "3200 th loss0 : 382.1041, test rmse : 35.3532, test mnll: : 4.8325\n",
      "3300 th loss0 : 381.9817, test rmse : 31.2069, test mnll: : 4.7347\n",
      "3400 th loss0 : 381.9211, test rmse : 28.4793, test mnll: : 4.6759\n",
      "3500 th loss0 : 381.8878, test rmse : 26.3950, test mnll: : 4.6308\n",
      "3600 th loss0 : 381.8743, test rmse : 24.9345, test mnll: : 4.6006\n",
      "3700 th loss0 : 381.8713, test rmse : 24.3944, test mnll: : 4.5878\n",
      "3800 th loss0 : 381.8712, test rmse : 24.2852, test mnll: : 4.5850\n",
      "3900 th loss0 : 381.8743, test rmse : 24.2908, test mnll: : 4.5855\n",
      "4000 th loss0 : 381.8755, test rmse : 24.3174, test mnll: : 4.5864\n",
      "4100 th loss0 : 381.8720, test rmse : 24.3611, test mnll: : 4.5881\n",
      "4200 th loss0 : 381.8712, test rmse : 24.2902, test mnll: : 4.5854\n",
      "4300 th loss0 : 381.8719, test rmse : 24.2445, test mnll: : 4.5837\n",
      "4400 th loss0 : 381.8714, test rmse : 24.3028, test mnll: : 4.5857\n",
      "4500 th loss0 : 381.8727, test rmse : 24.3484, test mnll: : 4.5875\n",
      "4600 th loss0 : 381.8714, test rmse : 24.2680, test mnll: : 4.5845\n",
      "4700 th loss0 : 381.8714, test rmse : 24.2399, test mnll: : 4.5833\n",
      "4800 th loss0 : 381.8711, test rmse : 24.2776, test mnll: : 4.5849\n",
      "4900 th loss0 : 381.8714, test rmse : 24.2714, test mnll: : 4.5847\n",
      "5000 th loss0 : 381.8731, test rmse : 24.2760, test mnll: : 4.5847\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "0 init loss: 86397.9101 \n",
      "0 model chosen \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "1 init loss: 50545.7595 \n",
      "1 model chosen \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "9 init loss: 49549.3486 \n",
      "9 model chosen \n",
      "########################################################################################################################################################################################################\n",
      "weight_reg\n",
      "########################################################################################################################################################################################################\n",
      "0 th loss0 : 120764.7782, test rmse : 567.1970, test mnll: : 6395.9484\n",
      "[1. 1. 1. 1. 1. 1. 1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0082 0.1725 0.0587 0.4201 0.245  0.0794 0.4803] \t\t\t\t\t self.mu.exp() \n",
      "[0.0012 0.0042 0.0482 0.011  0.0282 0.0058 0.0052] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 4 5 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[19.8385] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "100 th loss0 : 31941.2823, test rmse : 509.7120, test mnll: : 3202.6819\n",
      "[2. 2. 2. 2. 2. 2. 1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0056 0.1702 0.4269 0.2423 0.0835 0.4826 0.0559] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.0034 0.0102 0.0301 0.005  0.0057 0.0496] \t\t\t\t\t self.std.exp() \n",
      "[3 3 4 5 4 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[32.8556] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 th loss0 : 21593.1636, test rmse : 360.9133, test mnll: : 1211.5415\n",
      "[3. 3. 2. 2. 2. 2. 2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0045 0.1689 0.0553 0.4179 0.2381 0.0861 0.4717] \t\t\t\t\t self.mu.exp() \n",
      "[0.0017 0.0028 0.0498 0.01   0.0303 0.0048 0.006 ] \t\t\t\t\t self.std.exp() \n",
      "[3 3 5 4 5 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[43.1173] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "300 th loss0 : 18081.5135, test rmse : 308.4985, test mnll: : 710.0952\n",
      "[5. 4. 3. 3. 3. 2. 2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0037 0.169  0.4252 0.2427 0.0947 0.0546 0.4756] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.0023 0.01   0.0306 0.0054 0.0503 0.0065] \t\t\t\t\t self.std.exp() \n",
      "[3 3 4 5 4 5 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[54.3804] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "400 th loss0 : 11259.0108, test rmse : 343.3603, test mnll: : 714.2403\n",
      "[6. 5. 3. 3. 3. 2. 2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0033 0.1688 0.4185 0.2523 0.1511 0.0543 0.4807] \t\t\t\t\t self.mu.exp() \n",
      "[0.0015 0.002  0.0098 0.0296 0.0057 0.0502 0.0069] \t\t\t\t\t self.std.exp() \n",
      "[3 3 4 5 4 5 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[67.5138] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "500 th loss0 : 7281.0321, test rmse : 289.3083, test mnll: : 411.2711\n",
      "[9. 7. 4. 3. 3. 2. 2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0029 0.1681 0.2586 0.4162 0.2661 0.0545 0.4656] \t\t\t\t\t self.mu.exp() \n",
      "[0.0013 0.0018 0.0286 0.0096 0.0056 0.05   0.0077] \t\t\t\t\t self.std.exp() \n",
      "[3 3 5 4 4 5 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[85.2926] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "600 th loss0 : 3838.6810, test rmse : 293.8459, test mnll: : 336.3049\n",
      "[12.  9.  4.  3.  3.  2.  2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0027 0.168  0.2677 0.4092 0.4011 0.0545 0.4537] \t\t\t\t\t self.mu.exp() \n",
      "[0.0012 0.0016 0.0281 0.0098 0.0056 0.0499 0.0092] \t\t\t\t\t self.std.exp() \n",
      "[3 3 5 4 4 5 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[108.1042] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "700 th loss0 : 2801.1251, test rmse : 277.3218, test mnll: : 236.6137\n",
      "[17. 13.  4.  3.  3.  2.  2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0025 0.1689 0.2711 0.403  0.4331 0.0544 0.4236] \t\t\t\t\t self.mu.exp() \n",
      "[0.0011 0.0015 0.0284 0.0111 0.0054 0.05   0.0116] \t\t\t\t\t self.std.exp() \n",
      "[3 3 5 4 4 5 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[141.2177] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "800 th loss0 : 2485.4543, test rmse : 226.5329, test mnll: : 122.2878\n",
      "[24. 18.  4.  3.  3.  2.  2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0023 0.1686 0.28   0.3792 0.4331 0.0545 0.4054] \t\t\t\t\t self.mu.exp() \n",
      "[0.001  0.0014 0.0276 0.0139 0.0053 0.0497 0.0155] \t\t\t\t\t self.std.exp() \n",
      "[3 3 5 4 4 5 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[189.0854] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "900 th loss0 : 1742.4362, test rmse : 257.7357, test mnll: : 115.3356\n",
      "[32. 24.  4.  3.  2.  2.  1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0022 0.1691 0.2875 0.4331 0.0545 0.3255 0.3702] \t\t\t\t\t self.mu.exp() \n",
      "[0.0009 0.0015 0.0275 0.005  0.0496 0.018  0.0234] \t\t\t\t\t self.std.exp() \n",
      "[3 3 5 4 5 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[262.8496] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1000 th loss0 : 1394.8411, test rmse : 238.6460, test mnll: : 72.4636\n",
      "[44. 31.  3.  3.  3.  2.  1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0021 0.1713 0.0544 0.2953 0.4333 0.2865 0.326 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0009 0.0018 0.0497 0.0265 0.0047 0.0235 0.0353] \t\t\t\t\t self.std.exp() \n",
      "[3 3 5 5 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[374.8965] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1100 th loss0 : 1121.8037, test rmse : 230.0318, test mnll: : 47.8539\n",
      "[60. 37.  3.  3.  3.  2.  1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0021 0.2086 0.0543 0.2953 0.4333 0.2463 0.2886] \t\t\t\t\t self.mu.exp() \n",
      "[0.0008 0.0029 0.0497 0.0252 0.0043 0.034  0.0538] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 5 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[550.486] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1200 th loss0 : 904.4202, test rmse : 237.8911, test mnll: : 36.4322\n",
      "[82. 31.  3.  3.  2.  1.  1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.002  0.2807 0.0543 0.4334 0.294  0.2066 0.2539] \t\t\t\t\t self.mu.exp() \n",
      "[0.0008 0.0036 0.0497 0.0039 0.0239 0.0465 0.0691] \t\t\t\t\t self.std.exp() \n",
      "[3 4 5 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[819.9398] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1300 th loss0 : 787.7662, test rmse : 255.9851, test mnll: : 30.1236\n",
      "[111.  24.   3.   3.   2.   1.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.002  0.2807 0.0543 0.4334 0.2946 0.1723 0.2266] \t\t\t\t\t self.mu.exp() \n",
      "[0.0007 0.0047 0.0497 0.0036 0.0226 0.0583 0.0807] \t\t\t\t\t self.std.exp() \n",
      "[4 4 5 3 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[1205.2633] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1400 th loss0 : 712.2776, test rmse : 232.9870, test mnll: : 19.8381\n",
      "[150.  18.   3.   2.   2.   1.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0019 0.2808 0.0545 0.2947 0.4334 0.1391 0.2032] \t\t\t\t\t self.mu.exp() \n",
      "[0.0007 0.0063 0.0497 0.0219 0.0033 0.0746 0.0934] \t\t\t\t\t self.std.exp() \n",
      "[4 4 5 4 3 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[1705.1778] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1500 th loss0 : 666.9128, test rmse : 237.9292, test mnll: : 16.7477\n",
      "[204.  14.   3.   2.   2.   1.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0019 0.2808 0.0548 0.1139 0.4334 0.2946 0.1855] \t\t\t\t\t self.mu.exp() \n",
      "[0.0007 0.0079 0.0498 0.0813 0.0031 0.0216 0.1009] \t\t\t\t\t self.std.exp() \n",
      "[3 4 5 5 3 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[2266.3155] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1600 th loss0 : 626.1406, test rmse : 229.3456, test mnll: : 14.2379\n",
      "[279.  11.   3.   2.   2.   1.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0019 0.2808 0.0554 0.0979 0.4334 0.2945 0.1724] \t\t\t\t\t self.mu.exp() \n",
      "[0.0006 0.0084 0.05   0.0778 0.0031 0.0215 0.1057] \t\t\t\t\t self.std.exp() \n",
      "[3 4 5 5 3 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[2688.5822] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1700 th loss0 : 603.2934, test rmse : 216.7894, test mnll: : 13.6800\n",
      "[390.   9.   3.   3.   2.   1.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.002  0.2808 0.0565 0.082  0.4334 0.2945 0.1717] \t\t\t\t\t self.mu.exp() \n",
      "[0.0006 0.0085 0.0501 0.0795 0.0031 0.0215 0.101 ] \t\t\t\t\t self.std.exp() \n",
      "[3 4 5 5 3 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[2533.5606] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1800 th loss0 : 571.4874, test rmse : 179.6708, test mnll: : 12.7604\n",
      "[559.   6.   5.   3.   2.   1.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.002  0.2808 0.068  0.0582 0.4334 0.2945 0.1765] \t\t\t\t\t self.mu.exp() \n",
      "[0.0005 0.0085 0.0865 0.0504 0.0031 0.0216 0.0962] \t\t\t\t\t self.std.exp() \n",
      "[3 4 5 5 3 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[1880.3202] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1900 th loss0 : 549.9998, test rmse : 196.3757, test mnll: : 17.2619\n",
      "[808.   8.   4.   4.   1.   1.   0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0019 0.0605 0.2808 0.0612 0.4334 0.1773 0.2944] \t\t\t\t\t self.mu.exp() \n",
      "[0.0005 0.0887 0.0085 0.0507 0.0031 0.098  0.0215] \t\t\t\t\t self.std.exp() \n",
      "[3 5 4 5 3 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[1403.9068] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2000 th loss0 : 533.4469, test rmse : 165.2761, test mnll: : 14.7206\n",
      "[1.161e+03 1.300e+01 4.000e+00 3.000e+00 1.000e+00 1.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0019 0.0591 0.066  0.2808 0.4334 0.1677 0.2947] \t\t\t\t\t self.mu.exp() \n",
      "[0.0004 0.0871 0.0504 0.0085 0.0031 0.1051 0.0215] \t\t\t\t\t self.std.exp() \n",
      "[3 5 5 4 3 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[1221.5015] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2100 th loss0 : 523.4289, test rmse : 137.0399, test mnll: : 12.2460\n",
      "[1.651e+03 2.000e+01 5.000e+00 2.000e+00 1.000e+00 1.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0017 0.0623 0.077  0.2808 0.4334 0.1734 0.2946] \t\t\t\t\t self.mu.exp() \n",
      "[0.0004 0.0823 0.0505 0.0085 0.0031 0.0971 0.0215] \t\t\t\t\t self.std.exp() \n",
      "[3 5 5 4 3 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[1098.0081] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2200 th loss0 : 513.3171, test rmse : 129.2354, test mnll: : 11.4335\n",
      "[2.342e+03 3.100e+01 8.000e+00 1.000e+00 1.000e+00 1.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0016 0.071  0.0951 0.2808 0.4333 0.1849 0.2946] \t\t\t\t\t self.mu.exp() \n",
      "[0.0004 0.075  0.0514 0.0085 0.0031 0.0903 0.0216] \t\t\t\t\t self.std.exp() \n",
      "[3 5 5 4 3 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[1060.0106] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2300 th loss0 : 504.7923, test rmse : 112.8978, test mnll: : 10.3144\n",
      "[3.312e+03 4.200e+01 1.100e+01 1.000e+00 1.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0016 0.0749 0.1064 0.2808 0.1731 0.2944 0.4334] \t\t\t\t\t self.mu.exp() \n",
      "[0.0004 0.0758 0.0516 0.0085 0.0962 0.0216 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[3 4 5 4 5 4 3] \t\t\t\t\t self.num_samplept_list_at \n",
      "[947.7352] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2400 th loss0 : 501.0919, test rmse : 106.2815, test mnll: : 9.1960\n",
      "[4.663e+03 5.700e+01 1.500e+01 2.000e+00 1.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0014 0.0715 0.1245 0.1864 0.2808 0.2946 0.4334] \t\t\t\t\t self.mu.exp() \n",
      "[0.0004 0.0771 0.0466 0.0923 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[3 4 5 5 4 4 3] \t\t\t\t\t self.num_samplept_list_at \n",
      "[922.9145] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500 th loss0 : 501.2548, test rmse : 97.0970, test mnll: : 8.5832\n",
      "[6.585e+03 6.600e+01 2.000e+01 2.000e+00 0.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.0683 0.1295 0.1777 0.2809 0.2947 0.4334] \t\t\t\t\t self.mu.exp() \n",
      "[0.0004 0.0717 0.0462 0.0959 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[3 4 5 5 4 4 3] \t\t\t\t\t self.num_samplept_list_at \n",
      "[911.0552] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2600 th loss0 : 497.5902, test rmse : 92.4415, test mnll: : 8.1982\n",
      "[9.341e+03 7.700e+01 2.500e+01 2.000e+00 0.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.0709 0.1287 0.1847 0.2809 0.2944 0.4333] \t\t\t\t\t self.mu.exp() \n",
      "[0.0005 0.0618 0.0504 0.0931 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[3 4 5 5 4 4 3] \t\t\t\t\t self.num_samplept_list_at \n",
      "[879.4969] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2700 th loss0 : 496.1175, test rmse : 92.2476, test mnll: : 7.9544\n",
      "[1.3399e+04 9.7000e+01 3.3000e+01 2.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.0763 0.1372 0.1856 0.2808 0.2946 0.4334] \t\t\t\t\t self.mu.exp() \n",
      "[0.0005 0.0548 0.0495 0.0927 0.0085 0.0216 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[3 4 5 5 4 4 3] \t\t\t\t\t self.num_samplept_list_at \n",
      "[848.8975] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2800 th loss0 : 477.2694, test rmse : 94.1003, test mnll: : 8.5855\n",
      "[1.8491e+04 1.1700e+02 4.1000e+01 3.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.0716 0.1442 0.1742 0.2808 0.2946 0.4334] \t\t\t\t\t self.mu.exp() \n",
      "[0.0005 0.052  0.0479 0.0997 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[3 4 5 5 4 4 3] \t\t\t\t\t self.num_samplept_list_at \n",
      "[784.9023] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2900 th loss0 : 487.9617, test rmse : 82.4915, test mnll: : 7.5448\n",
      "[2.5697e+04 1.3100e+02 4.6000e+01 3.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0012 0.0672 0.1395 0.1737 0.2808 0.2946 0.4333] \t\t\t\t\t self.mu.exp() \n",
      "[0.0006 0.052  0.0503 0.0978 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[3 4 5 5 4 4 3] \t\t\t\t\t self.num_samplept_list_at \n",
      "[758.8294] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3000 th loss0 : 506.3762, test rmse : 75.8653, test mnll: : 6.8823\n",
      "[3.5577e+04 1.4800e+02 5.4000e+01 3.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0011 0.0641 0.1362 0.1759 0.2808 0.2945 0.4334] \t\t\t\t\t self.mu.exp() \n",
      "[0.0006 0.0469 0.0523 0.0936 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[3 5 4 5 4 4 3] \t\t\t\t\t self.num_samplept_list_at \n",
      "[709.6219] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3100 th loss0 : 472.1604, test rmse : 81.4818, test mnll: : 7.5729\n",
      "[4.9605e+04 1.6300e+02 5.9000e+01 4.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0011 0.0653 0.1274 0.1768 0.2808 0.2946 0.4332] \t\t\t\t\t self.mu.exp() \n",
      "[0.0007 0.048  0.0563 0.0923 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[3 5 5 5 3 4 3] \t\t\t\t\t self.num_samplept_list_at \n",
      "[728.5964] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3200 th loss0 : 500.5844, test rmse : 75.8782, test mnll: : 7.2162\n",
      "[6.9984e+04 1.9700e+02 7.9000e+01 4.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0011 0.0673 0.1201 0.1718 0.2808 0.2945 0.4334] \t\t\t\t\t self.mu.exp() \n",
      "[0.0009 0.0442 0.0578 0.0967 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[3 5 5 5 3 4 3] \t\t\t\t\t self.num_samplept_list_at \n",
      "[583.8339] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3300 th loss0 : 467.8260, test rmse : 70.2136, test mnll: : 6.4840\n",
      "[9.1269e+04 2.1700e+02 9.0000e+01 5.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0011 0.0741 0.1245 0.1863 0.2809 0.2945 0.4334] \t\t\t\t\t self.mu.exp() \n",
      "[0.001  0.0413 0.0538 0.0857 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[3 5 5 5 3 4 3] \t\t\t\t\t self.num_samplept_list_at \n",
      "[613.4884] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3400 th loss0 : 487.8819, test rmse : 63.6505, test mnll: : 5.9063\n",
      "[1.0875e+05 2.4000e+02 1.0000e+02 5.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.001  0.0717 0.1326 0.1951 0.2809 0.2946 0.4334] \t\t\t\t\t self.mu.exp() \n",
      "[0.0012 0.0391 0.049  0.0815 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[3 5 5 5 3 4 3] \t\t\t\t\t self.num_samplept_list_at \n",
      "[599.0113] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3500 th loss0 : 471.4153, test rmse : 74.1701, test mnll: : 6.0705\n",
      "[1.2665e+05 2.4700e+02 1.0800e+02 6.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.001  0.0726 0.1392 0.1781 0.2809 0.2946 0.4334] \t\t\t\t\t self.mu.exp() \n",
      "[0.0013 0.038  0.0454 0.0841 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[3 5 5 5 3 4 3] \t\t\t\t\t self.num_samplept_list_at \n",
      "[589.0546] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3600 th loss0 : 492.9731, test rmse : 73.3171, test mnll: : 6.7066\n",
      "[1.4066e+05 2.7700e+02 1.0800e+02 7.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0009 0.0676 0.143  0.179  0.2808 0.2946 0.4334] \t\t\t\t\t self.mu.exp() \n",
      "[0.0014 0.0331 0.0429 0.0833 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[3 5 5 5 3 4 3] \t\t\t\t\t self.num_samplept_list_at \n",
      "[559.4424] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3700 th loss0 : 470.6581, test rmse : 66.1375, test mnll: : 6.2632\n",
      "[1.5034e+05 3.0100e+02 1.1400e+02 8.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0009 0.0711 0.143  0.1793 0.2808 0.2946 0.4334] \t\t\t\t\t self.mu.exp() \n",
      "[0.0015 0.0329 0.0422 0.0813 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[3 5 5 5 3 4 3] \t\t\t\t\t self.num_samplept_list_at \n",
      "[519.0004] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3800 th loss0 : 490.3166, test rmse : 67.6630, test mnll: : 6.2649\n",
      "[1.6274e+05 3.2100e+02 1.1200e+02 8.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0008 0.0709 0.1493 0.1774 0.2808 0.2946 0.4333] \t\t\t\t\t self.mu.exp() \n",
      "[0.0015 0.0285 0.0417 0.0796 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[3 5 4 5 4 4 3] \t\t\t\t\t self.num_samplept_list_at \n",
      "[537.349] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3900 th loss0 : 453.8153, test rmse : 75.5461, test mnll: : 7.0019\n",
      "[1.7648e+05 3.3400e+02 9.9000e+01 9.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0009 0.0694 0.1611 0.1831 0.2808 0.2946 0.4334] \t\t\t\t\t self.mu.exp() \n",
      "[0.0015 0.0241 0.0406 0.0771 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[3 5 4 5 4 4 3] \t\t\t\t\t self.num_samplept_list_at \n",
      "[577.1043] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4000 th loss0 : 465.5234, test rmse : 68.6225, test mnll: : 6.5145\n",
      "[1.851e+05 3.820e+02 7.900e+01 9.000e+00 0.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0009 0.0748 0.1555 0.1914 0.2808 0.2945 0.4334] \t\t\t\t\t self.mu.exp() \n",
      "[0.0015 0.0213 0.0412 0.0753 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[3 5 4 5 4 4 3] \t\t\t\t\t self.num_samplept_list_at \n",
      "[569.2425] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4100 th loss0 : 475.8092, test rmse : 57.8107, test mnll: : 5.8678\n",
      "[1.8925e+05 4.4100e+02 7.8000e+01 1.0000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0009 0.0774 0.1403 0.1741 0.2808 0.2946 0.4334] \t\t\t\t\t self.mu.exp() \n",
      "[0.0015 0.0167 0.0453 0.0813 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[3 5 4 5 4 4 3] \t\t\t\t\t self.num_samplept_list_at \n",
      "[450.8076] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4200 th loss0 : 442.3196, test rmse : 78.0047, test mnll: : 7.6658\n",
      "[2.0654e+05 5.5800e+02 7.5000e+01 1.1000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0009 0.0826 0.1393 0.1682 0.2808 0.2946 0.4334] \t\t\t\t\t self.mu.exp() \n",
      "[0.0015 0.0128 0.0437 0.0808 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[3 5 4 5 4 4 3] \t\t\t\t\t self.num_samplept_list_at \n",
      "[355.0535] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4300 th loss0 : 459.5447, test rmse : 64.1352, test mnll: : 6.4777\n",
      "[2.183e+05 6.840e+02 6.800e+01 1.300e+01 0.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0008 0.0815 0.1403 0.153  0.2808 0.2946 0.4335] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.0097 0.0437 0.0835 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[3 5 4 5 4 4 3] \t\t\t\t\t self.num_samplept_list_at \n",
      "[317.0301] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4400 th loss0 : 450.1962, test rmse : 54.7818, test mnll: : 5.7712\n",
      "[2.507e+05 7.720e+02 6.000e+01 1.400e+01 0.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0008 0.0837 0.1542 0.1412 0.2808 0.2946 0.4334] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.0074 0.045  0.082  0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[3 5 4 5 4 4 3] \t\t\t\t\t self.num_samplept_list_at \n",
      "[295.3436] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4500 th loss0 : 446.6455, test rmse : 41.0659, test mnll: : 5.2437\n",
      "[2.6708e+05 8.6100e+02 5.5000e+01 1.7000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0008 0.082  0.1613 0.132  0.2809 0.2946 0.4335] \t\t\t\t\t self.mu.exp() \n",
      "[0.0018 0.0058 0.0433 0.0765 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[3 4 5 5 4 4 3] \t\t\t\t\t self.num_samplept_list_at \n",
      "[282.5969] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4600 th loss0 : 446.7424, test rmse : 45.3676, test mnll: : 5.5039\n",
      "[2.6591e+05 8.6000e+02 5.3000e+01 1.8000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0007 0.0835 0.1687 0.123  0.2807 0.2946 0.4334] \t\t\t\t\t self.mu.exp() \n",
      "[0.0018 0.0048 0.0417 0.0699 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[3 4 5 5 4 4 3] \t\t\t\t\t self.num_samplept_list_at \n",
      "[280.776] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4700 th loss0 : 447.2169, test rmse : 47.5103, test mnll: : 5.6684\n",
      "[2.4648e+05 8.8100e+02 5.7000e+01 1.9000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0007 0.0829 0.1596 0.112  0.2808 0.2946 0.4333] \t\t\t\t\t self.mu.exp() \n",
      "[0.0017 0.004  0.0375 0.068  0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[3 4 5 5 4 4 3] \t\t\t\t\t self.num_samplept_list_at \n",
      "[244.5377] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4800 th loss0 : 440.4923, test rmse : 40.2914, test mnll: : 5.3506\n",
      "[2.4752e+05 9.0600e+02 6.3000e+01 2.0000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0007 0.0827 0.1665 0.1132 0.2808 0.2946 0.4334] \t\t\t\t\t self.mu.exp() \n",
      "[0.0018 0.0034 0.031  0.0664 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[3 4 5 5 4 4 3] \t\t\t\t\t self.num_samplept_list_at \n",
      "[249.1937] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4900 th loss0 : 434.8083, test rmse : 39.5784, test mnll: : 5.2187\n",
      "[2.6879e+05 9.6500e+02 7.6000e+01 2.0000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0007 0.0838 0.1644 0.1169 0.2808 0.2945 0.4333] \t\t\t\t\t self.mu.exp() \n",
      "[0.0019 0.003  0.0239 0.0686 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[3 4 5 5 4 4 3] \t\t\t\t\t self.num_samplept_list_at \n",
      "[226.9899] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "5000 th loss0 : 443.3042, test rmse : 38.3538, test mnll: : 5.3319\n",
      "[2.6956e+05 1.0000e+03 9.8000e+01 1.9000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0006 0.0837 0.176  0.1205 0.2808 0.2947 0.4334] \t\t\t\t\t self.mu.exp() \n",
      "[0.0019 0.0027 0.0177 0.0716 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[3 4 5 5 4 4 3] \t\t\t\t\t self.num_samplept_list_at \n",
      "[199.9753] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "0 init loss: 114549.3853 \n",
      "0 model chosen \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "1 init loss: 96657.1177 \n",
      "1 model chosen \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "2 init loss: 94322.9966 \n",
      "2 model chosen \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "3 init loss: 87125.6933 \n",
      "3 model chosen \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "6 init loss: 85065.3268 \n",
      "6 model chosen \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "7 init loss: 76038.6356 \n",
      "7 model chosen \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "8 init loss: 62481.7979 \n",
      "8 model chosen \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "########################################################################################################################################################################################################\n",
      "equal_reg\n",
      "########################################################################################################################################################################################################\n",
      "0 th loss0 : 47654.7387, test rmse : 548.9424, test mnll: : 5995.6369\n",
      "[1. 1. 1. 1. 1. 1. 1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0082 0.1683 0.0608 0.4131 0.2475 0.0794 0.4815] \t\t\t\t\t self.mu.exp() \n",
      "[0.0012 0.0042 0.0466 0.0115 0.0296 0.0059 0.005 ] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[19.9205] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "100 th loss0 : 47816.8419, test rmse : 493.5797, test mnll: : 3020.2136\n",
      "[2. 2. 2. 2. 2. 2. 1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0054 0.1691 0.4257 0.2567 0.0842 0.4801 0.0636] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.0034 0.0117 0.0282 0.0051 0.0051 0.0441] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[32.5914] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "200 th loss0 : 23197.0775, test rmse : 412.6867, test mnll: : 1660.1788\n",
      "[3. 3. 2. 2. 2. 2. 1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0043 0.1698 0.4132 0.2591 0.0846 0.4841 0.0628] \t\t\t\t\t self.mu.exp() \n",
      "[0.0017 0.0027 0.0117 0.027  0.0048 0.0053 0.0443] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[41.403] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "300 th loss0 : 14482.5827, test rmse : 332.7824, test mnll: : 882.9726\n",
      "[5. 4. 3. 2. 2. 2. 2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0036 0.1697 0.0902 0.0624 0.4208 0.2578 0.4669] \t\t\t\t\t self.mu.exp() \n",
      "[0.0017 0.0023 0.0051 0.0444 0.0116 0.0271 0.0057] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[50.2588] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "400 th loss0 : 12720.9600, test rmse : 287.7237, test mnll: : 542.7245\n",
      "[7. 5. 3. 3. 3. 2. 2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0032 0.1681 0.4114 0.2609 0.1329 0.062  0.4751] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.002  0.0113 0.0271 0.006  0.0446 0.0061] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[62.1657] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "500 th loss0 : 6871.7344, test rmse : 252.4702, test mnll: : 340.8886\n",
      "[9. 7. 3. 3. 3. 2. 2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0028 0.1675 0.4155 0.2622 0.242  0.0619 0.4763] \t\t\t\t\t self.mu.exp() \n",
      "[0.0014 0.0018 0.0115 0.0265 0.0059 0.0445 0.0068] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[77.5122] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "600 th loss0 : 4620.8067, test rmse : 254.3700, test mnll: : 277.7542\n",
      "[13. 10.  4.  3.  3.  2.  2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0026 0.1686 0.2637 0.406  0.3845 0.0614 0.4629] \t\t\t\t\t self.mu.exp() \n",
      "[0.0013 0.0016 0.0263 0.0115 0.0058 0.0446 0.0078] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[97.3445] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "700 th loss0 : 2903.9642, test rmse : 277.6556, test mnll: : 262.2779\n",
      "[18. 14.  4.  3.  3.  2.  2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0024 0.1687 0.2735 0.397  0.4326 0.0611 0.4403] \t\t\t\t\t self.mu.exp() \n",
      "[0.0012 0.0015 0.026  0.0127 0.0057 0.0448 0.01  ] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[126.8716] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "800 th loss0 : 2218.2580, test rmse : 256.7393, test mnll: : 170.9732\n",
      "[24. 18.  4.  3.  2.  2.  2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0023 0.1693 0.2774 0.433  0.061  0.3681 0.4089] \t\t\t\t\t self.mu.exp() \n",
      "[0.0011 0.0015 0.0261 0.0055 0.0448 0.0157 0.0132] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[171.8244] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "900 th loss0 : 1777.1896, test rmse : 242.7330, test mnll: : 112.7681\n",
      "[33. 25.  3.  3.  2.  2.  1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0022 0.1701 0.2855 0.4332 0.0609 0.3318 0.3831] \t\t\t\t\t self.mu.exp() \n",
      "[0.001  0.0016 0.0258 0.0052 0.0449 0.0177 0.0201] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[239.8398] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1000 th loss0 : 1404.5719, test rmse : 213.1572, test mnll: : 62.3492\n",
      "[45. 33.  3.  3.  2.  2.  1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0021 0.1714 0.2943 0.4332 0.0609 0.2978 0.3338] \t\t\t\t\t self.mu.exp() \n",
      "[0.0009 0.0022 0.025  0.0048 0.0448 0.0237 0.0316] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[344.5053] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1100 th loss0 : 1108.1311, test rmse : 228.4265, test mnll: : 49.9446\n",
      "[62. 39.  3.  2.  2.  2.  1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0021 0.2211 0.4333 0.0608 0.2515 0.2947 0.2984] \t\t\t\t\t self.mu.exp() \n",
      "[0.0008 0.0036 0.0044 0.0449 0.0341 0.0244 0.0479] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[511.0624] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200 th loss0 : 922.1512, test rmse : 220.4657, test mnll: : 33.7736\n",
      "[83. 32.  3.  2.  2.  2.  1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.002  0.2809 0.4333 0.0607 0.2104 0.2943 0.2636] \t\t\t\t\t self.mu.exp() \n",
      "[0.0008 0.0042 0.004  0.045  0.0483 0.0234 0.0699] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[764.7211] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1300 th loss0 : 789.1921, test rmse : 240.6539, test mnll: : 28.4262\n",
      "[113.  25.   3.   2.   2.   2.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.002  0.2808 0.4334 0.0609 0.1737 0.2943 0.2278] \t\t\t\t\t self.mu.exp() \n",
      "[0.0007 0.0052 0.0036 0.045  0.0646 0.0224 0.0917] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[1129.754] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1400 th loss0 : 714.9927, test rmse : 241.1635, test mnll: : 21.7840\n",
      "[153.  19.   3.   2.   2.   1.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.002  0.2808 0.4334 0.0612 0.1418 0.2945 0.2078] \t\t\t\t\t self.mu.exp() \n",
      "[0.0007 0.0067 0.0033 0.0451 0.0767 0.0218 0.0951] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[1610.9257] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1500 th loss0 : 660.1730, test rmse : 232.8485, test mnll: : 16.8467\n",
      "[207.  15.   3.   2.   2.   1.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.002  0.2808 0.4334 0.0616 0.12   0.2946 0.1908] \t\t\t\t\t self.mu.exp() \n",
      "[0.0007 0.008  0.0031 0.0452 0.0778 0.0216 0.0981] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[2138.9802] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1600 th loss0 : 624.9469, test rmse : 230.6537, test mnll: : 14.9079\n",
      "[284.  12.   3.   2.   2.   1.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.002  0.2808 0.1    0.0624 0.4334 0.2946 0.1804] \t\t\t\t\t self.mu.exp() \n",
      "[0.0006 0.0084 0.0822 0.0454 0.0031 0.0216 0.0983] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[2520.3199] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1700 th loss0 : 597.2696, test rmse : 216.5389, test mnll: : 14.1165\n",
      "[397.   9.   3.   2.   2.   1.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.002  0.2808 0.082  0.064  0.4334 0.2945 0.1752] \t\t\t\t\t self.mu.exp() \n",
      "[0.0006 0.0085 0.0863 0.0458 0.0031 0.0216 0.0985] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[2376.4065] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1800 th loss0 : 581.8310, test rmse : 198.5678, test mnll: : 14.9638\n",
      "[567.   6.   5.   3.   2.   1.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.002  0.2808 0.073  0.0668 0.4334 0.2946 0.1756] \t\t\t\t\t self.mu.exp() \n",
      "[0.0005 0.0085 0.0825 0.0463 0.0031 0.0216 0.0972] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[1796.9689] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1900 th loss0 : 550.3323, test rmse : 165.6667, test mnll: : 13.6970\n",
      "[816.   7.   4.   3.   2.   1.   0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0019 0.073  0.2808 0.071  0.4334 0.1712 0.2947] \t\t\t\t\t self.mu.exp() \n",
      "[0.0005 0.0712 0.0085 0.0476 0.0031 0.0978 0.0215] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[1392.4361] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2000 th loss0 : 532.4696, test rmse : 152.6035, test mnll: : 13.3612\n",
      "[1.171e+03 1.200e+01 3.000e+00 3.000e+00 1.000e+00 1.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0019 0.0613 0.2808 0.08   0.4334 0.1596 0.2948] \t\t\t\t\t self.mu.exp() \n",
      "[0.0005 0.0711 0.0085 0.0488 0.0031 0.1052 0.0215] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[1202.8474] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2100 th loss0 : 520.8150, test rmse : 135.6283, test mnll: : 11.7596\n",
      "[1.664e+03 2.000e+01 4.000e+00 2.000e+00 1.000e+00 1.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0017 0.0614 0.0936 0.2808 0.4333 0.1611 0.2945] \t\t\t\t\t self.mu.exp() \n",
      "[0.0004 0.068  0.051  0.0085 0.0031 0.1029 0.0216] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[1117.3338] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2200 th loss0 : 513.1837, test rmse : 134.5759, test mnll: : 12.1121\n",
      "[2.353e+03 3.100e+01 5.000e+00 1.000e+00 1.000e+00 1.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0016 0.0623 0.1077 0.2808 0.4334 0.1657 0.2948] \t\t\t\t\t self.mu.exp() \n",
      "[0.0005 0.07   0.0533 0.0085 0.0031 0.0989 0.0215] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[1005.8546] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2300 th loss0 : 504.6270, test rmse : 130.5379, test mnll: : 12.0871\n",
      "[3.334e+03 4.300e+01 7.000e+00 1.000e+00 1.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0015 0.0634 0.1213 0.2808 0.1664 0.2946 0.4333] \t\t\t\t\t self.mu.exp() \n",
      "[0.0005 0.0728 0.056  0.0085 0.0996 0.0216 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[943.522] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2400 th loss0 : 505.2365, test rmse : 108.0778, test mnll: : 9.8983\n",
      "[4.72e+03 5.70e+01 8.00e+00 1.00e+00 1.00e+00 0.00e+00 0.00e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0015 0.063  0.1382 0.2808 0.1705 0.2947 0.4335] \t\t\t\t\t self.mu.exp() \n",
      "[0.0006 0.0659 0.0583 0.0085 0.0976 0.0216 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[902.9648] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2500 th loss0 : 492.1715, test rmse : 100.0704, test mnll: : 8.8512\n",
      "[6.7e+03 7.8e+01 1.0e+01 1.0e+00 0.0e+00 0.0e+00 0.0e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0014 0.0655 0.1421 0.1644 0.2809 0.2944 0.4334] \t\t\t\t\t self.mu.exp() \n",
      "[0.0007 0.0623 0.0614 0.1013 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[859.5475] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2600 th loss0 : 495.7360, test rmse : 104.0842, test mnll: : 9.3418\n",
      "[9.628e+03 9.500e+01 1.300e+01 1.000e+00 0.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0014 0.0671 0.1365 0.1684 0.2808 0.2946 0.4334] \t\t\t\t\t self.mu.exp() \n",
      "[0.0009 0.0636 0.0666 0.1023 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[833.7033] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2700 th loss0 : 485.0640, test rmse : 86.5370, test mnll: : 7.2690\n",
      "[1.3561e+04 1.0900e+02 1.4000e+01 2.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0014 0.0684 0.145  0.1795 0.2808 0.2945 0.4334] \t\t\t\t\t self.mu.exp() \n",
      "[0.0011 0.0662 0.0664 0.0915 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[881.5007] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2800 th loss0 : 482.5674, test rmse : 85.9717, test mnll: : 7.5778\n",
      "[1.9121e+04 1.2200e+02 1.7000e+01 2.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0014 0.0774 0.1586 0.1781 0.2809 0.2944 0.4334] \t\t\t\t\t self.mu.exp() \n",
      "[0.0013 0.0614 0.0618 0.0961 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[763.4319] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2900 th loss0 : 494.4155, test rmse : 76.1959, test mnll: : 6.5970\n",
      "[2.6048e+04 1.2600e+02 2.0000e+01 2.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0014 0.079  0.1656 0.1863 0.2808 0.2945 0.4334] \t\t\t\t\t self.mu.exp() \n",
      "[0.0015 0.06   0.0624 0.091  0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[828.0122] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3000 th loss0 : 487.8662, test rmse : 88.5967, test mnll: : 6.6582\n",
      "[3.4653e+04 1.3500e+02 2.1000e+01 2.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.0798 0.1609 0.1809 0.2808 0.2946 0.4335] \t\t\t\t\t self.mu.exp() \n",
      "[0.0018 0.0589 0.069  0.0932 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[777.7692] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3100 th loss0 : 486.7524, test rmse : 92.4328, test mnll: : 6.7617\n",
      "[4.5871e+04 1.3500e+02 2.4000e+01 2.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.0746 0.1688 0.1669 0.2808 0.2946 0.4334] \t\t\t\t\t self.mu.exp() \n",
      "[0.0017 0.0561 0.0662 0.0985 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[743.0461] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3200 th loss0 : 489.3835, test rmse : 74.4252, test mnll: : 6.3273\n",
      "[5.7613e+04 1.4400e+02 2.5000e+01 3.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.0739 0.1814 0.1588 0.2809 0.2946 0.4334] \t\t\t\t\t self.mu.exp() \n",
      "[0.0018 0.052  0.0637 0.1045 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[742.4744] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3300 th loss0 : 472.0127, test rmse : 78.1952, test mnll: : 6.0712\n",
      "[7.2003e+04 1.4900e+02 2.7000e+01 3.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.0686 0.1767 0.1552 0.2808 0.2946 0.4333] \t\t\t\t\t self.mu.exp() \n",
      "[0.0018 0.0505 0.0644 0.1073 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[771.1503] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3400 th loss0 : 489.1675, test rmse : 71.8985, test mnll: : 6.1992\n",
      "[8.3093e+04 1.6000e+02 2.5000e+01 4.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0012 0.0666 0.1889 0.1478 0.2808 0.2946 0.4334] \t\t\t\t\t self.mu.exp() \n",
      "[0.0019 0.0513 0.0606 0.1112 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[746.0845] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3500 th loss0 : 484.0172, test rmse : 69.8968, test mnll: : 6.1270\n",
      "[8.8152e+04 1.6200e+02 2.3000e+01 4.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0012 0.0684 0.1924 0.1566 0.2808 0.2946 0.4334] \t\t\t\t\t self.mu.exp() \n",
      "[0.0017 0.052  0.0615 0.1071 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[775.2349] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3600 th loss0 : 469.5545, test rmse : 70.3777, test mnll: : 6.2650\n",
      "[9.4265e+04 1.5900e+02 2.0000e+01 5.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0011 0.0739 0.1937 0.1641 0.2807 0.2945 0.4334] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.0524 0.0614 0.1002 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[752.5898] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3700 th loss0 : 482.0818, test rmse : 73.0483, test mnll: : 5.9087\n",
      "[1.017e+05 1.600e+02 1.900e+01 5.000e+00 0.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0011 0.0698 0.1984 0.1638 0.2809 0.2946 0.4335] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.0477 0.0615 0.1061 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[765.3543] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3800 th loss0 : 482.3940, test rmse : 73.6077, test mnll: : 6.0681\n",
      "[1.0874e+05 1.6400e+02 1.9000e+01 6.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.001  0.0758 0.1972 0.1582 0.2809 0.2946 0.4334] \t\t\t\t\t self.mu.exp() \n",
      "[0.0015 0.0487 0.0615 0.1089 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[753.6497] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3900 th loss0 : 463.1035, test rmse : 73.2600, test mnll: : 6.3708\n",
      "[1.1971e+05 1.6900e+02 1.9000e+01 7.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.001  0.0759 0.2042 0.1556 0.2808 0.2946 0.4333] \t\t\t\t\t self.mu.exp() \n",
      "[0.0015 0.0469 0.0612 0.1107 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[720.5893] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4000 th loss0 : 476.9350, test rmse : 71.5084, test mnll: : 6.1028\n",
      "[1.2266e+05 1.8300e+02 1.6000e+01 8.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0009 0.0755 0.2031 0.1432 0.2808 0.2946 0.4334] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.0436 0.0625 0.1136 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[735.8859] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4100 th loss0 : 488.1785, test rmse : 71.1085, test mnll: : 6.1078\n",
      "[1.2343e+05 1.7700e+02 1.4000e+01 9.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0009 0.0796 0.207  0.1337 0.2808 0.2945 0.4334] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.0408 0.0613 0.1184 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[741.4336] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4200 th loss0 : 461.5109, test rmse : 72.2382, test mnll: : 6.5552\n",
      "[1.2421e+05 1.8900e+02 1.4000e+01 1.1000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0008 0.0787 0.192  0.1384 0.2807 0.2946 0.4334] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.0363 0.0662 0.1162 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[659.153] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4300 th loss0 : 493.5314, test rmse : 62.9953, test mnll: : 6.1425\n",
      "[1.2113e+05 1.9700e+02 1.5000e+01 1.3000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0008 0.0786 0.1946 0.1392 0.2808 0.2945 0.4334] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.0303 0.0673 0.1204 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[675.494] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4400 th loss0 : 466.7509, test rmse : 60.7215, test mnll: : 6.0351\n",
      "[1.2852e+05 2.3400e+02 1.5000e+01 1.4000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0007 0.0795 0.1935 0.1432 0.2808 0.2946 0.4333] \t\t\t\t\t self.mu.exp() \n",
      "[0.0017 0.023  0.071  0.1168 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[605.8615] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4500 th loss0 : 494.6653, test rmse : 79.1232, test mnll: : 6.6088\n",
      "[1.3186e+05 3.0100e+02 1.7000e+01 1.4000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0007 0.0781 0.1277 0.1955 0.2809 0.2946 0.4334] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.0161 0.1217 0.0724 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[552.8424] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4600 th loss0 : 466.0935, test rmse : 49.2467, test mnll: : 5.4918\n",
      "[1.3854e+05 4.4100e+02 1.8000e+01 1.4000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0007 0.0809 0.1257 0.1932 0.2808 0.2945 0.4333] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.0113 0.1206 0.076  0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[418.6444] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4700 th loss0 : 449.1592, test rmse : 46.8983, test mnll: : 5.4674\n",
      "[1.4516e+05 6.0900e+02 2.0000e+01 1.3000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0008 0.0849 0.1378 0.198  0.2808 0.2946 0.4333] \t\t\t\t\t self.mu.exp() \n",
      "[0.0015 0.0081 0.1144 0.0723 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[349.3532] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4800 th loss0 : 462.4828, test rmse : 40.3713, test mnll: : 5.2305\n",
      "[1.7104e+05 7.5900e+02 1.9000e+01 1.4000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0008 0.0803 0.1365 0.1907 0.2808 0.2945 0.4334] \t\t\t\t\t self.mu.exp() \n",
      "[0.0015 0.0066 0.1058 0.0699 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[322.9175] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4900 th loss0 : 453.4156, test rmse : 46.4337, test mnll: : 5.3733\n",
      "[1.7794e+05 8.5600e+02 1.8000e+01 1.5000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0008 0.0837 0.138  0.1798 0.2807 0.2945 0.4334] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.0054 0.1006 0.0698 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[313.1165] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "5000 th loss0 : 440.9044, test rmse : 40.6133, test mnll: : 5.2816\n",
      "[1.7727e+05 9.6200e+02 1.8000e+01 1.4000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0008 0.0833 0.1448 0.1839 0.2808 0.2946 0.4334] \t\t\t\t\t self.mu.exp() \n",
      "[0.0015 0.0043 0.0993 0.0703 0.0085 0.0215 0.0031] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[309.4931] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "##################################################\n",
      "#3 th experimnet\n",
      "0 init loss: 60942.3859 \n",
      "0 model chosen \n",
      "1 init loss: 60942.3859 \n",
      "1 model chosen \n",
      "2 init loss: 60942.3859 \n",
      "2 model chosen \n",
      "3 init loss: 60942.3859 \n",
      "3 model chosen \n",
      "4 init loss: 60942.3859 \n",
      "4 model chosen \n",
      "5 init loss: 60942.3859 \n",
      "5 model chosen \n",
      "6 init loss: 60942.3859 \n",
      "6 model chosen \n",
      "7 init loss: 60942.3859 \n",
      "7 model chosen \n",
      "8 init loss: 60942.3859 \n",
      "8 model chosen \n",
      "9 init loss: 60942.3859 \n",
      "9 model chosen \n",
      "########################################################################################################################################################################################################\n",
      "gpsm\n",
      "########################################################################################################################################################################################################\n",
      "0 th loss0 : 60108.3960, test rmse : 517.4492, test mnll: : 4766.8624\n",
      "100 th loss0 : 20941.9527, test rmse : 435.3062, test mnll: : 2219.5190\n",
      "200 th loss0 : 12215.4951, test rmse : 369.1745, test mnll: : 1267.3755\n",
      "300 th loss0 : 8224.2889, test rmse : 333.2917, test mnll: : 842.9215\n",
      "400 th loss0 : 5804.8506, test rmse : 307.4165, test mnll: : 583.4739\n",
      "500 th loss0 : 4195.7157, test rmse : 285.3006, test mnll: : 405.2731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 th loss0 : 3093.8157, test rmse : 265.8109, test mnll: : 279.2928\n",
      "700 th loss0 : 2329.4317, test rmse : 249.5979, test mnll: : 191.0348\n",
      "800 th loss0 : 1792.0213, test rmse : 237.5255, test mnll: : 130.9669\n",
      "900 th loss0 : 1409.7946, test rmse : 229.8612, test mnll: : 90.6238\n",
      "1000 th loss0 : 1137.2394, test rmse : 226.1753, test mnll: : 63.5246\n",
      "1100 th loss0 : 944.6502, test rmse : 225.4547, test mnll: : 45.2543\n",
      "1200 th loss0 : 811.0007, test rmse : 226.2507, test mnll: : 32.9930\n",
      "1300 th loss0 : 720.1065, test rmse : 226.6006, test mnll: : 24.9495\n",
      "1400 th loss0 : 658.5689, test rmse : 223.6511, test mnll: : 19.9810\n",
      "1500 th loss0 : 613.7874, test rmse : 213.0772, test mnll: : 17.5324\n",
      "1600 th loss0 : 572.3374, test rmse : 190.1541, test mnll: : 17.6182\n",
      "1700 th loss0 : 527.6451, test rmse : 157.0047, test mnll: : 18.7818\n",
      "1800 th loss0 : 477.7848, test rmse : 142.6787, test mnll: : 21.4464\n",
      "1900 th loss0 : 430.0907, test rmse : 136.9964, test mnll: : 22.2995\n",
      "2000 th loss0 : 401.3085, test rmse : 133.3045, test mnll: : 20.7874\n",
      "2100 th loss0 : 388.0144, test rmse : 124.1735, test mnll: : 16.3331\n",
      "2200 th loss0 : 376.1691, test rmse : 117.0060, test mnll: : 13.0088\n",
      "2300 th loss0 : 369.9713, test rmse : 110.9943, test mnll: : 11.0153\n",
      "2400 th loss0 : 366.0658, test rmse : 104.6029, test mnll: : 9.4546\n",
      "2500 th loss0 : 363.4046, test rmse : 97.2434, test mnll: : 8.2298\n",
      "2600 th loss0 : 361.6139, test rmse : 89.2217, test mnll: : 7.3477\n",
      "2700 th loss0 : 360.3536, test rmse : 78.8079, test mnll: : 6.6194\n",
      "2800 th loss0 : 359.4496, test rmse : 67.2214, test mnll: : 6.0288\n",
      "2900 th loss0 : 358.8078, test rmse : 56.8272, test mnll: : 5.5876\n",
      "3000 th loss0 : 358.3518, test rmse : 48.2978, test mnll: : 5.2677\n",
      "3100 th loss0 : 358.0539, test rmse : 41.5839, test mnll: : 5.0439\n",
      "3200 th loss0 : 357.8685, test rmse : 36.5400, test mnll: : 4.8913\n",
      "3300 th loss0 : 357.7594, test rmse : 32.7562, test mnll: : 4.7834\n",
      "3400 th loss0 : 357.7141, test rmse : 30.0481, test mnll: : 4.7092\n",
      "3500 th loss0 : 357.6867, test rmse : 28.7370, test mnll: : 4.6772\n",
      "3600 th loss0 : 357.6818, test rmse : 27.7778, test mnll: : 4.6511\n",
      "3700 th loss0 : 357.6829, test rmse : 27.5666, test mnll: : 4.6463\n",
      "3800 th loss0 : 357.6814, test rmse : 27.5626, test mnll: : 4.6467\n",
      "3900 th loss0 : 357.6862, test rmse : 27.6478, test mnll: : 4.6496\n",
      "4000 th loss0 : 357.6820, test rmse : 27.5320, test mnll: : 4.6457\n",
      "4100 th loss0 : 357.6833, test rmse : 27.4195, test mnll: : 4.6417\n",
      "4200 th loss0 : 357.6808, test rmse : 27.5053, test mnll: : 4.6449\n",
      "4300 th loss0 : 357.6826, test rmse : 27.5780, test mnll: : 4.6469\n",
      "4400 th loss0 : 357.6819, test rmse : 27.5707, test mnll: : 4.6468\n",
      "4500 th loss0 : 357.6810, test rmse : 27.5147, test mnll: : 4.6452\n",
      "4600 th loss0 : 357.6813, test rmse : 27.5801, test mnll: : 4.6471\n",
      "4700 th loss0 : 357.6820, test rmse : 27.5838, test mnll: : 4.6470\n",
      "4800 th loss0 : 357.6808, test rmse : 27.5679, test mnll: : 4.6468\n",
      "4900 th loss0 : 357.6813, test rmse : 27.5440, test mnll: : 4.6461\n",
      "5000 th loss0 : 357.6821, test rmse : 27.5319, test mnll: : 4.6456\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "0 init loss: 79961.2097 \n",
      "0 model chosen \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "1 init loss: 48204.0981 \n",
      "1 model chosen \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "5 init loss: 46512.4308 \n",
      "5 model chosen \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "########################################################################################################################################################################################################\n",
      "weight_reg\n",
      "########################################################################################################################################################################################################\n",
      "0 th loss0 : 104624.2177, test rmse : 533.7154, test mnll: : 5689.1989\n",
      "[1. 1. 1. 1. 1. 1. 1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0781 0.0084 0.3337 0.1714 0.4241 0.2443 0.0351] \t\t\t\t\t self.mu.exp() \n",
      "[0.006  0.0012 0.0129 0.0044 0.0058 0.0134 0.023 ] \t\t\t\t\t self.std.exp() \n",
      "[4 3 4 4 4 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[19.8914] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "100 th loss0 : 15048.4979, test rmse : 491.0023, test mnll: : 3016.9861\n",
      "[2. 2. 2. 2. 2. 2. 1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.078  0.0056 0.3343 0.1701 0.4194 0.2509 0.0346] \t\t\t\t\t self.mu.exp() \n",
      "[0.0053 0.0017 0.0128 0.0036 0.0054 0.0133 0.0226] \t\t\t\t\t self.std.exp() \n",
      "[4 3 5 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[31.9559] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "200 th loss0 : 19802.6642, test rmse : 354.3200, test mnll: : 1185.9209\n",
      "[3. 3. 3. 2. 2. 2. 2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0044 0.3333 0.1673 0.0798 0.4198 0.2572 0.0347] \t\t\t\t\t self.mu.exp() \n",
      "[0.0018 0.0118 0.0029 0.0049 0.005  0.0127 0.0221] \t\t\t\t\t self.std.exp() \n",
      "[3 5 3 4 4 5 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[41.7147] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "300 th loss0 : 13590.5013, test rmse : 328.8473, test mnll: : 840.7938\n",
      "[5. 4. 3. 3. 3. 3. 2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0037 0.1685 0.0798 0.3377 0.4229 0.2522 0.0344] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.0024 0.0043 0.011  0.0047 0.012  0.022 ] \t\t\t\t\t self.std.exp() \n",
      "[3 3 4 5 4 5 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[51.5957] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "400 th loss0 : 6544.7543, test rmse : 335.8776, test mnll: : 724.7784\n",
      "[7. 5. 4. 4. 3. 3. 2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0032 0.1683 0.0805 0.3373 0.4184 0.2496 0.0339] \t\t\t\t\t self.mu.exp() \n",
      "[0.0015 0.002  0.0036 0.0102 0.0045 0.0111 0.0221] \t\t\t\t\t self.std.exp() \n",
      "[3 3 4 5 4 5 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[61.7078] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "500 th loss0 : 4853.4114, test rmse : 290.5400, test mnll: : 454.7609\n",
      "[9. 7. 6. 5. 4. 4. 2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0029 0.1673 0.081  0.3376 0.4192 0.249  0.0336] \t\t\t\t\t self.mu.exp() \n",
      "[0.0014 0.0017 0.0032 0.0094 0.0044 0.0098 0.0221] \t\t\t\t\t self.std.exp() \n",
      "[3 3 4 5 4 5 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[74.3042] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "600 th loss0 : 4100.6959, test rmse : 272.1970, test mnll: : 320.8738\n",
      "[13. 10.  8.  7.  6.  4.  2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0026 0.1682 0.0822 0.34   0.2522 0.417  0.0332] \t\t\t\t\t self.mu.exp() \n",
      "[0.0013 0.0015 0.0028 0.0085 0.0087 0.0043 0.0221] \t\t\t\t\t self.std.exp() \n",
      "[3 3 4 5 5 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[90.5855] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "700 th loss0 : 2679.1108, test rmse : 289.6899, test mnll: : 298.0271\n",
      "[18. 13. 11. 10.  7.  5.  2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0024 0.1685 0.0809 0.3341 0.2507 0.4162 0.0328] \t\t\t\t\t self.mu.exp() \n",
      "[0.0011 0.0013 0.0026 0.0076 0.0076 0.0046 0.0222] \t\t\t\t\t self.std.exp() \n",
      "[3 3 4 5 5 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[112.7381] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "800 th loss0 : 2202.7093, test rmse : 287.4552, test mnll: : 228.1471\n",
      "[25. 18. 16. 12. 10.  5.  2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0023 0.168  0.0822 0.336  0.2488 0.4028 0.0323] \t\t\t\t\t self.mu.exp() \n",
      "[0.001  0.0012 0.0024 0.007  0.0064 0.0064 0.0224] \t\t\t\t\t self.std.exp() \n",
      "[3 3 4 5 5 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[143.2988] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "900 th loss0 : 1658.1600, test rmse : 211.0217, test mnll: : 97.3248\n",
      "[35. 25. 21. 14. 12.  4.  3.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0022 0.1681 0.082  0.3331 0.2523 0.315  0.0323] \t\t\t\t\t self.mu.exp() \n",
      "[0.0009 0.0012 0.0024 0.0066 0.0055 0.009  0.0223] \t\t\t\t\t self.std.exp() \n",
      "[3 3 4 5 4 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[187.3474] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 th loss0 : 1343.0172, test rmse : 205.4640, test mnll: : 70.5030\n",
      "[48. 33. 29. 16. 15.  3.  3.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0021 0.1682 0.0815 0.3338 0.2497 0.2558 0.0321] \t\t\t\t\t self.mu.exp() \n",
      "[0.0008 0.0012 0.0023 0.0063 0.005  0.0136 0.0224] \t\t\t\t\t self.std.exp() \n",
      "[3 3 4 5 4 5 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[252.8643] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1100 th loss0 : 1147.6964, test rmse : 249.2347, test mnll: : 77.6191\n",
      "[66. 44. 40. 16. 15.  3.  2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0021 0.1687 0.0825 0.2528 0.3309 0.032  0.2219] \t\t\t\t\t self.mu.exp() \n",
      "[0.0007 0.0014 0.0022 0.005  0.0065 0.0225 0.0199] \t\t\t\t\t self.std.exp() \n",
      "[3 3 4 4 5 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[343.4724] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1200 th loss0 : 948.0111, test rmse : 214.8664, test mnll: : 44.6546\n",
      "[91. 56. 54. 15. 12.  3.  2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.002  0.168  0.0816 0.2527 0.3316 0.0323 0.1951] \t\t\t\t\t self.mu.exp() \n",
      "[0.0007 0.0015 0.0022 0.0054 0.0077 0.0225 0.0289] \t\t\t\t\t self.std.exp() \n",
      "[3 3 4 4 5 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[472.5589] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1300 th loss0 : 839.2491, test rmse : 203.3200, test mnll: : 31.3669\n",
      "[125.  73.  70.  12.   8.   3.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0021 0.082  0.169  0.258  0.3165 0.0328 0.18  ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0006 0.0022 0.0019 0.0071 0.0113 0.0225 0.0358] \t\t\t\t\t self.std.exp() \n",
      "[3 4 3 4 5 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[650.9981] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1400 th loss0 : 760.0974, test rmse : 201.0017, test mnll: : 24.6548\n",
      "[171.  97.  84.   8.   5.   4.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0021 0.0818 0.1692 0.2649 0.3019 0.0339 0.1727] \t\t\t\t\t self.mu.exp() \n",
      "[0.0006 0.0022 0.0023 0.0108 0.0174 0.0226 0.0385] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 5 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[855.4706] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1500 th loss0 : 707.9946, test rmse : 189.6264, test mnll: : 19.6525\n",
      "[236. 129.  93.   5.   4.   4.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0021 0.0811 0.1695 0.2647 0.3007 0.0363 0.1711] \t\t\t\t\t self.mu.exp() \n",
      "[0.0005 0.0022 0.0027 0.0139 0.0227 0.0226 0.0379] \t\t\t\t\t self.std.exp() \n",
      "[3 3 4 5 5 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[1027.3297] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1600 th loss0 : 664.5055, test rmse : 191.7191, test mnll: : 19.2150\n",
      "[327. 173.  98.   4.   4.   3.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0021 0.0824 0.1688 0.2655 0.0409 0.3012 0.1712] \t\t\t\t\t self.mu.exp() \n",
      "[0.0005 0.0025 0.0028 0.0143 0.0226 0.0247 0.0378] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 5 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[1041.9988] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1700 th loss0 : 628.7037, test rmse : 161.6171, test mnll: : 16.7097\n",
      "[460. 242. 108.   4.   3.   2.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.002  0.0818 0.1694 0.0506 0.2656 0.3003 0.1709] \t\t\t\t\t self.mu.exp() \n",
      "[0.0004 0.0026 0.003  0.0227 0.0142 0.0249 0.0378] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 5 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[863.5643] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1800 th loss0 : 589.2118, test rmse : 158.4506, test mnll: : 19.0375\n",
      "[654. 345. 116.   4.   2.   1.   0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0018 0.0829 0.1669 0.0729 0.2669 0.2995 0.1712] \t\t\t\t\t self.mu.exp() \n",
      "[0.0004 0.0027 0.0026 0.0224 0.0145 0.0246 0.0376] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 5 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[627.4987] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1900 th loss0 : 554.3409, test rmse : 106.3979, test mnll: : 12.8052\n",
      "[937. 492. 126.   4.   1.   1.   0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0017 0.0827 0.1682 0.1172 0.3016 0.2646 0.171 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0004 0.0028 0.0022 0.0225 0.0246 0.0144 0.0376] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 5 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[479.2675] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2000 th loss0 : 528.0686, test rmse : 97.4391, test mnll: : 12.7288\n",
      "[1.342e+03 6.500e+02 1.350e+02 4.000e+00 1.000e+00 1.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0015 0.0823 0.1685 0.1824 0.3001 0.2644 0.171 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0004 0.0026 0.002  0.0223 0.0251 0.0141 0.0379] \t\t\t\t\t self.std.exp() \n",
      "[4 4 3 5 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[394.1856] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2100 th loss0 : 513.1805, test rmse : 108.4703, test mnll: : 14.2174\n",
      "[1.93e+03 7.80e+02 1.48e+02 3.00e+00 1.00e+00 0.00e+00 0.00e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0014 0.0825 0.1689 0.2098 0.2642 0.2992 0.171 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0003 0.0026 0.0021 0.0219 0.0142 0.0255 0.0378] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 5 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[351.6795] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2200 th loss0 : 506.7708, test rmse : 84.4290, test mnll: : 11.7901\n",
      "[2.762e+03 8.930e+02 1.520e+02 2.000e+00 1.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.0835 0.1674 0.2112 0.2642 0.3008 0.1711] \t\t\t\t\t self.mu.exp() \n",
      "[0.0004 0.0024 0.002  0.022  0.0143 0.0248 0.0377] \t\t\t\t\t self.std.exp() \n",
      "[4 4 3 5 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[319.6161] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2300 th loss0 : 496.1668, test rmse : 73.0036, test mnll: : 10.3260\n",
      "[4.002e+03 9.780e+02 1.680e+02 2.000e+00 0.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0012 0.0832 0.1682 0.2114 0.3021 0.1714 0.2648] \t\t\t\t\t self.mu.exp() \n",
      "[0.0005 0.0023 0.002  0.0216 0.0244 0.0379 0.0142] \t\t\t\t\t self.std.exp() \n",
      "[4 4 3 5 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[274.0895] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2400 th loss0 : 478.0936, test rmse : 56.1449, test mnll: : 7.5438\n",
      "[5.982e+03 1.013e+03 1.900e+02 1.000e+00 0.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0012 0.0829 0.1681 0.2128 0.3033 0.1714 0.2666] \t\t\t\t\t self.mu.exp() \n",
      "[0.0008 0.0022 0.002  0.0215 0.0248 0.0377 0.0146] \t\t\t\t\t self.std.exp() \n",
      "[4 4 3 5 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[217.3583] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2500 th loss0 : 488.6267, test rmse : 49.4272, test mnll: : 6.6533\n",
      "[8.771e+03 1.090e+03 2.130e+02 1.000e+00 0.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.0832 0.1681 0.2097 0.3001 0.1718 0.2624] \t\t\t\t\t self.mu.exp() \n",
      "[0.0011 0.0022 0.002  0.0216 0.025  0.0381 0.0143] \t\t\t\t\t self.std.exp() \n",
      "[4 4 3 5 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[180.5035] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2600 th loss0 : 568.6394, test rmse : 57.9546, test mnll: : 8.1728\n",
      "[1.2789e+04 1.1850e+03 2.2500e+02 1.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0014 0.0826 0.1673 0.2088 0.3011 0.1709 0.2625] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.0022 0.002  0.0211 0.0252 0.0382 0.0147] \t\t\t\t\t self.std.exp() \n",
      "[3 4 3 5 4 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[178.8874] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2700 th loss0 : 497.0322, test rmse : 46.2254, test mnll: : 6.6170\n",
      "[1.854e+04 1.279e+03 2.380e+02 1.000e+00 0.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0014 0.0837 0.1667 0.2125 0.3038 0.1711 0.2643] \t\t\t\t\t self.mu.exp() \n",
      "[0.0019 0.0023 0.002  0.0225 0.0252 0.038  0.0146] \t\t\t\t\t self.std.exp() \n",
      "[3 4 3 5 4 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[169.9681] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2800 th loss0 : 461.4428, test rmse : 36.4379, test mnll: : 5.1460\n",
      "[24942.  1320.   251.     0.     0.     0.     0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0015 0.0832 0.1692 0.2998 0.1715 0.2622 0.2091] \t\t\t\t\t self.mu.exp() \n",
      "[0.0019 0.0021 0.0021 0.0249 0.0378 0.0143 0.0211] \t\t\t\t\t self.std.exp() \n",
      "[4 3 3 4 4 5 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[162.8658] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2900 th loss0 : 458.3082, test rmse : 31.8182, test mnll: : 4.8760\n",
      "[33647.  1507.   264.     0.     0.     0.     0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0015 0.0837 0.1677 0.3005 0.1712 0.2627 0.2137] \t\t\t\t\t self.mu.exp() \n",
      "[0.0019 0.0022 0.002  0.0243 0.0378 0.0143 0.0214] \t\t\t\t\t self.std.exp() \n",
      "[4 3 3 4 4 5 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[161.1575] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3000 th loss0 : 455.7484, test rmse : 32.0261, test mnll: : 5.0354\n",
      "[4.4345e+04 1.4840e+03 2.8100e+02 1.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0015 0.0832 0.1671 0.2628 0.3018 0.1713 0.2113] \t\t\t\t\t self.mu.exp() \n",
      "[0.002  0.002  0.002  0.0146 0.0247 0.0378 0.0209] \t\t\t\t\t self.std.exp() \n",
      "[4 3 3 5 4 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[156.8396] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3100 th loss0 : 457.7516, test rmse : 29.0638, test mnll: : 4.8737\n",
      "[5.8335e+04 1.6250e+03 2.7700e+02 1.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0015 0.0836 0.1674 0.2636 0.3019 0.1712 0.2115] \t\t\t\t\t self.mu.exp() \n",
      "[0.002  0.0021 0.002  0.0136 0.0245 0.0378 0.0216] \t\t\t\t\t self.std.exp() \n",
      "[4 4 3 5 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[149.421] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200 th loss0 : 461.2710, test rmse : 30.2122, test mnll: : 4.9430\n",
      "[7.5167e+04 1.7370e+03 2.5200e+02 1.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0015 0.0829 0.1673 0.2584 0.2992 0.1709 0.2102] \t\t\t\t\t self.mu.exp() \n",
      "[0.0021 0.0021 0.002  0.0137 0.0244 0.0377 0.0208] \t\t\t\t\t self.std.exp() \n",
      "[4 3 4 5 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[153.6011] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3300 th loss0 : 458.7346, test rmse : 39.5417, test mnll: : 5.2257\n",
      "[9.5229e+04 1.8410e+03 2.7000e+02 1.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0016 0.0835 0.1678 0.2623 0.3009 0.1711 0.2109] \t\t\t\t\t self.mu.exp() \n",
      "[0.0021 0.002  0.0021 0.0131 0.0246 0.0377 0.0207] \t\t\t\t\t self.std.exp() \n",
      "[4 3 4 5 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[150.9304] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3400 th loss0 : 456.4728, test rmse : 43.8673, test mnll: : 5.4688\n",
      "[1.1954e+05 1.8350e+03 2.7000e+02 2.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0015 0.0842 0.1683 0.2552 0.3029 0.171  0.2112] \t\t\t\t\t self.mu.exp() \n",
      "[0.0022 0.002  0.002  0.0126 0.0244 0.0379 0.0205] \t\t\t\t\t self.std.exp() \n",
      "[4 3 4 5 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[141.4667] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3500 th loss0 : 453.4086, test rmse : 31.0370, test mnll: : 4.9886\n",
      "[1.484e+05 1.843e+03 2.550e+02 3.000e+00 0.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0015 0.0843 0.168  0.2515 0.3015 0.171  0.2098] \t\t\t\t\t self.mu.exp() \n",
      "[0.0021 0.0021 0.002  0.0102 0.025  0.0379 0.0205] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 5 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[138.8391] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3600 th loss0 : 452.9852, test rmse : 40.1642, test mnll: : 5.3429\n",
      "[1.9367e+05 1.7050e+03 2.6200e+02 5.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0014 0.0843 0.1672 0.2501 0.3011 0.1711 0.21  ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0023 0.0021 0.002  0.0072 0.0247 0.0378 0.0207] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[134.7497] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3700 th loss0 : 465.6998, test rmse : 33.1952, test mnll: : 5.0001\n",
      "[2.2477e+05 1.6370e+03 2.4100e+02 8.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0014 0.0829 0.1684 0.2486 0.2997 0.1711 0.2101] \t\t\t\t\t self.mu.exp() \n",
      "[0.0024 0.002  0.0019 0.005  0.0247 0.0379 0.0206] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 4 5 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[131.8794] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3800 th loss0 : 452.9690, test rmse : 42.2858, test mnll: : 5.5264\n",
      "[2.7221e+05 1.6740e+03 2.5500e+02 1.2000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0014 0.0828 0.1697 0.25   0.2999 0.1711 0.2105] \t\t\t\t\t self.mu.exp() \n",
      "[0.0024 0.002  0.002  0.0042 0.0247 0.0378 0.0206] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 4 5 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[135.6131] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3900 th loss0 : 453.1967, test rmse : 50.3882, test mnll: : 5.5952\n",
      "[2.7818e+05 1.6570e+03 2.5600e+02 1.5000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.0836 0.1679 0.252  0.3009 0.1711 0.2104] \t\t\t\t\t self.mu.exp() \n",
      "[0.0024 0.002  0.002  0.0037 0.0248 0.0379 0.0206] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 4 4 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[126.8693] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4000 th loss0 : 458.5031, test rmse : 35.3589, test mnll: : 5.0841\n",
      "[2.889e+05 1.709e+03 2.870e+02 1.600e+01 0.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.0831 0.167  0.2499 0.3001 0.1711 0.2104] \t\t\t\t\t self.mu.exp() \n",
      "[0.0024 0.0021 0.0021 0.0034 0.0246 0.0379 0.0206] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 4 5 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[128.5815] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4100 th loss0 : 455.8030, test rmse : 41.4464, test mnll: : 5.3943\n",
      "[3.1468e+05 1.7750e+03 2.7600e+02 1.6000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.0831 0.1667 0.2503 0.3005 0.1712 0.2104] \t\t\t\t\t self.mu.exp() \n",
      "[0.0025 0.0021 0.0021 0.0035 0.0251 0.0379 0.0206] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 4 5 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[125.8671] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4200 th loss0 : 459.2759, test rmse : 55.1772, test mnll: : 6.0167\n",
      "[3.3548e+05 1.7360e+03 2.6600e+02 1.7000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.0838 0.1682 0.2483 0.3018 0.171  0.2106] \t\t\t\t\t self.mu.exp() \n",
      "[0.0024 0.002  0.002  0.0035 0.0248 0.0379 0.0206] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 4 4 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[124.8615] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4300 th loss0 : 454.3116, test rmse : 36.7566, test mnll: : 5.2145\n",
      "[3.554e+05 1.852e+03 2.580e+02 1.700e+01 0.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.0837 0.1681 0.2506 0.3007 0.171  0.2107] \t\t\t\t\t self.mu.exp() \n",
      "[0.0026 0.002  0.002  0.0036 0.0247 0.0379 0.0206] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 4 4 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[121.584] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4400 th loss0 : 463.9886, test rmse : 50.5436, test mnll: : 6.3275\n",
      "[3.5602e+05 1.7450e+03 2.5700e+02 1.7000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.0844 0.1687 0.2496 0.3001 0.1711 0.2105] \t\t\t\t\t self.mu.exp() \n",
      "[0.0025 0.002  0.002  0.0035 0.0247 0.0379 0.0206] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 4 4 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[124.9656] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4500 th loss0 : 451.6011, test rmse : 55.4865, test mnll: : 5.8366\n",
      "[3.8196e+05 1.6730e+03 2.4800e+02 1.6000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.0842 0.1683 0.249  0.3003 0.1711 0.2104] \t\t\t\t\t self.mu.exp() \n",
      "[0.0025 0.002  0.0019 0.0035 0.0244 0.0379 0.0206] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 4 4 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[120.4849] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4600 th loss0 : 456.0974, test rmse : 52.2467, test mnll: : 5.9596\n",
      "[3.835e+05 1.659e+03 2.490e+02 1.700e+01 0.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.0845 0.167  0.2512 0.3012 0.1711 0.2106] \t\t\t\t\t self.mu.exp() \n",
      "[0.0025 0.002  0.002  0.0033 0.025  0.0379 0.0206] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 4 4 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[121.5935] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4700 th loss0 : 453.7187, test rmse : 39.6050, test mnll: : 5.5246\n",
      "[3.9011e+05 1.6350e+03 2.5600e+02 1.7000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.0837 0.1692 0.2497 0.3022 0.1711 0.2105] \t\t\t\t\t self.mu.exp() \n",
      "[0.0025 0.002  0.002  0.0034 0.0249 0.0379 0.0206] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 4 4 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[122.7526] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4800 th loss0 : 454.1572, test rmse : 37.6074, test mnll: : 5.6201\n",
      "[3.9891e+05 1.6340e+03 2.8000e+02 1.7000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0012 0.0838 0.1681 0.2509 0.3006 0.1711 0.2105] \t\t\t\t\t self.mu.exp() \n",
      "[0.0026 0.002  0.0021 0.0034 0.0248 0.0379 0.0206] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 4 5 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[122.5578] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4900 th loss0 : 455.1287, test rmse : 32.0253, test mnll: : 4.9149\n",
      "[3.8893e+05 1.6980e+03 2.6200e+02 1.7000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0011 0.084  0.1688 0.2509 0.2986 0.1711 0.2105] \t\t\t\t\t self.mu.exp() \n",
      "[0.0026 0.002  0.002  0.0033 0.0245 0.0379 0.0206] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 4 4 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[122.5831] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "5000 th loss0 : 454.7559, test rmse : 34.5152, test mnll: : 5.1388\n",
      "[3.8236e+05 1.8070e+03 2.7100e+02 1.7000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0011 0.083  0.168  0.2489 0.3009 0.1711 0.2105] \t\t\t\t\t self.mu.exp() \n",
      "[0.0026 0.0021 0.0021 0.0033 0.0246 0.0379 0.0206] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 4 4 4 5] \t\t\t\t\t self.num_samplept_list_at \n",
      "[122.7353] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "0 init loss: 92798.1082 \n",
      "0 model chosen \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "1 init loss: 82525.8335 \n",
      "1 model chosen \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 init loss: 71994.7554 \n",
      "3 model chosen \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "5 init loss: 60176.3526 \n",
      "5 model chosen \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "9 init loss: 46903.6749 \n",
      "9 model chosen \n",
      "########################################################################################################################################################################################################\n",
      "equal_reg\n",
      "########################################################################################################################################################################################################\n",
      "0 th loss0 : 67678.6587, test rmse : 530.9249, test mnll: : 5716.1102\n",
      "[1. 1. 1. 1. 1. 1. 1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.078  0.0083 0.3412 0.1717 0.4281 0.2589 0.0348] \t\t\t\t\t self.mu.exp() \n",
      "[0.0059 0.0012 0.0125 0.0047 0.0058 0.0128 0.0227] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[19.567] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "100 th loss0 : 24612.5579, test rmse : 461.2946, test mnll: : 2726.3738\n",
      "[2. 2. 2. 2. 2. 2. 1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0769 0.0055 0.3498 0.1672 0.4237 0.2524 0.0347] \t\t\t\t\t self.mu.exp() \n",
      "[0.0053 0.0016 0.0122 0.0041 0.0056 0.0119 0.0221] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[31.2043] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "200 th loss0 : 13665.2045, test rmse : 380.8486, test mnll: : 1426.7832\n",
      "[3. 3. 3. 2. 2. 2. 2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0798 0.0044 0.1687 0.3389 0.4188 0.2513 0.0335] \t\t\t\t\t self.mu.exp() \n",
      "[0.0046 0.0018 0.0033 0.0115 0.0051 0.0113 0.0226] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[40.1226] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "300 th loss0 : 9209.6784, test rmse : 320.8950, test mnll: : 833.0853\n",
      "[5. 4. 3. 3. 3. 3. 2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0037 0.1681 0.0801 0.3382 0.4177 0.253  0.0325] \t\t\t\t\t self.mu.exp() \n",
      "[0.0017 0.0026 0.0039 0.0107 0.0047 0.0103 0.0231] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[48.6924] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "400 th loss0 : 6236.7061, test rmse : 324.1836, test mnll: : 718.1180\n",
      "[7. 5. 5. 4. 4. 3. 2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0033 0.0801 0.168  0.3365 0.2541 0.4184 0.032 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0017 0.0034 0.0021 0.0097 0.0089 0.0045 0.0232] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[57.6872] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "500 th loss0 : 4478.4316, test rmse : 337.5700, test mnll: : 637.8320\n",
      "[9. 7. 6. 5. 5. 4. 2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0029 0.1683 0.0805 0.3365 0.2527 0.4193 0.0318] \t\t\t\t\t self.mu.exp() \n",
      "[0.0015 0.0018 0.003  0.009  0.0078 0.0043 0.0232] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[69.6348] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "600 th loss0 : 4008.0121, test rmse : 302.8685, test mnll: : 415.4390\n",
      "[13. 10.  8.  7.  7.  5.  2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0027 0.1676 0.0808 0.3348 0.2528 0.4169 0.0317] \t\t\t\t\t self.mu.exp() \n",
      "[0.0014 0.0016 0.0027 0.0081 0.0067 0.0044 0.0231] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[85.2239] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "700 th loss0 : 2722.1051, test rmse : 233.5843, test mnll: : 200.1273\n",
      "[18. 13. 12.  9.  9.  5.  2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0024 0.1686 0.0812 0.3318 0.2522 0.413  0.0316] \t\t\t\t\t self.mu.exp() \n",
      "[0.0012 0.0014 0.0025 0.0072 0.0057 0.0049 0.0231] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[106.6152] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "800 th loss0 : 2177.9419, test rmse : 204.1861, test mnll: : 118.7696\n",
      "[25. 18. 16. 11. 11.  5.  2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0023 0.1679 0.0808 0.3372 0.2484 0.3918 0.0313] \t\t\t\t\t self.mu.exp() \n",
      "[0.0011 0.0013 0.0023 0.0066 0.005  0.0071 0.0231] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[135.8501] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "900 th loss0 : 1736.2874, test rmse : 207.2177, test mnll: : 98.3444\n",
      "[34. 25. 22. 14. 13.  4.  3.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0022 0.1677 0.0805 0.2508 0.3309 0.308  0.031 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.001  0.0013 0.0023 0.0045 0.0062 0.0097 0.0232] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[177.3403] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1000 th loss0 : 1382.1750, test rmse : 231.9817, test mnll: : 92.2977\n",
      "[47. 33. 31. 17. 15.  3.  3.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0021 0.1677 0.0813 0.2488 0.3323 0.2525 0.0309] \t\t\t\t\t self.mu.exp() \n",
      "[0.001  0.0013 0.0023 0.0042 0.0057 0.0141 0.0232] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[238.7679] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1100 th loss0 : 1131.3688, test rmse : 199.1138, test mnll: : 51.5745\n",
      "[65. 44. 42. 18. 15.  3.  2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0021 0.1686 0.0817 0.2506 0.3289 0.0309 0.2185] \t\t\t\t\t self.mu.exp() \n",
      "[0.0009 0.0014 0.0023 0.0043 0.0056 0.0232 0.0203] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[329.8033] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1200 th loss0 : 985.0786, test rmse : 215.3938, test mnll: : 45.5055\n",
      "[89. 57. 56. 17. 13.  3.  2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.002  0.082  0.1677 0.2516 0.3317 0.0311 0.1941] \t\t\t\t\t self.mu.exp() \n",
      "[0.0008 0.0024 0.0017 0.0048 0.0066 0.0232 0.0289] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[460.5723] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1300 th loss0 : 848.4006, test rmse : 217.1178, test mnll: : 35.2297\n",
      "[122.  76.  70.  14.   9.   3.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.002  0.0816 0.1678 0.2535 0.3246 0.0316 0.1806] \t\t\t\t\t self.mu.exp() \n",
      "[0.0007 0.0024 0.0019 0.0064 0.0095 0.0232 0.0357] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[639.0097] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1400 th loss0 : 764.1885, test rmse : 223.9270, test mnll: : 29.0011\n",
      "[167. 102.  83.   9.   6.   4.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.002  0.0823 0.1684 0.2626 0.3047 0.0326 0.1732] \t\t\t\t\t self.mu.exp() \n",
      "[0.0007 0.0024 0.0022 0.0097 0.015  0.0232 0.0382] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[856.9347] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1500 th loss0 : 709.5388, test rmse : 190.6692, test mnll: : 19.3129\n",
      "[230. 135.  93.   6.   4.   4.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0021 0.0827 0.1673 0.2648 0.3013 0.0346 0.1711] \t\t\t\t\t self.mu.exp() \n",
      "[0.0006 0.0025 0.0027 0.0133 0.0213 0.0232 0.0381] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[1044.8315] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1600 th loss0 : 666.4581, test rmse : 178.1118, test mnll: : 16.9373\n",
      "[319. 182.  97.   4.   4.   3.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.002  0.0818 0.1689 0.266  0.0385 0.301  0.1707] \t\t\t\t\t self.mu.exp() \n",
      "[0.0006 0.0026 0.003  0.0144 0.0233 0.0245 0.038 ] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[1066.8066] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1700 th loss0 : 634.9905, test rmse : 168.1442, test mnll: : 17.5107\n",
      "[448. 252. 104.   4.   3.   2.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.002  0.0822 0.1686 0.0465 0.2651 0.3006 0.1714] \t\t\t\t\t self.mu.exp() \n",
      "[0.0005 0.0027 0.003  0.0232 0.0144 0.0251 0.0378] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[861.9954] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1800 th loss0 : 596.1119, test rmse : 148.7648, test mnll: : 17.5684\n",
      "[638. 356. 117.   5.   2.   1.   0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0019 0.0815 0.1682 0.064  0.2652 0.3008 0.1714] \t\t\t\t\t self.mu.exp() \n",
      "[0.0005 0.0027 0.0026 0.0235 0.0145 0.0244 0.038 ] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[613.5954] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1900 th loss0 : 562.1895, test rmse : 110.6905, test mnll: : 13.0633\n",
      "[913. 486. 132.   5.   1.   1.   0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0016 0.0817 0.1668 0.1006 0.3022 0.266  0.172 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0005 0.0026 0.0021 0.0238 0.0255 0.0143 0.0379] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[468.1377] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 th loss0 : 533.7767, test rmse : 119.8734, test mnll: : 16.8473\n",
      "[1.315e+03 6.310e+02 1.370e+02 4.000e+00 1.000e+00 1.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0015 0.0818 0.1664 0.1645 0.2958 0.2631 0.1706] \t\t\t\t\t self.mu.exp() \n",
      "[0.0004 0.0025 0.0021 0.0234 0.0245 0.0146 0.0382] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[385.0205] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2100 th loss0 : 512.7181, test rmse : 93.4513, test mnll: : 12.5118\n",
      "[1.895e+03 7.830e+02 1.420e+02 3.000e+00 1.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0014 0.082  0.1685 0.2088 0.2656 0.3018 0.1706] \t\t\t\t\t self.mu.exp() \n",
      "[0.0005 0.0024 0.002  0.0231 0.0144 0.0248 0.0378] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[356.0677] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2200 th loss0 : 504.4842, test rmse : 75.5022, test mnll: : 9.2930\n",
      "[2.718e+03 9.410e+02 1.500e+02 3.000e+00 1.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.082  0.1668 0.2125 0.2662 0.3016 0.1713] \t\t\t\t\t self.mu.exp() \n",
      "[0.0006 0.0024 0.0019 0.0231 0.0144 0.0249 0.0377] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[307.9633] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2300 th loss0 : 489.0623, test rmse : 58.7941, test mnll: : 7.4766\n",
      "[4.052e+03 1.033e+03 1.800e+02 2.000e+00 0.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.0831 0.1678 0.2121 0.3009 0.1717 0.2643] \t\t\t\t\t self.mu.exp() \n",
      "[0.0009 0.0023 0.002  0.0226 0.0244 0.0386 0.0145] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[236.5032] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2400 th loss0 : 471.3080, test rmse : 50.7440, test mnll: : 7.1520\n",
      "[5.959e+03 1.125e+03 1.810e+02 1.000e+00 0.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0012 0.0842 0.1676 0.2082 0.2993 0.1714 0.2637] \t\t\t\t\t self.mu.exp() \n",
      "[0.0012 0.0022 0.0019 0.0214 0.0252 0.0382 0.0143] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[210.6271] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2500 th loss0 : 464.2577, test rmse : 47.8758, test mnll: : 6.3199\n",
      "[8.753e+03 1.177e+03 2.020e+02 1.000e+00 0.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0014 0.0823 0.1682 0.2129 0.3008 0.1702 0.2639] \t\t\t\t\t self.mu.exp() \n",
      "[0.0013 0.0022 0.002  0.0214 0.025  0.038  0.0145] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[181.1115] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2600 th loss0 : 462.9063, test rmse : 43.8959, test mnll: : 6.2522\n",
      "[1.2391e+04 1.1690e+03 2.0200e+02 1.0000e+00 1.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0014 0.0832 0.1686 0.266  0.2124 0.2989 0.1714] \t\t\t\t\t self.mu.exp() \n",
      "[0.0015 0.0021 0.002  0.0142 0.0221 0.0251 0.0378] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[169.6196] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2700 th loss0 : 461.1452, test rmse : 60.9954, test mnll: : 6.5538\n",
      "[1.7249e+04 1.3160e+03 2.0000e+02 1.0000e+00 1.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.0832 0.1658 0.2639 0.2105 0.3023 0.1708] \t\t\t\t\t self.mu.exp() \n",
      "[0.0018 0.0021 0.002  0.0145 0.0214 0.0246 0.038 ] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[173.8595] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2800 th loss0 : 472.6970, test rmse : 37.3831, test mnll: : 5.5293\n",
      "[2.3561e+04 1.2630e+03 2.2300e+02 1.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0014 0.0837 0.1686 0.2622 0.2998 0.1715 0.2126] \t\t\t\t\t self.mu.exp() \n",
      "[0.0018 0.0021 0.002  0.0144 0.0248 0.0376 0.0215] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[158.3731] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2900 th loss0 : 462.5422, test rmse : 30.7190, test mnll: : 4.9259\n",
      "[3.2792e+04 1.4190e+03 2.3800e+02 1.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0016 0.0834 0.1677 0.2618 0.3001 0.1708 0.2106] \t\t\t\t\t self.mu.exp() \n",
      "[0.0018 0.0022 0.0021 0.0142 0.0249 0.0379 0.0211] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[156.3242] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3000 th loss0 : 455.1286, test rmse : 36.9805, test mnll: : 5.2348\n",
      "[4.4394e+04 1.3680e+03 2.3900e+02 1.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0017 0.0839 0.1678 0.2609 0.304  0.1712 0.2095] \t\t\t\t\t self.mu.exp() \n",
      "[0.0018 0.0021 0.002  0.0138 0.025  0.0381 0.021 ] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[154.0256] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3100 th loss0 : 453.6564, test rmse : 40.5860, test mnll: : 5.4447\n",
      "[5.8112e+04 1.3480e+03 2.2700e+02 1.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0016 0.0841 0.1682 0.2593 0.3002 0.171  0.2111] \t\t\t\t\t self.mu.exp() \n",
      "[0.0021 0.0021 0.0019 0.0134 0.0247 0.038  0.0205] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[145.7231] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3200 th loss0 : 461.1842, test rmse : 32.9932, test mnll: : 5.0230\n",
      "[7.4952e+04 1.4280e+03 2.3900e+02 2.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0015 0.0838 0.168  0.2603 0.3009 0.1712 0.2102] \t\t\t\t\t self.mu.exp() \n",
      "[0.0023 0.0021 0.002  0.013  0.0249 0.0378 0.0208] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[148.9] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3300 th loss0 : 455.3917, test rmse : 33.3484, test mnll: : 5.0646\n",
      "[9.5118e+04 1.4710e+03 2.5500e+02 2.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0016 0.0831 0.1683 0.2612 0.2998 0.1711 0.2111] \t\t\t\t\t self.mu.exp() \n",
      "[0.0021 0.0021 0.002  0.0118 0.0247 0.0379 0.021 ] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[140.2463] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3400 th loss0 : 459.0159, test rmse : 41.8075, test mnll: : 5.6670\n",
      "[1.2474e+05 1.5730e+03 2.5000e+02 3.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0017 0.0836 0.1695 0.2563 0.3018 0.1712 0.2109] \t\t\t\t\t self.mu.exp() \n",
      "[0.0022 0.0021 0.0019 0.0101 0.0247 0.0378 0.0208] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[141.4486] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3500 th loss0 : 450.1029, test rmse : 69.6706, test mnll: : 6.1847\n",
      "[1.5376e+05 1.5650e+03 2.6500e+02 5.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0017 0.0842 0.1681 0.2526 0.3005 0.1709 0.2098] \t\t\t\t\t self.mu.exp() \n",
      "[0.0022 0.0021 0.0019 0.0076 0.0246 0.0379 0.0207] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[134.3034] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3600 th loss0 : 453.6434, test rmse : 40.3867, test mnll: : 5.2594\n",
      "[1.9061e+05 1.6080e+03 2.6600e+02 9.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0017 0.0826 0.1682 0.2516 0.3021 0.1711 0.2105] \t\t\t\t\t self.mu.exp() \n",
      "[0.0022 0.0021 0.0018 0.0054 0.0244 0.0379 0.0205] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[125.9394] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3700 th loss0 : 454.8671, test rmse : 40.0367, test mnll: : 5.4980\n",
      "[2.0911e+05 1.6280e+03 2.7100e+02 1.2000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0018 0.0839 0.1683 0.2502 0.3032 0.1711 0.2104] \t\t\t\t\t self.mu.exp() \n",
      "[0.0021 0.002  0.0017 0.0045 0.0251 0.0378 0.0206] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[121.4817] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3800 th loss0 : 451.5423, test rmse : 51.0722, test mnll: : 5.7006\n",
      "[2.2092e+05 1.6970e+03 2.6900e+02 1.5000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0018 0.0838 0.1685 0.2525 0.299  0.171  0.21  ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0021 0.002  0.0019 0.0039 0.0244 0.0379 0.0206] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[121.5956] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3900 th loss0 : 454.0680, test rmse : 36.9886, test mnll: : 5.2553\n",
      "[2.3504e+05 1.7220e+03 2.5300e+02 1.7000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0019 0.0836 0.1672 0.2504 0.3033 0.171  0.2104] \t\t\t\t\t self.mu.exp() \n",
      "[0.002  0.002  0.0018 0.0036 0.025  0.0379 0.0206] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[122.2308] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4000 th loss0 : 455.4208, test rmse : 42.5344, test mnll: : 5.4209\n",
      "[2.3987e+05 1.7810e+03 2.5200e+02 1.7000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0018 0.0848 0.1673 0.2488 0.3015 0.1711 0.2104] \t\t\t\t\t self.mu.exp() \n",
      "[0.002  0.002  0.0019 0.0035 0.0248 0.0379 0.0206] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[127.2189] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4100 th loss0 : 456.4792, test rmse : 50.8424, test mnll: : 5.9498\n",
      "[2.5122e+05 1.8240e+03 2.6800e+02 1.7000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0017 0.0842 0.1669 0.249  0.3014 0.1711 0.2106] \t\t\t\t\t self.mu.exp() \n",
      "[0.0022 0.002  0.0019 0.0034 0.0243 0.0379 0.0206] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[122.8214] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4200 th loss0 : 450.7942, test rmse : 42.5354, test mnll: : 5.4342\n",
      "[2.5276e+05 1.7740e+03 2.5400e+02 1.7000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0016 0.0836 0.167  0.2503 0.2998 0.171  0.2106] \t\t\t\t\t self.mu.exp() \n",
      "[0.0024 0.0019 0.0019 0.0034 0.0246 0.0379 0.0206] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[120.8676] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4300 th loss0 : 454.3365, test rmse : 51.8362, test mnll: : 5.5862\n",
      "[2.591e+05 1.825e+03 2.700e+02 1.700e+01 0.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0016 0.0831 0.1676 0.2507 0.3008 0.1711 0.2105] \t\t\t\t\t self.mu.exp() \n",
      "[0.0025 0.0019 0.002  0.0034 0.0246 0.0378 0.0206] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[123.2559] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4400 th loss0 : 452.5740, test rmse : 41.0212, test mnll: : 5.3391\n",
      "[2.4924e+05 1.8740e+03 2.8000e+02 1.6000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0016 0.0839 0.1688 0.2503 0.3009 0.1711 0.2106] \t\t\t\t\t self.mu.exp() \n",
      "[0.0027 0.0018 0.002  0.0033 0.0246 0.0378 0.0206] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[120.7515] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4500 th loss0 : 454.9724, test rmse : 83.4442, test mnll: : 6.7316\n",
      "[2.4498e+05 1.8750e+03 2.7800e+02 1.6000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0016 0.0838 0.1676 0.2503 0.3006 0.1711 0.2105] \t\t\t\t\t self.mu.exp() \n",
      "[0.0032 0.0018 0.002  0.0032 0.0247 0.0379 0.0206] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[115.8894] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4600 th loss0 : 451.8448, test rmse : 62.2936, test mnll: : 5.8680\n",
      "[2.4623e+05 1.9700e+03 2.7700e+02 1.7000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0015 0.0837 0.1674 0.2506 0.3015 0.1711 0.2105] \t\t\t\t\t self.mu.exp() \n",
      "[0.0033 0.002  0.002  0.0035 0.0248 0.0379 0.0206] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[119.0156] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4700 th loss0 : 449.0569, test rmse : 40.7848, test mnll: : 5.2857\n",
      "[2.2708e+05 1.9190e+03 2.7600e+02 1.6000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0015 0.0829 0.1679 0.25   0.3008 0.171  0.2105] \t\t\t\t\t self.mu.exp() \n",
      "[0.0034 0.002  0.002  0.0034 0.0249 0.0379 0.0206] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[117.2694] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4800 th loss0 : 452.4734, test rmse : 51.3258, test mnll: : 5.8135\n",
      "[2.4686e+05 1.8350e+03 2.7600e+02 1.7000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0015 0.0838 0.1687 0.2499 0.3007 0.1711 0.2105] \t\t\t\t\t self.mu.exp() \n",
      "[0.0036 0.0019 0.002  0.0033 0.0249 0.0379 0.0206] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[117.5959] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4900 th loss0 : 452.8198, test rmse : 45.0478, test mnll: : 5.6278\n",
      "[2.6333e+05 1.8620e+03 2.8400e+02 1.6000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0014 0.0837 0.1675 0.25   0.3016 0.1711 0.2105] \t\t\t\t\t self.mu.exp() \n",
      "[0.0037 0.002  0.002  0.0034 0.0248 0.0379 0.0206] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[118.1936] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "5000 th loss0 : 451.5968, test rmse : 52.2026, test mnll: : 5.9557\n",
      "[2.7557e+05 1.7880e+03 2.6400e+02 1.7000e+01 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0014 0.0835 0.1683 0.2488 0.3013 0.1711 0.2105] \t\t\t\t\t self.mu.exp() \n",
      "[0.0038 0.0019 0.0019 0.0034 0.0248 0.0379 0.0206] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[114.2432] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "##################################################\n",
      "#4 th experimnet\n",
      "0 init loss: 50971.9904 \n",
      "0 model chosen \n",
      "1 init loss: 50971.9904 \n",
      "1 model chosen \n",
      "2 init loss: 50971.9904 \n",
      "2 model chosen \n",
      "3 init loss: 50971.9904 \n",
      "3 model chosen \n",
      "4 init loss: 50971.9904 \n",
      "4 model chosen \n",
      "5 init loss: 50971.9904 \n",
      "5 model chosen \n",
      "6 init loss: 50971.9904 \n",
      "6 model chosen \n",
      "7 init loss: 50971.9904 \n",
      "7 model chosen \n",
      "8 init loss: 50971.9904 \n",
      "8 model chosen \n",
      "9 init loss: 50971.9904 \n",
      "9 model chosen \n",
      "########################################################################################################################################################################################################\n",
      "gpsm\n",
      "########################################################################################################################################################################################################\n",
      "0 th loss0 : 50525.0335, test rmse : 423.3803, test mnll: : 3118.9555\n",
      "100 th loss0 : 26766.2851, test rmse : 403.1963, test mnll: : 1590.8210\n",
      "200 th loss0 : 16240.2866, test rmse : 399.1731, test mnll: : 907.3296\n",
      "300 th loss0 : 10214.3129, test rmse : 398.6651, test mnll: : 525.5916\n",
      "400 th loss0 : 6541.6123, test rmse : 400.2293, test mnll: : 305.2084\n",
      "500 th loss0 : 4248.8873, test rmse : 403.2483, test mnll: : 178.2843\n",
      "600 th loss0 : 2816.7069, test rmse : 406.9438, test mnll: : 105.8515\n",
      "700 th loss0 : 1933.5867, test rmse : 410.5262, test mnll: : 64.6576\n",
      "800 th loss0 : 1398.0186, test rmse : 413.4996, test mnll: : 41.1180\n",
      "900 th loss0 : 1077.7307, test rmse : 415.7287, test mnll: : 27.5047\n",
      "1000 th loss0 : 888.3861, test rmse : 417.2997, test mnll: : 19.5091\n",
      "1100 th loss0 : 778.0971, test rmse : 418.3685, test mnll: : 14.7457\n",
      "1200 th loss0 : 715.5548, test rmse : 419.0809, test mnll: : 11.8825\n",
      "1300 th loss0 : 681.8388, test rmse : 419.5485, test mnll: : 10.1617\n",
      "1400 th loss0 : 665.2801, test rmse : 419.8488, test mnll: : 9.1416\n",
      "1500 th loss0 : 658.4223, test rmse : 420.0330, test mnll: : 8.5589\n",
      "1600 th loss0 : 656.3525, test rmse : 420.1328, test mnll: : 8.2540\n",
      "1700 th loss0 : 656.0061, test rmse : 420.1684, test mnll: : 8.1255\n",
      "1800 th loss0 : 655.9776, test rmse : 420.1584, test mnll: : 8.0942\n",
      "1900 th loss0 : 655.9581, test rmse : 420.1184, test mnll: : 8.0928\n",
      "2000 th loss0 : 655.9228, test rmse : 420.0397, test mnll: : 8.0940\n",
      "2100 th loss0 : 655.8522, test rmse : 419.8705, test mnll: : 8.0963\n",
      "2200 th loss0 : 655.6863, test rmse : 419.4258, test mnll: : 8.1012\n",
      "2300 th loss0 : 655.2024, test rmse : 417.8385, test mnll: : 8.1136\n",
      "2400 th loss0 : 653.7110, test rmse : 411.4396, test mnll: : 8.1424\n",
      "2500 th loss0 : 649.6642, test rmse : 391.5658, test mnll: : 8.2174\n",
      "2600 th loss0 : 635.9252, test rmse : 322.6082, test mnll: : 8.7389\n",
      "2700 th loss0 : 592.3362, test rmse : 219.1955, test mnll: : 10.6445\n",
      "2800 th loss0 : 519.6601, test rmse : 150.8038, test mnll: : 16.2451\n",
      "2900 th loss0 : 484.9008, test rmse : 133.6949, test mnll: : 16.2674\n",
      "3000 th loss0 : 455.7848, test rmse : 120.9598, test mnll: : 13.7916\n",
      "3100 th loss0 : 422.9342, test rmse : 239.8260, test mnll: : 21.1402\n",
      "3200 th loss0 : 405.1701, test rmse : 254.1717, test mnll: : 18.5861\n",
      "3300 th loss0 : 393.4496, test rmse : 251.8186, test mnll: : 15.7984\n",
      "3400 th loss0 : 382.5415, test rmse : 249.3325, test mnll: : 13.8555\n",
      "3500 th loss0 : 376.9452, test rmse : 250.6459, test mnll: : 12.4730\n",
      "3600 th loss0 : 373.4109, test rmse : 255.0314, test mnll: : 11.5859\n",
      "3700 th loss0 : 371.0026, test rmse : 259.4620, test mnll: : 10.9326\n",
      "3800 th loss0 : 369.9928, test rmse : 262.9824, test mnll: : 10.4143\n",
      "3900 th loss0 : 369.5886, test rmse : 266.0746, test mnll: : 10.0532\n",
      "4000 th loss0 : 369.4490, test rmse : 268.3711, test mnll: : 9.8335\n",
      "4100 th loss0 : 369.4051, test rmse : 269.7395, test mnll: : 9.7320\n",
      "4200 th loss0 : 369.3913, test rmse : 270.3751, test mnll: : 9.7192\n",
      "4300 th loss0 : 369.3916, test rmse : 270.4109, test mnll: : 9.7201\n",
      "4400 th loss0 : 369.3935, test rmse : 270.2274, test mnll: : 9.7095\n",
      "4500 th loss0 : 369.3907, test rmse : 270.3911, test mnll: : 9.7185\n",
      "4600 th loss0 : 369.3920, test rmse : 270.3191, test mnll: : 9.7132\n",
      "4700 th loss0 : 369.3907, test rmse : 270.3506, test mnll: : 9.7151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800 th loss0 : 369.3906, test rmse : 270.4140, test mnll: : 9.7198\n",
      "4900 th loss0 : 369.3926, test rmse : 270.3728, test mnll: : 9.7173\n",
      "5000 th loss0 : 369.3944, test rmse : 270.6889, test mnll: : 9.7350\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "0 init loss: 69836.4359 \n",
      "0 model chosen \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "########################################################################################################################################################################################################\n",
      "weight_reg\n",
      "########################################################################################################################################################################################################\n",
      "0 th loss0 : 62519.9359, test rmse : 453.0091, test mnll: : 4058.4774\n",
      "[1. 1. 1. 1. 1. 1. 1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0095 0.2354 0.0786 0.437  0.1923 0.2581 0.4745] \t\t\t\t\t self.mu.exp() \n",
      "[0.0061 0.0126 0.0064 0.014  0.01   0.0047 0.0147] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[19.5892] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "100 th loss0 : 38332.0068, test rmse : 337.5311, test mnll: : 1394.1847\n",
      "[2. 2. 2. 2. 2. 2. 1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0075 0.2429 0.0789 0.4269 0.1804 0.4315 0.3038] \t\t\t\t\t self.mu.exp() \n",
      "[0.0068 0.0127 0.0055 0.0139 0.0039 0.0144 0.0098] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[32.8833] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "200 th loss0 : 29518.3627, test rmse : 390.5060, test mnll: : 1249.4885\n",
      "[3. 3. 2. 2. 2. 2. 2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0065 0.1369 0.2513 0.0794 0.4296 0.4239 0.4292] \t\t\t\t\t self.mu.exp() \n",
      "[0.0064 0.0037 0.0118 0.0048 0.0142 0.0091 0.014 ] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[50.4371] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "300 th loss0 : 21068.9118, test rmse : 408.2942, test mnll: : 955.9748\n",
      "[4. 3. 3. 3. 2. 2. 2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0058 0.2508 0.0803 0.1077 0.4026 0.4429 0.4236] \t\t\t\t\t self.mu.exp() \n",
      "[0.0059 0.0108 0.0042 0.0031 0.0146 0.0082 0.014 ] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[73.4688] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "400 th loss0 : 12393.2639, test rmse : 418.8918, test mnll: : 697.2647\n",
      "[5. 4. 4. 4. 3. 2. 2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0052 0.2512 0.0794 0.0865 0.4254 0.3881 0.4432] \t\t\t\t\t self.mu.exp() \n",
      "[0.0053 0.0103 0.0037 0.0028 0.0138 0.015  0.0073] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[108.3007] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "500 th loss0 : 7432.1802, test rmse : 408.9789, test mnll: : 458.3291\n",
      "[8. 7. 5. 4. 3. 3. 2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0706 0.0046 0.0805 0.2498 0.364  0.4223 0.4427] \t\t\t\t\t self.mu.exp() \n",
      "[0.0029 0.0049 0.0035 0.0096 0.016  0.0136 0.0063] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[159.715] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "600 th loss0 : 4651.9394, test rmse : 370.9030, test mnll: : 271.4814\n",
      "[11.  9.  6.  5.  4.  3.  2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0585 0.0041 0.08   0.2549 0.4184 0.3422 0.4429] \t\t\t\t\t self.mu.exp() \n",
      "[0.0032 0.0044 0.003  0.0092 0.0136 0.0164 0.0054] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[227.4339] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "700 th loss0 : 3336.6128, test rmse : 323.8628, test mnll: : 144.0280\n",
      "[17. 12.  8.  6.  4.  3.  2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0484 0.0036 0.0801 0.2553 0.4196 0.3252 0.4429] \t\t\t\t\t self.mu.exp() \n",
      "[0.0033 0.0039 0.0027 0.0091 0.0135 0.0172 0.0046] \t\t\t\t\t self.std.exp() \n",
      "[4 4 3 4 4 5 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[336.0356] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "800 th loss0 : 2413.3256, test rmse : 372.1029, test mnll: : 131.5231\n",
      "[24. 16. 11.  7.  3.  3.  2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0407 0.0033 0.0805 0.2592 0.3065 0.4189 0.4428] \t\t\t\t\t self.mu.exp() \n",
      "[0.0031 0.0034 0.0024 0.0095 0.0195 0.014  0.0039] \t\t\t\t\t self.std.exp() \n",
      "[4 4 3 5 5 4 3] \t\t\t\t\t self.num_samplept_list_at \n",
      "[491.6783] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "900 th loss0 : 1809.2283, test rmse : 353.4519, test mnll: : 84.4583\n",
      "[33. 21. 13.  6.  3.  3.  1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0345 0.0029 0.0806 0.2724 0.2857 0.4182 0.4428] \t\t\t\t\t self.mu.exp() \n",
      "[0.003  0.0031 0.0022 0.0115 0.024  0.015  0.0035] \t\t\t\t\t self.std.exp() \n",
      "[4 4 3 5 5 4 3] \t\t\t\t\t self.num_samplept_list_at \n",
      "[720.6223] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1000 th loss0 : 1390.0757, test rmse : 325.9832, test mnll: : 49.8099\n",
      "[51. 27. 17.  6.  2.  2.  1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0294 0.0026 0.0814 0.295  0.2665 0.4174 0.4428] \t\t\t\t\t self.mu.exp() \n",
      "[0.0032 0.0027 0.0021 0.015  0.0305 0.0159 0.0032] \t\t\t\t\t self.std.exp() \n",
      "[4 3 3 5 5 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[1096.7439] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1100 th loss0 : 1109.1603, test rmse : 372.7754, test mnll: : 44.4533\n",
      "[77. 35. 21.  5.  2.  2.  1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0257 0.0024 0.0815 0.3045 0.2549 0.4171 0.4428] \t\t\t\t\t self.mu.exp() \n",
      "[0.0027 0.0024 0.002  0.0202 0.0377 0.0164 0.003 ] \t\t\t\t\t self.std.exp() \n",
      "[4 4 3 5 5 4 3] \t\t\t\t\t self.num_samplept_list_at \n",
      "[1640.5186] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1200 th loss0 : 958.1456, test rmse : 364.3176, test mnll: : 30.3262\n",
      "[109.  45.  25.   4.   2.   2.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0235 0.0022 0.0837 0.304  0.251  0.417  0.4428] \t\t\t\t\t self.mu.exp() \n",
      "[0.0022 0.0022 0.0021 0.0261 0.0421 0.0164 0.003 ] \t\t\t\t\t self.std.exp() \n",
      "[4 3 4 4 5 5 3] \t\t\t\t\t self.num_samplept_list_at \n",
      "[2488.1957] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1300 th loss0 : 873.4784, test rmse : 362.8463, test mnll: : 21.6506\n",
      "[151.  58.  28.   4.   2.   1.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0223 0.002  0.0894 0.3043 0.2504 0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0021 0.002  0.0026 0.0296 0.043  0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[4 3 4 5 5 3 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[3819.5249] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1400 th loss0 : 775.8815, test rmse : 326.8803, test mnll: : 14.0606\n",
      "[200.  74.  28.   3.   1.   1.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0218 0.0019 0.1408 0.3041 0.2502 0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.002  0.0019 0.0036 0.03   0.0433 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 5 5 3 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[5892.7637] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1500 th loss0 : 715.2837, test rmse : 340.6207, test mnll: : 11.8452\n",
      "[245.  94.  26.   3.   1.   1.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0219 0.0018 0.2345 0.3041 0.2502 0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0017 0.0017 0.0052 0.03   0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[3 4 4 5 5 3 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[8871.667] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1600 th loss0 : 686.0967, test rmse : 358.4160, test mnll: : 10.6191\n",
      "[293. 119.  25.   2.   1.   1.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0219 0.0017 0.312  0.3042 0.2502 0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0014 0.0016 0.0079 0.03   0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[3 3 5 5 5 3 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[12603.5698] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1700 th loss0 : 669.1508, test rmse : 340.5939, test mnll: : 9.2887\n",
      "[332. 153.  24.   2.   1.   1.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0219 0.0016 0.319  0.3042 0.2502 0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0012 0.0015 0.0123 0.03   0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[3 3 5 5 5 3 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[16169.9211] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800 th loss0 : 659.6448, test rmse : 327.7875, test mnll: : 8.9211\n",
      "[369. 208.  22.   2.   1.   1.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0219 0.0015 0.3189 0.3042 0.2502 0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0011 0.0014 0.018  0.03   0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[3 4 5 5 4 3 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[16803.875] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1900 th loss0 : 639.9836, test rmse : 276.0023, test mnll: : 8.8510\n",
      "[411. 318.  19.   1.   1.   1.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0218 0.0013 0.3189 0.3041 0.2502 0.4429 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0011 0.0013 0.0227 0.03   0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[3 3 6 5 4 3 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[11367.8423] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2000 th loss0 : 598.4887, test rmse : 233.3218, test mnll: : 10.6735\n",
      "[536. 485.  14.   1.   0.   0.   0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.0218 0.3191 0.3043 0.2501 0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0013 0.0011 0.0238 0.03   0.0433 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[3 3 6 5 4 3 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[4649.6472] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2100 th loss0 : 559.4357, test rmse : 189.6757, test mnll: : 12.8622\n",
      "[892. 555.   8.   1.   0.   0.   0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0016 0.022  0.3183 0.3043 0.2499 0.4427 0.4169] \t\t\t\t\t self.mu.exp() \n",
      "[0.0012 0.0014 0.0237 0.03   0.0439 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[3 3 6 5 4 3 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[1895.7865] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2200 th loss0 : 537.4260, test rmse : 180.4282, test mnll: : 15.6609\n",
      "[1391.  681.    5.    0.    0.    0.    0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0018 0.0213 0.3194 0.3039 0.2509 0.4429 0.4171] \t\t\t\t\t self.mu.exp() \n",
      "[0.0011 0.0016 0.0235 0.03   0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[3 3 6 5 4 3 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[1158.0733] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2300 th loss0 : 534.6225, test rmse : 130.7094, test mnll: : 11.1644\n",
      "[2033.  809.    3.    0.    0.    0.    0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0017 0.021  0.321  0.3039 0.2495 0.4428 0.4169] \t\t\t\t\t self.mu.exp() \n",
      "[0.001  0.0017 0.0238 0.0301 0.0435 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[3 3 6 5 4 3 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[1080.9331] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2400 th loss0 : 520.4486, test rmse : 130.9629, test mnll: : 11.1334\n",
      "[2.917e+03 8.610e+02 2.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0017 0.0213 0.3185 0.3043 0.2502 0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0009 0.0016 0.0236 0.03   0.0434 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[3 3 6 5 4 3 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[1031.3349] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2500 th loss0 : 516.3792, test rmse : 130.6776, test mnll: : 10.9736\n",
      "[4.119e+03 8.510e+02 2.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0017 0.0214 0.3195 0.3041 0.2505 0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0008 0.0016 0.0239 0.03   0.0431 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[3 3 6 5 4 3 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[971.8333] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2600 th loss0 : 520.6823, test rmse : 136.8173, test mnll: : 11.6946\n",
      "[5.766e+03 7.130e+02 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0016 0.0217 0.319  0.3041 0.2507 0.4428 0.4171] \t\t\t\t\t self.mu.exp() \n",
      "[0.0008 0.0015 0.0238 0.03   0.043  0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[3 3 6 5 4 3 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[1009.0245] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2700 th loss0 : 509.4895, test rmse : 115.8369, test mnll: : 9.1428\n",
      "[8.145e+03 5.170e+02 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0016 0.022  0.3193 0.3041 0.2504 0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0008 0.0013 0.0239 0.0299 0.0433 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[3 3 5 5 5 3 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[969.5118] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2800 th loss0 : 512.3156, test rmse : 96.0367, test mnll: : 8.0414\n",
      "[1.1349e+04 3.6800e+02 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0016 0.0221 0.3189 0.3043 0.2505 0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0008 0.0012 0.0238 0.03   0.0431 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[3 3 5 5 5 3 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[956.671] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2900 th loss0 : 511.2501, test rmse : 89.7273, test mnll: : 7.4707\n",
      "[15520.   250.     0.     0.     0.     0.     0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0015 0.0221 0.3043 0.3182 0.2499 0.4428 0.4171] \t\t\t\t\t self.mu.exp() \n",
      "[0.0008 0.0011 0.03   0.0237 0.0433 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[3 3 5 5 5 3 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[955.6121] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3000 th loss0 : 504.9167, test rmse : 86.1791, test mnll: : 7.1875\n",
      "[21353.   165.     0.     0.     0.     0.     0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0014 0.022  0.3042 0.3191 0.2502 0.4427 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0008 0.0011 0.03   0.0238 0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[3 3 5 5 5 3 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[921.3178] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3100 th loss0 : 502.9585, test rmse : 96.2033, test mnll: : 8.0394\n",
      "[29681.   109.     0.     0.     0.     0.     0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.0221 0.3042 0.3186 0.25   0.4429 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.001  0.001  0.03   0.0237 0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[3 3 5 5 5 3 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[925.6152] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3200 th loss0 : 501.1149, test rmse : 77.7454, test mnll: : 6.6094\n",
      "[39260.    77.     0.     0.     0.     0.     0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.022  0.3041 0.3189 0.2503 0.4428 0.4171] \t\t\t\t\t self.mu.exp() \n",
      "[0.001  0.001  0.03   0.0238 0.0434 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[3 3 5 5 5 3 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[908.7395] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3300 th loss0 : 502.2556, test rmse : 87.5802, test mnll: : 7.3907\n",
      "[51811.    58.     0.     0.     0.     0.     0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0012 0.022  0.3042 0.319  0.2501 0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.001  0.001  0.03   0.0238 0.0433 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[3 3 5 5 5 3 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[915.7993] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3400 th loss0 : 502.1312, test rmse : 79.0082, test mnll: : 6.5553\n",
      "[6.8053e+04 4.6000e+01 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0012 0.0219 0.3041 0.3189 0.2502 0.4427 0.4171] \t\t\t\t\t self.mu.exp() \n",
      "[0.0011 0.001  0.03   0.0238 0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[3 3 5 5 5 3 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[897.222] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3500 th loss0 : 502.7795, test rmse : 70.3313, test mnll: : 6.2090\n",
      "[8.6525e+04 4.0000e+01 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0011 0.0219 0.3042 0.3188 0.2502 0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0013 0.001  0.03   0.0238 0.0431 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[3 3 5 5 5 3 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[886.6787] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3600 th loss0 : 500.5427, test rmse : 80.2670, test mnll: : 6.6685\n",
      "[1.01e+05 3.60e+01 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.001  0.0219 0.3042 0.3188 0.2501 0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0013 0.001  0.03   0.0238 0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[3 3 5 5 5 3 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[898.835] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3700 th loss0 : 500.8844, test rmse : 74.2772, test mnll: : 6.8614\n",
      "[1.1469e+05 3.6000e+01 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.001  0.0218 0.3042 0.3188 0.2502 0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0013 0.001  0.03   0.0238 0.0433 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[3 3 5 5 5 3 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[899.3445] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3800 th loss0 : 500.7670, test rmse : 73.2688, test mnll: : 6.2551\n",
      "[1.2944e+05 3.4000e+01 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0009 0.022  0.3041 0.3189 0.2502 0.4428 0.4171] \t\t\t\t\t self.mu.exp() \n",
      "[0.0014 0.001  0.03   0.0238 0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[3 3 5 5 5 3 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[896.9677] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3900 th loss0 : 500.5683, test rmse : 69.5048, test mnll: : 6.1228\n",
      "[1.3566e+05 3.3000e+01 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0009 0.022  0.3041 0.3189 0.2502 0.4427 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0015 0.001  0.03   0.0238 0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[3 3 5 5 5 3 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[905.0857] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 th loss0 : 499.8769, test rmse : 68.9980, test mnll: : 6.1251\n",
      "[1.3711e+05 3.3000e+01 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0008 0.0219 0.3042 0.3189 0.2502 0.4428 0.4171] \t\t\t\t\t self.mu.exp() \n",
      "[0.0015 0.001  0.03   0.0238 0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[3 3 5 5 5 3 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[899.5301] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4100 th loss0 : 501.3335, test rmse : 70.4525, test mnll: : 6.3074\n",
      "[1.371e+05 3.300e+01 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0008 0.022  0.3041 0.3189 0.2502 0.4428 0.4171] \t\t\t\t\t self.mu.exp() \n",
      "[0.0015 0.001  0.03   0.0238 0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[3 3 5 5 5 3 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[920.3572] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4200 th loss0 : 501.0248, test rmse : 74.2165, test mnll: : 6.2781\n",
      "[1.344e+05 3.300e+01 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0008 0.0219 0.3041 0.3189 0.2502 0.4428 0.4171] \t\t\t\t\t self.mu.exp() \n",
      "[0.0015 0.001  0.03   0.0238 0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[3 3 5 5 5 3 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[890.4356] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4300 th loss0 : 500.1945, test rmse : 72.0534, test mnll: : 6.2604\n",
      "[1.3064e+05 3.2000e+01 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0008 0.0219 0.3042 0.3188 0.2502 0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0015 0.001  0.03   0.0238 0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[3 3 5 5 5 3 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[891.6518] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4400 th loss0 : 500.2869, test rmse : 69.1984, test mnll: : 6.2449\n",
      "[1.3586e+05 3.3000e+01 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0007 0.0217 0.3042 0.3188 0.2502 0.4428 0.4171] \t\t\t\t\t self.mu.exp() \n",
      "[0.0015 0.001  0.03   0.0238 0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[3 3 5 5 5 3 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[886.9883] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4500 th loss0 : 501.1802, test rmse : 78.8636, test mnll: : 6.4564\n",
      "[1.3317e+05 3.2000e+01 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0007 0.0218 0.3041 0.3188 0.2503 0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0015 0.001  0.03   0.0238 0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[3 3 5 5 5 3 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[889.8504] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4600 th loss0 : 502.3084, test rmse : 68.7260, test mnll: : 6.0473\n",
      "[1.3582e+05 3.4000e+01 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0006 0.0218 0.3041 0.3189 0.2502 0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.001  0.03   0.0238 0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[3 3 5 5 5 3 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[885.8584] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4700 th loss0 : 501.7735, test rmse : 70.4990, test mnll: : 6.3003\n",
      "[1.3895e+05 3.2000e+01 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0006 0.0218 0.3042 0.3189 0.2502 0.4429 0.4171] \t\t\t\t\t self.mu.exp() \n",
      "[0.0017 0.001  0.03   0.0238 0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[3 3 5 5 5 3 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[889.4951] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4800 th loss0 : 500.3596, test rmse : 76.1712, test mnll: : 6.8459\n",
      "[1.3415e+05 3.2000e+01 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0006 0.022  0.3041 0.3189 0.2502 0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.001  0.03   0.0238 0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[3 3 5 5 5 3 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[893.8829] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4900 th loss0 : 500.4711, test rmse : 69.5939, test mnll: : 6.3644\n",
      "[1.4448e+05 3.3000e+01 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0006 0.0218 0.3042 0.3188 0.2502 0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.001  0.03   0.0238 0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[3 3 5 5 5 3 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[890.9082] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "5000 th loss0 : 499.9271, test rmse : 69.0019, test mnll: : 5.8772\n",
      "[1.4803e+05 3.3000e+01 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0006 0.0219 0.3041 0.3189 0.2502 0.4429 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.001  0.03   0.0238 0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[3 3 5 5 5 3 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[917.7099] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "0 init loss: 107755.5800 \n",
      "0 model chosen \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "2 init loss: 85414.0955 \n",
      "2 model chosen \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "3 init loss: 84966.0115 \n",
      "3 model chosen \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "5 init loss: 78470.7407 \n",
      "5 model chosen \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in spt manager\n",
      "total spt:28, spt:4, Q:7 in setup model \n",
      "9 init loss: 71557.8557 \n",
      "9 model chosen \n",
      "########################################################################################################################################################################################################\n",
      "equal_reg\n",
      "########################################################################################################################################################################################################\n",
      "0 th loss0 : 99041.7332, test rmse : 457.3705, test mnll: : 4257.9436\n",
      "[1. 1. 1. 1. 1. 1. 1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0095 0.2418 0.077  0.4245 0.1995 0.2582 0.4705] \t\t\t\t\t self.mu.exp() \n",
      "[0.0063 0.0128 0.006  0.0145 0.0096 0.0045 0.0138] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[18.9885] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "100 th loss0 : 43641.8049, test rmse : 435.0307, test mnll: : 2208.1080\n",
      "[2. 2. 2. 2. 2. 2. 1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0075 0.2496 0.0789 0.4343 0.1805 0.4692 0.3249] \t\t\t\t\t self.mu.exp() \n",
      "[0.0069 0.0128 0.0051 0.0137 0.0037 0.0141 0.0094] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[35.0033] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "200 th loss0 : 26287.2653, test rmse : 458.1631, test mnll: : 1588.7704\n",
      "[3. 3. 2. 2. 2. 2. 2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0065 0.1369 0.2522 0.0797 0.4162 0.4333 0.4391] \t\t\t\t\t self.mu.exp() \n",
      "[0.0067 0.0035 0.0119 0.0044 0.0136 0.009  0.0145] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[55.0725] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "300 th loss0 : 18195.2513, test rmse : 414.6756, test mnll: : 870.3582\n",
      "[4. 3. 3. 3. 2. 2. 2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0059 0.2504 0.0805 0.1077 0.408  0.4432 0.4268] \t\t\t\t\t self.mu.exp() \n",
      "[0.0061 0.0113 0.004  0.0029 0.0136 0.0082 0.0145] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[84.7568] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "400 th loss0 : 9867.8677, test rmse : 456.6848, test mnll: : 707.9938\n",
      "[5. 4. 4. 4. 3. 3. 2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0053 0.2514 0.0797 0.0865 0.3959 0.4204 0.4428] \t\t\t\t\t self.mu.exp() \n",
      "[0.0057 0.0106 0.0035 0.0026 0.0144 0.0144 0.0073] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[129.7514] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "500 th loss0 : 6743.6388, test rmse : 383.6283, test mnll: : 334.2133\n",
      "[8. 6. 5. 4. 3. 3. 2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0707 0.0047 0.0806 0.2518 0.3664 0.418  0.4427] \t\t\t\t\t self.mu.exp() \n",
      "[0.0029 0.0053 0.0033 0.0102 0.0162 0.0141 0.0064] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[198.0378] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 th loss0 : 5514.3583, test rmse : 400.0885, test mnll: : 242.4398\n",
      "[12.  8.  6.  5.  3.  3.  2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0585 0.0043 0.0795 0.2544 0.338  0.4155 0.4427] \t\t\t\t\t self.mu.exp() \n",
      "[0.0031 0.0049 0.0029 0.0101 0.0173 0.0141 0.0055] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[305.213] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "700 th loss0 : 3239.1126, test rmse : 385.6248, test mnll: : 152.8955\n",
      "[17. 10.  7.  5.  3.  3.  2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0484 0.0039 0.0804 0.2591 0.3201 0.4173 0.4428] \t\t\t\t\t self.mu.exp() \n",
      "[0.0028 0.0045 0.0027 0.0105 0.0193 0.0144 0.0047] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[461.8152] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "800 th loss0 : 2330.2550, test rmse : 406.7157, test mnll: : 110.7219\n",
      "[24. 13.  9.  5.  3.  3.  2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0409 0.0036 0.0807 0.2715 0.2976 0.4171 0.4428] \t\t\t\t\t self.mu.exp() \n",
      "[0.0026 0.004  0.0024 0.0119 0.0228 0.0151 0.004 ] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[729.9463] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "900 th loss0 : 1775.7251, test rmse : 385.3511, test mnll: : 65.5543\n",
      "[33. 17. 11.  5.  3.  2.  2.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0346 0.0033 0.0811 0.2931 0.2772 0.4428 0.4171] \t\t\t\t\t self.mu.exp() \n",
      "[0.0022 0.0037 0.0023 0.0146 0.0285 0.0035 0.0158] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[1158.7839] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1000 th loss0 : 1462.3903, test rmse : 401.7488, test mnll: : 47.0487\n",
      "[49. 21. 13.  4.  2.  2.  1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0298 0.0031 0.0816 0.3037 0.2622 0.4166 0.4428] \t\t\t\t\t self.mu.exp() \n",
      "[0.0024 0.0034 0.0023 0.0189 0.0353 0.0163 0.0032] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[1830.9756] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1100 th loss0 : 1100.2647, test rmse : 383.3680, test mnll: : 29.3347\n",
      "[73. 25. 14.  4.  2.  2.  1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0259 0.0029 0.085  0.3043 0.2538 0.4169 0.4428] \t\t\t\t\t self.mu.exp() \n",
      "[0.002  0.0031 0.0025 0.0246 0.0412 0.0164 0.003 ] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[2913.7789] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1200 th loss0 : 978.4047, test rmse : 386.2068, test mnll: : 20.7375\n",
      "[105.  30.  15.   4.   2.   2.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0239 0.0028 0.1075 0.3041 0.2506 0.4171 0.4428] \t\t\t\t\t self.mu.exp() \n",
      "[0.0015 0.0029 0.0029 0.0289 0.0431 0.0165 0.003 ] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[4671.9145] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1300 th loss0 : 815.0847, test rmse : 386.2474, test mnll: : 15.1241\n",
      "[141.  36.  14.   3.   2.   1.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0229 0.0026 0.1666 0.3041 0.2502 0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0014 0.0027 0.0037 0.03   0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[7519.777] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1400 th loss0 : 740.8147, test rmse : 397.0966, test mnll: : 12.1935\n",
      "[177.  41.  14.   3.   1.   1.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0223 0.0025 0.2599 0.3042 0.2502 0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0013 0.0026 0.005  0.03   0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[11799.9226] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1500 th loss0 : 700.8759, test rmse : 405.0117, test mnll: : 10.3551\n",
      "[212.  46.  14.   3.   1.   1.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0221 0.0024 0.3166 0.3041 0.2502 0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0012 0.0025 0.0074 0.03   0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[17873.4854] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1600 th loss0 : 690.8232, test rmse : 407.7048, test mnll: : 9.2228\n",
      "[239.  51.  13.   3.   1.   1.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.022  0.0024 0.3189 0.3042 0.2502 0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0011 0.0025 0.0114 0.03   0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[25520.5709] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1700 th loss0 : 682.3396, test rmse : 407.4545, test mnll: : 8.6051\n",
      "[260.  57.  13.   2.   1.   1.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.022  0.0023 0.3189 0.3042 0.2502 0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0011 0.0024 0.0168 0.03   0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[33248.9878] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1800 th loss0 : 679.1640, test rmse : 405.4406, test mnll: : 8.3044\n",
      "[273.  65.  13.   2.   1.   1.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.022  0.0022 0.3189 0.3042 0.2502 0.4429 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.001  0.0024 0.022  0.03   0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[38893.7457] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "1900 th loss0 : 677.1790, test rmse : 409.4347, test mnll: : 8.2896\n",
      "[283.  80.  12.   2.   1.   1.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0219 0.0022 0.3189 0.3042 0.2502 0.4429 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.001  0.0024 0.0238 0.03   0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[40270.696] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2000 th loss0 : 677.3146, test rmse : 395.9613, test mnll: : 8.2958\n",
      "[295. 113.  11.   1.   1.   1.   1.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0219 0.002  0.3189 0.3042 0.2502 0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.001  0.0022 0.0238 0.03   0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[36687.7873] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2100 th loss0 : 662.0430, test rmse : 357.0696, test mnll: : 8.5639\n",
      "[349. 207.  10.   1.   1.   0.   0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0219 0.0017 0.3189 0.3042 0.4428 0.2502 0.4169] \t\t\t\t\t self.mu.exp() \n",
      "[0.0011 0.0019 0.0238 0.03   0.003  0.0432 0.0165] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[24217.8207] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2200 th loss0 : 618.2005, test rmse : 240.9080, test mnll: : 9.2861\n",
      "[543. 439.   7.   1.   0.   0.   0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0216 0.0012 0.319  0.3042 0.2502 0.4428 0.4171] \t\t\t\t\t self.mu.exp() \n",
      "[0.0011 0.0014 0.0238 0.03   0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[7059.5915] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2300 th loss0 : 563.0226, test rmse : 177.2648, test mnll: : 11.0580\n",
      "[810. 688.   4.   0.   0.   0.   0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0016 0.0218 0.3189 0.3043 0.2499 0.4428 0.4171] \t\t\t\t\t self.mu.exp() \n",
      "[0.0015 0.0014 0.0238 0.0299 0.0433 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[2227.4791] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2400 th loss0 : 542.8999, test rmse : 161.0421, test mnll: : 13.1399\n",
      "[1309. 1001.    2.    0.    0.    0.    0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0018 0.0207 0.3165 0.304  0.2502 0.4428 0.4171] \t\t\t\t\t self.mu.exp() \n",
      "[0.0014 0.0019 0.0236 0.03   0.0435 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[1130.8577] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2500 th loss0 : 524.1799, test rmse : 201.1179, test mnll: : 19.8905\n",
      "[1.951e+03 1.229e+03 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0019 0.021  0.319  0.304  0.2505 0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0013 0.0019 0.0237 0.03   0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[987.9487] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2600 th loss0 : 522.5539, test rmse : 147.6552, test mnll: : 12.1422\n",
      "[2.801e+03 1.288e+03 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0018 0.0205 0.3183 0.304  0.2501 0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0013 0.0018 0.0238 0.0299 0.0433 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[975.4479] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2700 th loss0 : 513.4907, test rmse : 131.2895, test mnll: : 11.0269\n",
      "[3.958e+03 1.264e+03 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0017 0.0212 0.3178 0.3042 0.2496 0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0014 0.0017 0.0236 0.03   0.043  0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[953.253] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "2800 th loss0 : 523.3393, test rmse : 143.2677, test mnll: : 11.8161\n",
      "[5595.  969.    0.    0.    0.    0.    0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0017 0.0215 0.3038 0.3184 0.2498 0.4427 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0015 0.0015 0.0299 0.0238 0.0434 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[966.7998] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2900 th loss0 : 518.8038, test rmse : 124.6435, test mnll: : 10.3613\n",
      "[7982.  710.    0.    0.    0.    0.    0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0016 0.0217 0.3042 0.3192 0.25   0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0015 0.0013 0.03   0.024  0.0431 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[927.7824] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3000 th loss0 : 504.4315, test rmse : 104.3942, test mnll: : 8.3144\n",
      "[10985.   462.     0.     0.     0.     0.     0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0016 0.0218 0.3042 0.3189 0.2502 0.4428 0.4171] \t\t\t\t\t self.mu.exp() \n",
      "[0.0017 0.0012 0.03   0.0238 0.0431 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[895.4342] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3100 th loss0 : 505.9728, test rmse : 90.0308, test mnll: : 7.4823\n",
      "[15201.   296.     0.     0.     0.     0.     0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0015 0.0218 0.304  0.3194 0.2503 0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0018 0.0011 0.03   0.0238 0.0433 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[898.2081] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3200 th loss0 : 504.3960, test rmse : 110.7551, test mnll: : 8.3610\n",
      "[20949.   188.     0.     0.     0.     0.     0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0015 0.0219 0.3042 0.319  0.2501 0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.002  0.0011 0.0299 0.0238 0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[896.6102] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3300 th loss0 : 502.7227, test rmse : 113.4826, test mnll: : 7.0100\n",
      "[28022.   122.     0.     0.     0.     0.     0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0014 0.0218 0.3041 0.3188 0.2502 0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0021 0.001  0.03   0.0239 0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[899.1671] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3400 th loss0 : 500.3687, test rmse : 93.7696, test mnll: : 6.5450\n",
      "[36033.    84.     0.     0.     0.     0.     0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.022  0.3041 0.319  0.2501 0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0021 0.001  0.03   0.0238 0.0433 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[915.7883] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3500 th loss0 : 500.5136, test rmse : 88.2548, test mnll: : 6.4523\n",
      "[43053.    60.     0.     0.     0.     0.     0.] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.0218 0.3042 0.3188 0.2503 0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.002  0.001  0.03   0.0238 0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[894.6869] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3600 th loss0 : 501.6968, test rmse : 77.5450, test mnll: : 6.4165\n",
      "[5.1363e+04 4.6000e+01 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.0217 0.3042 0.3191 0.2501 0.4429 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.002  0.001  0.03   0.0238 0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[890.2005] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3700 th loss0 : 500.4223, test rmse : 77.9551, test mnll: : 6.2751\n",
      "[6.2092e+04 3.9000e+01 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0014 0.0219 0.3042 0.3188 0.2502 0.4428 0.4171] \t\t\t\t\t self.mu.exp() \n",
      "[0.0018 0.001  0.03   0.0238 0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[893.0049] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3800 th loss0 : 500.0757, test rmse : 76.2905, test mnll: : 6.2905\n",
      "[7.2371e+04 3.5000e+01 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.0218 0.3042 0.319  0.2502 0.4428 0.4169] \t\t\t\t\t self.mu.exp() \n",
      "[0.0018 0.001  0.03   0.0238 0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[893.0414] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "3900 th loss0 : 501.7286, test rmse : 71.4275, test mnll: : 6.2609\n",
      "[7.6758e+04 3.3000e+01 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0013 0.0218 0.3042 0.3189 0.2502 0.4429 0.4171] \t\t\t\t\t self.mu.exp() \n",
      "[0.0017 0.001  0.03   0.0238 0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[885.9807] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4000 th loss0 : 502.0612, test rmse : 74.2611, test mnll: : 6.1317\n",
      "[8.4671e+04 3.3000e+01 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0012 0.0219 0.3042 0.3189 0.2502 0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.001  0.03   0.0238 0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[896.957] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4100 th loss0 : 501.4464, test rmse : 72.9609, test mnll: : 5.9683\n",
      "[9.0308e+04 3.2000e+01 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0011 0.0217 0.3041 0.3189 0.2502 0.4429 0.4169] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.001  0.03   0.0238 0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[888.734] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4200 th loss0 : 500.1012, test rmse : 72.2079, test mnll: : 6.2624\n",
      "[9.2797e+04 3.2000e+01 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.001  0.0218 0.3042 0.3189 0.2502 0.4427 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.001  0.03   0.0238 0.0433 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[888.5997] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4300 th loss0 : 500.5085, test rmse : 78.6437, test mnll: : 6.1109\n",
      "[9.8364e+04 3.2000e+01 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.001  0.0219 0.3042 0.3189 0.2502 0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.001  0.03   0.0238 0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[886.7911] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4400 th loss0 : 502.0400, test rmse : 71.1463, test mnll: : 6.4280\n",
      "[1.0192e+05 3.3000e+01 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0009 0.0218 0.3041 0.3188 0.2502 0.4429 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.001  0.03   0.0238 0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[884.1096] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4500 th loss0 : 499.9894, test rmse : 70.3518, test mnll: : 6.1817\n",
      "[1.0646e+05 3.1000e+01 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0009 0.0218 0.3041 0.319  0.2503 0.4428 0.4171] \t\t\t\t\t self.mu.exp() \n",
      "[0.0015 0.001  0.03   0.0238 0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[893.309] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4600 th loss0 : 500.7435, test rmse : 70.9997, test mnll: : 6.0162\n",
      "[1.0829e+05 3.1000e+01 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0008 0.0218 0.3042 0.3188 0.2502 0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0016 0.001  0.03   0.0238 0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[896.5278] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4700 th loss0 : 500.5298, test rmse : 74.6957, test mnll: : 6.3603\n",
      "[1.0334e+05 3.1000e+01 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0008 0.0218 0.3043 0.3189 0.2502 0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0015 0.001  0.03   0.0238 0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[886.1664] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4800 th loss0 : 500.8600, test rmse : 72.7914, test mnll: : 6.2362\n",
      "[1.0941e+05 3.2000e+01 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0008 0.0218 0.3042 0.3189 0.2502 0.4428 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0015 0.001  0.03   0.0238 0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[894.3204] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "4900 th loss0 : 501.4767, test rmse : 71.2644, test mnll: : 6.0975\n",
      "[1.0844e+05 3.2000e+01 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0007 0.0219 0.3041 0.3189 0.2502 0.4427 0.417 ] \t\t\t\t\t self.mu.exp() \n",
      "[0.0015 0.001  0.03   0.0238 0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[896.1561] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 th loss0 : 500.5357, test rmse : 74.7372, test mnll: : 6.1604\n",
      "[1.1616e+05 3.2000e+01 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00] \t\t\t\t\t self.weight.exp() \n",
      "[0.0007 0.0219 0.3042 0.3188 0.2502 0.4428 0.4171] \t\t\t\t\t self.mu.exp() \n",
      "[0.0015 0.001  0.03   0.0238 0.0432 0.003  0.0165] \t\t\t\t\t self.std.exp() \n",
      "[4 4 4 4 4 4 4] \t\t\t\t\t self.num_samplept_list_at \n",
      "[890.7592] \t\t\t\t\t likelihood variance \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rep_loss_history_list_e,rep_loss_history_list_w,rep_loss_history_list_nw,\\\n",
    "rep_rmse_history_list_e,rep_rmse_history_list_w,rep_rmse_history_list_nw,\\\n",
    "rep_mnll_history_list_e,rep_mnll_history_list_w,rep_mnll_history_list_nw,\\\n",
    "rep_model_history_list_e,rep_model_history_list_w,rep_model_history_list_nw =  _compare_reg_model2(num_spt1,num_rep,setting_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl_mean1,wl_std1 = np.asarray(rep_loss_history_list_w).mean(axis = 0).round(3), np.asarray(rep_loss_history_list_w).std(axis = 0).round(3)\n",
    "el_mean1,el_std1 = np.asarray(rep_loss_history_list_e).mean(axis = 0).round(3), np.asarray(rep_loss_history_list_e).std(axis = 0).round(3)\n",
    "nwl_mean1,nwl_std1 = np.asarray(rep_loss_history_list_nw).mean(axis = 0).round(3), np.asarray(rep_loss_history_list_nw).std(axis = 0).round(3)\n",
    "\n",
    "\n",
    "wr_mean1,wr_std1 = np.asarray(rep_rmse_history_list_w).mean(axis = 0).round(3), np.asarray(rep_rmse_history_list_w).std(axis = 0).round(3)\n",
    "er_mean1,er_std1 = np.asarray(rep_rmse_history_list_e).mean(axis = 0).round(3), np.asarray(rep_rmse_history_list_e).std(axis = 0).round(3)\n",
    "nwr_mean1,nwr_std1 = np.asarray(rep_rmse_history_list_nw).mean(axis = 0).round(3), np.asarray(rep_rmse_history_list_nw).std(axis = 0).round(3)\n",
    "\n",
    "\n",
    "wm_mean1,wm_std1 = np.asarray(rep_mnll_history_list_w).mean(axis = 0).round(3), np.asarray(rep_mnll_history_list_w).std(axis = 0).round(3)\n",
    "em_mean1,em_std1 = np.asarray(rep_mnll_history_list_e).mean(axis = 0).round(3), np.asarray(rep_mnll_history_list_e).std(axis = 0).round(3)\n",
    "nwm_mean1,nwm_std1 = np.asarray(rep_mnll_history_list_nw).mean(axis = 0).round(3), np.asarray(rep_mnll_history_list_nw).std(axis = 0).round(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from os import path\n",
    "save_figure_path  = './result_figure/NeurIPS21/exp1_ab3_'+ filename +'/'\n",
    "os.makedirs(save_figure_path) if path.isdir(save_figure_path) is False else 1\n",
    "save_figure_path\n",
    "\n",
    "save_figname = filename + '_Q'+str(setting_dict['num_Q'])  + '_spt'+str( setting_dict['num_sample_pt'] ) + '_samplerate' +str(setting_dict['weight_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rep = 5\n",
    "factors = 2/np.sqrt(num_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_style('white')\n",
    "#sns.set_style('whitegrid')\n",
    "import matplotlib\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "plt.rc('font', family='serif')\n",
    "plt.rcParams['mathtext.fontset'] = 'custom'\n",
    "plt.rcParams['mathtext.cal'] = 'stix:italic'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4sAAABECAYAAAAoRaCfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAD10lEQVR4nO3cvY4bZRTH4bO2hUyKdCNFK5MbYMrlGqhcIOh8D5RwDVCGazAdopirQKR8Rc/GRDEDCG2RWMQfFA4fysHlZODleUrPrnT+2pWsn7Trq9PpdAoAAAD4m8nYBwAAAPDvIxYBAABIxCIAAACJWAQAACCZXXqw2+2ilBJN08R0On2TNwEAADCww+EQfd9H27Yxn8/T84uxWEqJ1Wo16HEAAACMa71ex83NTXr9Yiw2TXP+xp9v48FxP9xlIypfdtF+tRz7jMGUD7tor+rc9927EcfSxaStc9+xdPF1pdsiIj4oXawq3rcuXSzbR2OfMZiufBzL9oexzxjG3fvR3ZZYPmzHvmQQ3W2J5bd1bouI6N4rsfy04n2flfhkWe++z7sS31S676OIeNKVeKfSfU+6Eu3y6dhnDKZ019Euvxj7jEE8m72M1cPv/2y/112MxT/+9PTBcR+LSmNx2zSxuFfntohX+yZ17vtpEXHYNjFd1LnvsG3iXqXbIiKabRPHyvftF2+NfcZgzvtejH3GMH5dRPNiG/vrxdiXDKJ5sY39/Tq3RUQ0zTb2k7r3TfZ177tf6b7riNg127iudN+u2cZivxv7jMFsmyYW+3rf1yPi4r8d+oAbAAAAErEIAABAIhYBAABIxCIAAACJWAQAACARiwAAACRiEQAAgEQsAgAAkIhFAAAAErEIAABAIhYBAABIxCIAAACJWAQAACARiwAAACRiEQAAgEQsAgAAkIhFAAAAErEIAABAIhYBAABIxCIAAACJWAQAACARiwAAACRiEQAAgEQsAgAAkIhFAAAAErEIAABAIhYBAABIxCIAAACJWAQAACARiwAAACRiEQAAgEQsAgAAkIhFAAAAErEIAABAIhYBAABIxCIAAACJWAQAACARiwAAACRiEQAAgEQsAgAAkIhFAAAAErEIAABAIhYBAABIxCIAAACJWAQAACARiwAAACRiEQAAgEQsAgAAkIhFAAAAErEIAABAIhYBAABIZpceHA6HiIh4Nrn4Jf95fd/H5nnl+67q3PfjJuLY9zHZ1Lnv2PfxvNJtEeffzVp/dhHnfbPNb2OfMZjzvl/GPmMYd5vzvrc3Y18yiL7vY3ZX57aIV/uOde87zured1fpvqdx3jevdF/f97GZVfq+EBF9P4/NrM739WezlxHxV/u97up0Op3+6cHjx49jtVoNdxkAAACjW6/XcXNzk16/GIu73S5KKdE0TUyn08EPBAAA4M05HA7R9320bRvz+Tw9vxiLAAAA/H/5gBsAAAASsQgAAEAiFgEAAEjEIgAAAMnvk5/q65KvhvEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1152x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "current_palette = sns.color_palette(sns.hls_palette(15+1, l=.5, s=1.0))\n",
    "sns.palplot(current_palette)\n",
    "current_palette = np.asarray(current_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsiz = (6.0,4.5)\n",
    "markersiz = 8\n",
    "fontsiz=18\n",
    "markersiz = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'airline_loss_Q7_spt4_esti'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_figname = filename + '_loss'+ '_Q'+str(setting_dict['num_Q']) + '_spt' + str(num_spt1) + '_esti'\n",
    "save_figname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.0, 4.5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figsiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x324 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'./result_figure/NeurIPS21/exp1_ab3_airline/airline_loss_Q7_spt4_esti_loss_v2.pdf'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = observed_period*np.arange(len(wl_mean1))\n",
    "plt.figure(figsize = figsiz)\n",
    "\n",
    "\n",
    "\n",
    "idxh = 0\n",
    "plt.plot(idx, wl_mean1,color =  current_palette[idxh],marker = 'd',markersize = markersiz,label = 'SVSS Ws  M={0}x{1}'.format(setting_dict['num_Q'],num_spt1))\n",
    "plt.fill_between( idx,\n",
    "                  wl_mean1 - factors*wl_std1,\n",
    "                  wl_mean1 + factors*wl_std1,\n",
    "                  alpha = 0.5, edgecolor = current_palette[idxh], facecolor =  current_palette[idxh])\n",
    "\n",
    "\n",
    "\n",
    "idxh = 10\n",
    "plt.plot(idx,el_mean1,color =  current_palette[idxh],marker = 'd',markersize = markersiz,label = 'SVSS'  '        M={0}x{1}'.format(setting_dict['num_Q'],num_spt1))\n",
    "plt.fill_between( idx,\n",
    "                  el_mean1 - factors*el_std1,\n",
    "                  el_mean1 + factors*el_std1,\n",
    "                  alpha = 0.5, edgecolor = current_palette[idxh], facecolor =  current_palette[idxh])\n",
    "\n",
    "\n",
    "\n",
    "# idxh = 5\n",
    "# plt.plot(idx,nwl_mean1,color =  current_palette[idxh],marker = 'd',markersize = markersiz,label = 'SVSS NWs M={0}x{1}'.format(setting_dict['num_Q'],num_spt1))\n",
    "# plt.fill_between( idx,\n",
    "#                   nwl_mean1 - nwl_std1,\n",
    "#                   nwl_mean1 + nwl_std1,\n",
    "#                   alpha = 0.25, edgecolor = current_palette[idxh], facecolor =  current_palette[idxh])\n",
    "\n",
    "\n",
    "#plt.plot(idx,rep_mnll_history_list_nw[0],color = 'k',marker = 'd',markersize = markersiz,label = 'Baseline'.format(setting_dict['num_Q'],num_spt1))\n",
    "#plt.plot(idx,nwl_mean1,color = 'k',marker = 'd',markersize = markersiz,label = 'Baseline'.format(setting_dict['num_Q'],num_spt1))\n",
    "# plt.fill_between( idx,\n",
    "#                   nwl_mean1 - factors*nwl_std1,\n",
    "#                   nwl_mean1 + factors*nwl_std1,\n",
    "#                   alpha = 0.25, edgecolor = 'k', facecolor = 'k')\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('iteration',fontsize = fontsiz)\n",
    "plt.ylabel('loss',fontsize =  fontsiz)\n",
    "plt.xticks(fontsize =  fontsiz)\n",
    "plt.yticks(fontsize =  fontsiz)\n",
    "plt.locator_params(axis='y', nbins=6)\n",
    "plt.locator_params(axis='x', nbins=6)\n",
    "plt.ticklabel_format(axis='x',style='sci',scilimits=(0,0))\n",
    "plt.ticklabel_format(axis='y',style='sci',scilimits=(0,0))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#plt.ylim([.4*1e3,3.3*1e3]) #airline #M=6x4\n",
    "plt.ylim([.425*1e3,0.85*1e3]) #airline #M=6x4\n",
    "#plt.ylim([.001*1e3,0.1*1e3]) #airline #M=6x4\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "leg = plt.legend(loc='best', fontsize =  fontsiz-1,handlelength=.6)\n",
    "\n",
    "for line in leg.get_lines():\n",
    "    line.set_linewidth(3) \n",
    "plt.gca().yaxis.get_offset_text().set_size(17)\n",
    "plt.gca().xaxis.get_offset_text().set_size(15)\n",
    "\n",
    "\n",
    "plt.savefig(save_figure_path + save_figname + '_loss_v2' + '.pdf'  , format='pdf', dpi=1000, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "save_figure_path + save_figname + '_loss_v2' + '.pdf'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## summary statitics experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list = []\n",
    "metric_list_base = []\n",
    "for idx in range(num_rep):\n",
    "    ith_model_w = rep_model_history_list_w[idx]\n",
    "    ith_model_e = rep_model_history_list_e[idx]\n",
    "    ith_model_nw = rep_model_history_list_nw[idx]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred_test_mu_w, pred_test_var_w = ith_model_w._predict_exact(inputs_new=x_test)\n",
    "        pred_test_mu_e, pred_test_var_e = ith_model_e._predict_exact(inputs_new=x_test)\n",
    "        pred_test_mu_nw, pred_test_var_nw = ith_model_nw._predict(inputs_new=x_test)        \n",
    "        \n",
    "        ith_rmse_w,ith_mnll_w = _evaluate_metric(pred_test_mu_w, pred_test_var_w, y_test)\n",
    "        ith_rmse_e,ith_mnll_e = _evaluate_metric(pred_test_mu_e, pred_test_var_e, y_test)\n",
    "        ith_rmse_nw,ith_mnll_nw = _evaluate_metric(pred_test_mu_nw, pred_test_var_nw, y_test)        \n",
    "        \n",
    "        metric_list.append( (ith_rmse_w,ith_mnll_w , ith_rmse_e,ith_mnll_e )  )\n",
    "        metric_list_base.append( (ith_rmse_nw,ith_mnll_nw )  )\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "metric_list_approximate = []\n",
    "for idx in range(num_rep):\n",
    "    ith_model_w = rep_model_history_list_w[idx]\n",
    "    ith_model_e = rep_model_history_list_e[idx]\n",
    "    #ith_model_nw = rep_model_history_list_nw[idx]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred_test_mu_w, pred_test_var_w = ith_model_w._predict(inputs_new=x_test,num_sample=3)\n",
    "        pred_test_mu_e, pred_test_var_e = ith_model_e._predict(inputs_new=x_test,num_sample=3)\n",
    "        \n",
    "        ith_rmse_w,ith_mnll_w = _evaluate_metric(pred_test_mu_w, pred_test_var_w, y_test)\n",
    "        ith_rmse_e,ith_mnll_e = _evaluate_metric(pred_test_mu_e, pred_test_var_e, y_test)\n",
    "        \n",
    "        metric_list_approximate.append( (ith_rmse_w,ith_mnll_w , ith_rmse_e,ith_mnll_e )  )\n",
    "        \n",
    "        \n",
    "metric_list,metric_list_approximate\n",
    "metric_list = np.concatenate([np.asarray(metric_list),np.asarray(metric_list_approximate)],axis= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVSS using weight sampling of Propostion 2 and its prediction\n",
    "## exact rmse, mnll, approxiamte rmse, mnll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28.4664,  4.9077, 28.2935,  4.8104],\n",
       "       [31.9394,  4.8811, 46.4596,  5.1857],\n",
       "       [68.2995,  5.7108, 44.1567,  5.4555],\n",
       "       [48.0516,  5.2758, 59.1432,  5.7618],\n",
       "       [69.2872,  5.7663, 69.7222,  6.1089]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(metric_list)[:,[0,1,4,5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVSS using  equal sampling and its prediction\n",
    "## exact rmse, mnll, approxiamte rmse, mnll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 29.5616,   4.9089,  33.4605,   4.9356],\n",
       "       [ 31.6029,   4.8227,  37.482 ,   5.7022],\n",
       "       [ 47.6921,   5.2714,  44.5843,   5.4208],\n",
       "       [243.6648,   6.3888,  71.724 ,   5.2593],\n",
       "       [ 70.4129,   5.8373,  70.5968,   6.009 ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(metric_list)[:,[2,3,6,7]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baseline training  and its prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 27.3999,   4.6407],\n",
       "       [ 27.5803,   4.647 ],\n",
       "       [ 24.276 ,   4.5847],\n",
       "       [ 27.5319,   4.6456],\n",
       "       [270.6889,   9.735 ]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(metric_list_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################################################\n",
      "Ws\n",
      "mean exact rmse : 49.21, mean exact mnll : 5.31, mean appr rmse : 49.56, mean appr mnll : 5.46\n",
      "std exact rmse : 7.74,  std exact mnll : 0.17,   std appr rmse : 6.29,  std appr mnll : 0.2\n",
      "####################################################################################################\n",
      "Es\n",
      "mean exact rmse : 84.59, mean exact mnll : 5.45 mean appr rmse : 51.57, mean appr mnll : 5.47\n",
      "std exact rmse : 36.17,  std exact mnll : 0.26,   std appr rmse : 7.33,  std appr mnll : 0.16\n",
      "####################################################################################################\n",
      "NWs\n",
      "mean exact rmse : 75.5, mean exact mnll : 5.65 \n",
      "std exact rmse : 43.65,  std exact mnll : 0.91 \n"
     ]
    }
   ],
   "source": [
    "factors = 1/np.sqrt(num_rep)\n",
    "factors\n",
    "# print('mean exact rmse : {0:.4f}, mean exact mnll : {1:.4f}, mean appr rmse : {2:.4f}, mean appr mnll : {3:.4f}'.format(*np.asarray(metric_list)[:3,[0,1,4,5]].mean(axis=0)))\n",
    "# print('std exact rmse : {0:.4f},  std exact mnll : {1:.4f},   std appr rmse : {2:.4f},  std appr mnll : {3:.4f}'.format(*np.asarray(metric_list)[:3,[0,1,4,5]].std(axis=0)))\n",
    "print('#'*100)\n",
    "print('Ws')\n",
    "print('mean exact rmse : {}, mean exact mnll : {}, mean appr rmse : {}, mean appr mnll : {}'.format(*np.asarray(metric_list)[:,[0,1,4,5]].mean(axis=0).round(2)  ))\n",
    "print('std exact rmse : {},  std exact mnll : {},   std appr rmse : {},  std appr mnll : {}'.format(*(np.asarray(metric_list)[:,[0,1,4,5]].std(axis=0)*factors).round(2) ) )\n",
    "print('#'*100)\n",
    "print('Es')\n",
    "print('mean exact rmse : {}, mean exact mnll : {} mean appr rmse : {}, mean appr mnll : {}'.format(*np.asarray(metric_list)[:,[2,3,6,7]].mean(axis=0).round(2) )) \n",
    "print('std exact rmse : {},  std exact mnll : {},   std appr rmse : {},  std appr mnll : {}'.format(*(np.asarray(metric_list)[:,[2,3,6,7]].std(axis=0)*factors).round(2) )  )\n",
    "\n",
    "print('#'*100)\n",
    "print('NWs')\n",
    "print('mean exact rmse : {}, mean exact mnll : {} '.format(*np.asarray(metric_list_base).mean(axis=0).round(2) ))\n",
    "print('std exact rmse : {},  std exact mnll : {} '.format(*(np.asarray(metric_list_base).std(axis=0)*factors).round(2) ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rank the evaluation by test RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 3, 2, 4]), array([0, 1, 2, 4, 3]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortidx = np.argsort(np.asarray(metric_list)[:,0])  # svss-ws ranking\n",
    "sortidx2 = np.argsort(np.asarray(metric_list)[:,2])  # svss ranking\n",
    "\n",
    "sortidx,sortidx2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## median index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rep//2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVSS with Ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 700)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x324 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = sortidx[num_rep//2]\n",
    "ith_model = rep_model_history_list_w[idx]\n",
    "with torch.no_grad():\n",
    "#     pred_train_mu, pred_train_var = ith_model._predict(inputs_new=x_train)\n",
    "#     pred_test_mu, pred_test_var = ith_model._predict(inputs_new=x_test)\n",
    "\n",
    "    \n",
    "    pred_train_mu, pred_train_var = ith_model._predict_exact(inputs_new=x_train)\n",
    "    pred_test_mu, pred_test_var = ith_model._predict_exact(inputs_new=x_test)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "#figsiz = (7,5)\n",
    "fontsiz=18\n",
    "ith = 7\n",
    "plt.figure(figsize = figsiz)\n",
    "\n",
    "\n",
    "plt.plot(x_train.cpu().data.numpy().squeeze(),y_train.cpu().data.numpy().squeeze(),color=current_palette[0],ls = '',marker = '.',markersize = 10, label='train')\n",
    "plt.plot(x_test.cpu().data.numpy().squeeze(),y_test.cpu().data.numpy().squeeze(),color=current_palette[10],ls = '',marker = '.',markersize = 10, label='test')\n",
    "\n",
    "plt.plot(x_train.cpu().data.numpy().squeeze(),pred_train_mu.cpu().data.numpy().squeeze(),'k',linewidth = 3, label='SVSS Ws (M={}x{}) mean'.format(setting_dict['num_Q'],num_spt1))\n",
    "\n",
    "plt.fill_between( x_train.cpu().data.numpy().squeeze(),\n",
    "                  pred_train_mu.cpu().data.numpy().squeeze() + 2*pred_train_var.sqrt().cpu().data.numpy().squeeze(),\n",
    "                  pred_train_mu.cpu().data.numpy().squeeze() - 2*pred_train_var.sqrt().cpu().data.numpy().squeeze(),\n",
    "                  alpha = 0.25, edgecolor = current_palette[ith], facecolor =  current_palette[ith], label='SVSS Ws (M={}x{}) var'.format(setting_dict['num_Q'],num_spt1))\n",
    "\n",
    "plt.plot(x_test.cpu().data.numpy().squeeze(),pred_test_mu.cpu().data.numpy().squeeze() ,'k',linewidth = 3)\n",
    "plt.fill_between( x_test.cpu().data.numpy().squeeze(),\n",
    "                  pred_test_mu.cpu().data.numpy().squeeze() + 2*pred_test_var.sqrt().cpu().data.numpy().squeeze(),\n",
    "                  pred_test_mu.cpu().data.numpy().squeeze() - 2*pred_test_var.sqrt().cpu().data.numpy().squeeze(),\n",
    "                  alpha = 0.25, edgecolor = current_palette[ith], facecolor =  current_palette[ith])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('x',fontsize = fontsiz)\n",
    "plt.ylabel('y',fontsize = fontsiz)\n",
    "plt.xticks(fontsize = fontsiz)\n",
    "plt.yticks(fontsize = fontsiz)\n",
    "plt.locator_params(axis='y', nbins=8)\n",
    "plt.locator_params(axis='x', nbins=6)\n",
    "plt.ticklabel_format(axis='x',style='sci',scilimits=(0,0))\n",
    "plt.ticklabel_format(axis='y',style='sci',scilimits=(0,0))\n",
    "\n",
    "plt.xticks(fontsize = fontsiz)\n",
    "plt.yticks(fontsize = fontsiz)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "leg = plt.legend(loc='best', fontsize = 15,handlelength=.5,ncol=1)\n",
    "for line in leg.get_lines():\n",
    "    line.set_linewidth(4) \n",
    "    line.set_markersize(4) \n",
    "    \n",
    "    \n",
    "plt.ylim([50,700])\n",
    "# plt.savefig(save_figure_path + save_figname + '_pred_svssws' + '.pdf'  , format='pdf', dpi=1000, bbox_inches='tight')\n",
    "# plt.show()\n",
    "# save_figure_path + save_figname + '_pred_svssws' + '.pdf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVSS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x324 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx =sortidx2[num_rep//2]\n",
    "ith_model = rep_model_history_list_e[idx]\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "#     pred_train_mu2, pred_train_var2 = ith_model._predict(inputs_new=x_train)\n",
    "#     pred_test_mu2, pred_test_var2 = ith_model._predict(inputs_new=x_test)\n",
    "\n",
    "    pred_train_mu2, pred_train_var2 = ith_model._predict_exact(inputs_new=x_train)\n",
    "    pred_test_mu2, pred_test_var2 = ith_model._predict_exact(inputs_new=x_test)\n",
    "\n",
    "    \n",
    "    \n",
    "ith = 7\n",
    "plt.figure(figsize = figsiz)\n",
    "\n",
    "\n",
    "plt.plot(x_train.cpu().data.numpy().squeeze(),y_train.cpu().data.numpy().squeeze(),color=current_palette[0],ls = '',marker = '.',markersize = 10, label='train')\n",
    "plt.plot(x_test.cpu().data.numpy().squeeze(),y_test.cpu().data.numpy().squeeze(),color=current_palette[10],ls = '',marker = '.',markersize = 10, label='test')\n",
    "\n",
    "plt.plot(x_train.cpu().data.numpy().squeeze(),pred_train_mu2.cpu().data.numpy().squeeze(),'k',linewidth = 3, label='SVSS (M={}x{}) mean'.format(setting_dict['num_Q'],num_spt1))\n",
    "plt.plot(x_test.cpu().data.numpy().squeeze(),pred_test_mu2.cpu().data.numpy().squeeze() ,'k',linewidth = 3)\n",
    "\n",
    "plt.fill_between( x_train.cpu().data.numpy().squeeze(),\n",
    "                  pred_train_mu2.cpu().data.numpy().squeeze() + 2*pred_train_var2.sqrt().cpu().data.numpy().squeeze(),\n",
    "                  pred_train_mu2.cpu().data.numpy().squeeze() - 2*pred_train_var2.sqrt().cpu().data.numpy().squeeze(),\n",
    "                  alpha = 0.25, edgecolor = current_palette[ith], facecolor =  current_palette[ith], label='SVSS (M={}x{}) var'.format(setting_dict['num_Q'],num_spt1))\n",
    "\n",
    "plt.fill_between( x_test.cpu().data.numpy().squeeze(),\n",
    "                  pred_test_mu2.cpu().data.numpy().squeeze() + 2*pred_test_var2.sqrt().cpu().data.numpy().squeeze(),\n",
    "                  pred_test_mu2.cpu().data.numpy().squeeze() - 2*pred_test_var2.sqrt().cpu().data.numpy().squeeze(),\n",
    "                  alpha = 0.25, edgecolor = current_palette[ith], facecolor =  current_palette[ith])\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('x',fontsize =  fontsiz)\n",
    "plt.ylabel('y',fontsize =  fontsiz)\n",
    "plt.xticks(fontsize =  fontsiz)\n",
    "plt.yticks(fontsize =  fontsiz)\n",
    "plt.locator_params(axis='y', nbins=8)\n",
    "plt.locator_params(axis='x', nbins=6)\n",
    "\n",
    "\n",
    "\n",
    "leg = plt.legend(loc='best', fontsize =  fontsiz-3,handlelength=.6)\n",
    "for line in leg.get_lines():\n",
    "    line.set_linewidth(3) \n",
    "    line.set_markersize(3) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('x',fontsize = fontsiz)\n",
    "plt.ylabel('y',fontsize = fontsiz)\n",
    "plt.xticks(fontsize = fontsiz)\n",
    "plt.yticks(fontsize = fontsiz)\n",
    "plt.locator_params(axis='y', nbins=8)\n",
    "plt.locator_params(axis='x', nbins=6)\n",
    "plt.ticklabel_format(axis='x',style='sci',scilimits=(0,0))\n",
    "plt.ticklabel_format(axis='y',style='sci',scilimits=(0,0))\n",
    "\n",
    "plt.xticks(fontsize = fontsiz)\n",
    "plt.yticks(fontsize = fontsiz)\n",
    "\n",
    "plt.ylim([50,700])\n",
    "\n",
    "\n",
    "leg = plt.legend(loc='best', fontsize = 15,handlelength=.5,ncol=1)\n",
    "for line in leg.get_lines():\n",
    "    line.set_linewidth(4) \n",
    "    line.set_markersize(4) \n",
    "    \n",
    "    \n",
    "# plt.savefig(save_figure_path + save_figname + '_pred_svss' + '.pdf'  , format='pdf', dpi=1000, bbox_inches='tight')    \n",
    "# save_figure_path + save_figname + '_pred_svss' + '.pdf'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
